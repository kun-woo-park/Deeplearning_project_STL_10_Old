{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import shutil\n",
    "import torch.distributed as dist\n",
    "import math\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from glob import glob\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from typing import Type, Any, Callable, Union, List, Optional\n",
    "from torch import Tensor\n",
    "from torch.hub import load_state_dict_from_url\n",
    "from torch.utils.data.dataloader import default_collate\n",
    "from torch.utils.data.sampler import BatchSampler\n",
    "from collections.abc import Mapping, Sequence\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"2\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path_path= f\"../data/split_train/train\"\n",
    "test_path_path= f\"../data/split_train/val\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=256\n",
    "num_gpus=4\n",
    "num_workers=8\n",
    "lr=0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize = transforms.Normalize(mean=[0.507, 0.487, 0.441],\n",
    "                                     std=[0.267, 0.256, 0.276])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = datasets.ImageFolder(\n",
    "        train_path_path,\n",
    "        transforms.Compose([\n",
    "        transforms.RandomRotation(degrees=45),\n",
    "            \n",
    "        transforms.RandomResizedCrop(70),\n",
    "        transforms.ColorJitter(.3,.3,.3,.3),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "            normalize,\n",
    "        ]))\n",
    "for _ in range (19):\n",
    "    aug_data = datasets.ImageFolder(\n",
    "        train_path_path,\n",
    "        transforms.Compose([\n",
    "        transforms.RandomRotation(degrees=45),\n",
    "            \n",
    "        transforms.RandomResizedCrop(70),\n",
    "        transforms.ColorJitter(.3,.3,.3,.3),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "            normalize,\n",
    "        ]))\n",
    "    dataset=torch.utils.data.ConcatDataset([dataset,aug_data])\n",
    "valset = datasets.ImageFolder(\n",
    "        test_path_path,\n",
    "        transforms.Compose([\n",
    "        transforms.RandomRotation(degrees=45),\n",
    "            \n",
    "        transforms.RandomResizedCrop(70),\n",
    "        transforms.ColorJitter(.3,.3,.3,.3),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "            normalize,\n",
    "        ]))\n",
    "for _ in range (19):\n",
    "    aug_data = datasets.ImageFolder(\n",
    "        test_path_path,\n",
    "        transforms.Compose([\n",
    "        transforms.RandomRotation(degrees=45),\n",
    "            \n",
    "        transforms.RandomResizedCrop(70),\n",
    "        transforms.ColorJitter(.3,.3,.3,.3),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "            normalize,\n",
    "        ]))\n",
    "    valset=torch.utils.data.ConcatDataset([valset,aug_data])\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "        dataset, batch_size=batch_size, shuffle=True,\n",
    "        num_workers=8, pin_memory=True,drop_last=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "        valset, batch_size=batch_size, shuffle=True,\n",
    "        num_workers=8, pin_memory=True,drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv3x3(in_planes, out_planes, stride=1, groups=1, dilation=1):\n",
    "    \"\"\"3x3 convolution with padding\"\"\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
    "                     padding=dilation, groups=groups, bias=False, dilation=dilation)\n",
    "\n",
    "\n",
    "def conv1x1(in_planes, out_planes, stride=1):\n",
    "    \"\"\"1x1 convolution\"\"\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Bottleneck(nn.Module):\n",
    "    # Bottleneck in torchvision places the stride for downsampling at 3x3 convolution(self.conv2)\n",
    "    # while original implementation places the stride at the first 1x1 convolution(self.conv1)\n",
    "    # according to \"Deep residual learning for image recognition\"https://arxiv.org/abs/1512.03385.\n",
    "    # This variant is also known as ResNet V1.5 and improves accuracy according to\n",
    "    # https://ngc.nvidia.com/catalog/model-scripts/nvidia:resnet_50_v1_5_for_pytorch.\n",
    "\n",
    "    expansion: int = 4\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        inplanes: int,\n",
    "        planes: int,\n",
    "        stride: int = 1,\n",
    "        downsample: Optional[nn.Module] = None,\n",
    "        groups: int = 1,\n",
    "        base_width: int = 64,\n",
    "        dilation: int = 1,\n",
    "        norm_layer: Optional[Callable[..., nn.Module]] = None\n",
    "    ) -> None:\n",
    "        super(Bottleneck, self).__init__()\n",
    "        if norm_layer is None:\n",
    "            norm_layer = nn.BatchNorm2d\n",
    "        width = int(planes * (base_width / 64.)) * groups\n",
    "        # Both self.conv2 and self.downsample layers downsample the input when stride != 1\n",
    "        self.conv1 = conv1x1(inplanes, width)\n",
    "        self.bn1 = norm_layer(width)\n",
    "        self.conv2 = conv3x3(width, width, stride, groups, dilation)\n",
    "        self.bn2 = norm_layer(width)\n",
    "        self.conv3 = conv1x1(width, planes * self.expansion)\n",
    "        self.bn3 = norm_layer(planes * self.expansion)\n",
    "        self.relu = nn.LeakyReLU(0.1)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        identity = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "\n",
    "        out += identity\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        block: Type[Union[Bottleneck]],\n",
    "        layers: List[int],\n",
    "        num_classes: int = 10,\n",
    "        zero_init_residual: bool = False,\n",
    "        groups: int = 1,\n",
    "        width_per_group: int = 64,\n",
    "        replace_stride_with_dilation: Optional[List[bool]] = None,\n",
    "        norm_layer: Optional[Callable[..., nn.Module]] = None\n",
    "    ) -> None:\n",
    "        super(ResNet, self).__init__()\n",
    "        if norm_layer is None:\n",
    "            norm_layer = nn.BatchNorm2d\n",
    "        self._norm_layer = norm_layer\n",
    "\n",
    "        self.inplanes = 64\n",
    "        self.dilation = 1\n",
    "        if replace_stride_with_dilation is None:\n",
    "            # each element in the tuple indicates if we should replace\n",
    "            # the 2x2 stride with a dilated convolution instead\n",
    "            replace_stride_with_dilation = [False, False, False]\n",
    "        if len(replace_stride_with_dilation) != 3:\n",
    "            raise ValueError(\"replace_stride_with_dilation should be None \"\n",
    "                             \"or a 3-element tuple, got {}\".format(replace_stride_with_dilation))\n",
    "        self.groups = groups\n",
    "        self.base_width = width_per_group\n",
    "        self.conv1 = nn.Conv2d(3, self.inplanes, kernel_size=7, stride=2, padding=3,\n",
    "                               bias=False)\n",
    "        self.bn1 = norm_layer(self.inplanes)\n",
    "        self.relu = nn.LeakyReLU(0.1)\n",
    "        \n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.layer1 = self._make_layer(block, 32, layers[0])\n",
    "        self.layer2 = self._make_layer(block, 64, layers[1], stride=2,\n",
    "                                       dilate=replace_stride_with_dilation[0])\n",
    "        self.layer3 = self._make_layer(block, 96, layers[2], stride=2,\n",
    "                                       dilate=replace_stride_with_dilation[1])\n",
    "        \n",
    "        \n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(96 * block.expansion, num_classes)\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='leaky_relu')\n",
    "            elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "        # Zero-initialize the last BN in each residual branch,\n",
    "        # so that the residual branch starts with zeros, and each residual block behaves like an identity.\n",
    "        # This improves the model by 0.2~0.3% according to https://arxiv.org/abs/1706.02677\n",
    "        if zero_init_residual:\n",
    "            for m in self.modules():\n",
    "                if isinstance(m, Bottleneck):\n",
    "                    nn.init.constant_(m.bn3.weight, 0)  # type: ignore[arg-type]\n",
    "\n",
    "    def _make_layer(self, block: Type[Union[Bottleneck]], planes: int, blocks: int,\n",
    "                    stride: int = 1, dilate: bool = False) -> nn.Sequential:\n",
    "        norm_layer = self._norm_layer\n",
    "        downsample = None\n",
    "        previous_dilation = self.dilation\n",
    "        if dilate:\n",
    "            self.dilation *= stride\n",
    "            stride = 1\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                conv1x1(self.inplanes, planes * block.expansion, stride),\n",
    "                norm_layer(planes * block.expansion),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, stride, downsample, self.groups,\n",
    "                            self.base_width, previous_dilation, norm_layer))\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for _ in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes, groups=self.groups,\n",
    "                                base_width=self.base_width, dilation=self.dilation,\n",
    "                                norm_layer=norm_layer))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def _forward_impl(self, x: Tensor) -> Tensor:\n",
    "        # See note [TorchScript super()]\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x,1)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        return self._forward_impl(x)\n",
    "\n",
    "\n",
    "def _resnet(\n",
    "    arch: str,\n",
    "    block: Type[Union[Bottleneck]],\n",
    "    layers: List[int],\n",
    "    pretrained: bool,\n",
    "    progress: bool,\n",
    "    **kwargs: Any\n",
    ") -> ResNet:\n",
    "    model = ResNet(block, layers, **kwargs)\n",
    "    if pretrained:\n",
    "        state_dict = load_state_dict_from_url(model_urls[arch],\n",
    "                                              progress=progress)\n",
    "        model.load_state_dict(state_dict)\n",
    "    return model\n",
    "\n",
    "def _resnext(arch, block, layers, pretrained, progress, **kwargs):\n",
    "    model = ResNet(block, layers, **kwargs)\n",
    "    if pretrained:\n",
    "        state_dict = load_state_dict_from_url(model_urls[arch], progress=progress)\n",
    "        model.load_state_dict(state_dict)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Model(pretrained: bool = False, progress: bool = True, **kwargs):\n",
    "    \n",
    "    kwargs['groups'] = 4\n",
    "    kwargs['width_per_group'] = 32\n",
    "    return _resnext('resnext', Bottleneck, [3, 6, 5], pretrained, progress, **kwargs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model()\n",
    "model = model.cuda()\n",
    "criterion = nn.CrossEntropyLoss().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for name, param in model.named_parameters():\n",
    "#     if param.requires_grad:\n",
    "#         print (name, param.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 64, 48, 48]           9,408\n",
      "       BatchNorm2d-2           [-1, 64, 48, 48]             128\n",
      "         LeakyReLU-3           [-1, 64, 48, 48]               0\n",
      "         MaxPool2d-4           [-1, 64, 24, 24]               0\n",
      "            Conv2d-5           [-1, 64, 24, 24]           4,096\n",
      "       BatchNorm2d-6           [-1, 64, 24, 24]             128\n",
      "         LeakyReLU-7           [-1, 64, 24, 24]               0\n",
      "            Conv2d-8           [-1, 64, 24, 24]           9,216\n",
      "       BatchNorm2d-9           [-1, 64, 24, 24]             128\n",
      "        LeakyReLU-10           [-1, 64, 24, 24]               0\n",
      "           Conv2d-11          [-1, 128, 24, 24]           8,192\n",
      "      BatchNorm2d-12          [-1, 128, 24, 24]             256\n",
      "           Conv2d-13          [-1, 128, 24, 24]           8,192\n",
      "      BatchNorm2d-14          [-1, 128, 24, 24]             256\n",
      "        LeakyReLU-15          [-1, 128, 24, 24]               0\n",
      "       Bottleneck-16          [-1, 128, 24, 24]               0\n",
      "           Conv2d-17           [-1, 64, 24, 24]           8,192\n",
      "      BatchNorm2d-18           [-1, 64, 24, 24]             128\n",
      "        LeakyReLU-19           [-1, 64, 24, 24]               0\n",
      "           Conv2d-20           [-1, 64, 24, 24]           9,216\n",
      "      BatchNorm2d-21           [-1, 64, 24, 24]             128\n",
      "        LeakyReLU-22           [-1, 64, 24, 24]               0\n",
      "           Conv2d-23          [-1, 128, 24, 24]           8,192\n",
      "      BatchNorm2d-24          [-1, 128, 24, 24]             256\n",
      "        LeakyReLU-25          [-1, 128, 24, 24]               0\n",
      "       Bottleneck-26          [-1, 128, 24, 24]               0\n",
      "           Conv2d-27           [-1, 64, 24, 24]           8,192\n",
      "      BatchNorm2d-28           [-1, 64, 24, 24]             128\n",
      "        LeakyReLU-29           [-1, 64, 24, 24]               0\n",
      "           Conv2d-30           [-1, 64, 24, 24]           9,216\n",
      "      BatchNorm2d-31           [-1, 64, 24, 24]             128\n",
      "        LeakyReLU-32           [-1, 64, 24, 24]               0\n",
      "           Conv2d-33          [-1, 128, 24, 24]           8,192\n",
      "      BatchNorm2d-34          [-1, 128, 24, 24]             256\n",
      "        LeakyReLU-35          [-1, 128, 24, 24]               0\n",
      "       Bottleneck-36          [-1, 128, 24, 24]               0\n",
      "           Conv2d-37          [-1, 128, 24, 24]          16,384\n",
      "      BatchNorm2d-38          [-1, 128, 24, 24]             256\n",
      "        LeakyReLU-39          [-1, 128, 24, 24]               0\n",
      "           Conv2d-40          [-1, 128, 12, 12]          36,864\n",
      "      BatchNorm2d-41          [-1, 128, 12, 12]             256\n",
      "        LeakyReLU-42          [-1, 128, 12, 12]               0\n",
      "           Conv2d-43          [-1, 256, 12, 12]          32,768\n",
      "      BatchNorm2d-44          [-1, 256, 12, 12]             512\n",
      "           Conv2d-45          [-1, 256, 12, 12]          32,768\n",
      "      BatchNorm2d-46          [-1, 256, 12, 12]             512\n",
      "        LeakyReLU-47          [-1, 256, 12, 12]               0\n",
      "       Bottleneck-48          [-1, 256, 12, 12]               0\n",
      "           Conv2d-49          [-1, 128, 12, 12]          32,768\n",
      "      BatchNorm2d-50          [-1, 128, 12, 12]             256\n",
      "        LeakyReLU-51          [-1, 128, 12, 12]               0\n",
      "           Conv2d-52          [-1, 128, 12, 12]          36,864\n",
      "      BatchNorm2d-53          [-1, 128, 12, 12]             256\n",
      "        LeakyReLU-54          [-1, 128, 12, 12]               0\n",
      "           Conv2d-55          [-1, 256, 12, 12]          32,768\n",
      "      BatchNorm2d-56          [-1, 256, 12, 12]             512\n",
      "        LeakyReLU-57          [-1, 256, 12, 12]               0\n",
      "       Bottleneck-58          [-1, 256, 12, 12]               0\n",
      "           Conv2d-59          [-1, 128, 12, 12]          32,768\n",
      "      BatchNorm2d-60          [-1, 128, 12, 12]             256\n",
      "        LeakyReLU-61          [-1, 128, 12, 12]               0\n",
      "           Conv2d-62          [-1, 128, 12, 12]          36,864\n",
      "      BatchNorm2d-63          [-1, 128, 12, 12]             256\n",
      "        LeakyReLU-64          [-1, 128, 12, 12]               0\n",
      "           Conv2d-65          [-1, 256, 12, 12]          32,768\n",
      "      BatchNorm2d-66          [-1, 256, 12, 12]             512\n",
      "        LeakyReLU-67          [-1, 256, 12, 12]               0\n",
      "       Bottleneck-68          [-1, 256, 12, 12]               0\n",
      "           Conv2d-69          [-1, 128, 12, 12]          32,768\n",
      "      BatchNorm2d-70          [-1, 128, 12, 12]             256\n",
      "        LeakyReLU-71          [-1, 128, 12, 12]               0\n",
      "           Conv2d-72          [-1, 128, 12, 12]          36,864\n",
      "      BatchNorm2d-73          [-1, 128, 12, 12]             256\n",
      "        LeakyReLU-74          [-1, 128, 12, 12]               0\n",
      "           Conv2d-75          [-1, 256, 12, 12]          32,768\n",
      "      BatchNorm2d-76          [-1, 256, 12, 12]             512\n",
      "        LeakyReLU-77          [-1, 256, 12, 12]               0\n",
      "       Bottleneck-78          [-1, 256, 12, 12]               0\n",
      "           Conv2d-79          [-1, 128, 12, 12]          32,768\n",
      "      BatchNorm2d-80          [-1, 128, 12, 12]             256\n",
      "        LeakyReLU-81          [-1, 128, 12, 12]               0\n",
      "           Conv2d-82          [-1, 128, 12, 12]          36,864\n",
      "      BatchNorm2d-83          [-1, 128, 12, 12]             256\n",
      "        LeakyReLU-84          [-1, 128, 12, 12]               0\n",
      "           Conv2d-85          [-1, 256, 12, 12]          32,768\n",
      "      BatchNorm2d-86          [-1, 256, 12, 12]             512\n",
      "        LeakyReLU-87          [-1, 256, 12, 12]               0\n",
      "       Bottleneck-88          [-1, 256, 12, 12]               0\n",
      "           Conv2d-89          [-1, 128, 12, 12]          32,768\n",
      "      BatchNorm2d-90          [-1, 128, 12, 12]             256\n",
      "        LeakyReLU-91          [-1, 128, 12, 12]               0\n",
      "           Conv2d-92          [-1, 128, 12, 12]          36,864\n",
      "      BatchNorm2d-93          [-1, 128, 12, 12]             256\n",
      "        LeakyReLU-94          [-1, 128, 12, 12]               0\n",
      "           Conv2d-95          [-1, 256, 12, 12]          32,768\n",
      "      BatchNorm2d-96          [-1, 256, 12, 12]             512\n",
      "        LeakyReLU-97          [-1, 256, 12, 12]               0\n",
      "       Bottleneck-98          [-1, 256, 12, 12]               0\n",
      "           Conv2d-99          [-1, 192, 12, 12]          49,152\n",
      "     BatchNorm2d-100          [-1, 192, 12, 12]             384\n",
      "       LeakyReLU-101          [-1, 192, 12, 12]               0\n",
      "          Conv2d-102            [-1, 192, 6, 6]          82,944\n",
      "     BatchNorm2d-103            [-1, 192, 6, 6]             384\n",
      "       LeakyReLU-104            [-1, 192, 6, 6]               0\n",
      "          Conv2d-105            [-1, 384, 6, 6]          73,728\n",
      "     BatchNorm2d-106            [-1, 384, 6, 6]             768\n",
      "          Conv2d-107            [-1, 384, 6, 6]          98,304\n",
      "     BatchNorm2d-108            [-1, 384, 6, 6]             768\n",
      "       LeakyReLU-109            [-1, 384, 6, 6]               0\n",
      "      Bottleneck-110            [-1, 384, 6, 6]               0\n",
      "          Conv2d-111            [-1, 192, 6, 6]          73,728\n",
      "     BatchNorm2d-112            [-1, 192, 6, 6]             384\n",
      "       LeakyReLU-113            [-1, 192, 6, 6]               0\n",
      "          Conv2d-114            [-1, 192, 6, 6]          82,944\n",
      "     BatchNorm2d-115            [-1, 192, 6, 6]             384\n",
      "       LeakyReLU-116            [-1, 192, 6, 6]               0\n",
      "          Conv2d-117            [-1, 384, 6, 6]          73,728\n",
      "     BatchNorm2d-118            [-1, 384, 6, 6]             768\n",
      "       LeakyReLU-119            [-1, 384, 6, 6]               0\n",
      "      Bottleneck-120            [-1, 384, 6, 6]               0\n",
      "          Conv2d-121            [-1, 192, 6, 6]          73,728\n",
      "     BatchNorm2d-122            [-1, 192, 6, 6]             384\n",
      "       LeakyReLU-123            [-1, 192, 6, 6]               0\n",
      "          Conv2d-124            [-1, 192, 6, 6]          82,944\n",
      "     BatchNorm2d-125            [-1, 192, 6, 6]             384\n",
      "       LeakyReLU-126            [-1, 192, 6, 6]               0\n",
      "          Conv2d-127            [-1, 384, 6, 6]          73,728\n",
      "     BatchNorm2d-128            [-1, 384, 6, 6]             768\n",
      "       LeakyReLU-129            [-1, 384, 6, 6]               0\n",
      "      Bottleneck-130            [-1, 384, 6, 6]               0\n",
      "          Conv2d-131            [-1, 192, 6, 6]          73,728\n",
      "     BatchNorm2d-132            [-1, 192, 6, 6]             384\n",
      "       LeakyReLU-133            [-1, 192, 6, 6]               0\n",
      "          Conv2d-134            [-1, 192, 6, 6]          82,944\n",
      "     BatchNorm2d-135            [-1, 192, 6, 6]             384\n",
      "       LeakyReLU-136            [-1, 192, 6, 6]               0\n",
      "          Conv2d-137            [-1, 384, 6, 6]          73,728\n",
      "     BatchNorm2d-138            [-1, 384, 6, 6]             768\n",
      "       LeakyReLU-139            [-1, 384, 6, 6]               0\n",
      "      Bottleneck-140            [-1, 384, 6, 6]               0\n",
      "          Conv2d-141            [-1, 192, 6, 6]          73,728\n",
      "     BatchNorm2d-142            [-1, 192, 6, 6]             384\n",
      "       LeakyReLU-143            [-1, 192, 6, 6]               0\n",
      "          Conv2d-144            [-1, 192, 6, 6]          82,944\n",
      "     BatchNorm2d-145            [-1, 192, 6, 6]             384\n",
      "       LeakyReLU-146            [-1, 192, 6, 6]               0\n",
      "          Conv2d-147            [-1, 384, 6, 6]          73,728\n",
      "     BatchNorm2d-148            [-1, 384, 6, 6]             768\n",
      "       LeakyReLU-149            [-1, 384, 6, 6]               0\n",
      "      Bottleneck-150            [-1, 384, 6, 6]               0\n",
      "AdaptiveAvgPool2d-151            [-1, 384, 1, 1]               0\n",
      "          Linear-152                   [-1, 10]           3,850\n",
      "================================================================\n",
      "Total params: 1,967,690\n",
      "Trainable params: 1,967,690\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.11\n",
      "Forward/backward pass size (MB): 34.61\n",
      "Params size (MB): 7.51\n",
      "Estimated Total Size (MB): 42.23\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "summary(model,(3,96,96))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=1e-4)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020/11/23 19:42:57\n",
      "epoch: 1/200 | trn loss: 2.0464 | val loss: 1.8546 | val accuracy: 30.1583% \n",
      "\n",
      "2020/11/23 19:43:32\n",
      "epoch: 2/200 | trn loss: 1.7636 | val loss: 1.6841 | val accuracy: 38.0058% \n",
      "\n",
      "2020/11/23 19:44:06\n",
      "epoch: 3/200 | trn loss: 1.6131 | val loss: 1.5852 | val accuracy: 42.1374% \n",
      "\n",
      "2020/11/23 19:44:40\n",
      "epoch: 4/200 | trn loss: 1.5141 | val loss: 1.5361 | val accuracy: 43.8151% \n",
      "\n",
      "2020/11/23 19:45:15\n",
      "epoch: 5/200 | trn loss: 1.4425 | val loss: 1.4497 | val accuracy: 47.5511% \n",
      "\n",
      "2020/11/23 19:45:50\n",
      "epoch: 6/200 | trn loss: 1.3791 | val loss: 1.4068 | val accuracy: 49.3640% \n",
      "\n",
      "2020/11/23 19:46:26\n",
      "epoch: 7/200 | trn loss: 1.3124 | val loss: 1.3583 | val accuracy: 50.8313% \n",
      "\n"
     ]
    }
   ],
   "source": [
    "saving_path=\"/home/jupyter-deeplearning/res_model\"\n",
    "trn_loss_list = []\n",
    "val_loss_list = []\n",
    "val_acc_list = []\n",
    "total_epoch=200\n",
    "model_char=\"2.0\"\n",
    "model_name=\"\"\n",
    "patience=10\n",
    "start_early_stop_check=0\n",
    "saving_start_epoch=10\n",
    "\n",
    "for epoch in range(total_epoch):\n",
    "    trn_loss = 0.0\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        inputs, labels = data\n",
    "        if torch.cuda.is_available():\n",
    "            inputs=inputs.cuda()\n",
    "            labels=labels.cuda()\n",
    "        # grad init\n",
    "        optimizer.zero_grad()\n",
    "        # forward propagation\n",
    "        output= model(inputs)\n",
    "        # calculate loss\n",
    "        loss=criterion(output, labels)\n",
    "        # back propagation \n",
    "        loss.backward()\n",
    "        # weight update\n",
    "        optimizer.step()\n",
    "        \n",
    "        # trn_loss summary\n",
    "        trn_loss += loss.item()\n",
    "        # del (memory issue)\n",
    "        del loss\n",
    "        del output\n",
    "    with torch.no_grad():\n",
    "        val_loss = 0.0\n",
    "        cor_match = 0\n",
    "        for j, val in enumerate(test_loader):\n",
    "            val_x, val_label = val\n",
    "            if torch.cuda.is_available():\n",
    "                val_x = val_x.cuda()\n",
    "                val_label =val_label.cuda()\n",
    "            val_output = model(val_x)\n",
    "            v_loss = criterion(val_output, val_label)\n",
    "            val_loss += v_loss\n",
    "            _, predicted=torch.max(val_output,1)\n",
    "            cor_match+=np.count_nonzero(predicted.cpu().detach()==val_label.cpu().detach())\n",
    "    del val_output\n",
    "    del v_loss\n",
    "    del predicted\n",
    "    \n",
    "    scheduler.step()\n",
    "    \n",
    "    \n",
    "    \n",
    "    trn_loss_list.append(trn_loss/len(train_loader))\n",
    "    val_loss_list.append(val_loss/len(test_loader))\n",
    "    val_acc=cor_match/(len(test_loader)*batch_size)\n",
    "    val_acc_list.append(val_acc)\n",
    "    now = time.localtime()\n",
    "    print (\"%04d/%02d/%02d %02d:%02d:%02d\" % (now.tm_year, now.tm_mon, now.tm_mday, now.tm_hour, now.tm_min, now.tm_sec))\n",
    "\n",
    "    print(\"epoch: {}/{} | trn loss: {:.4f} | val loss: {:.4f} | val accuracy: {:.4f}% \\n\".format(\n",
    "                epoch+1, total_epoch, trn_loss / len(train_loader), val_loss / len(test_loader), val_acc*100\n",
    "            ))\n",
    "    \n",
    "    \n",
    "    if epoch+1>2:\n",
    "        if val_loss_list[-1]>val_loss_list[-2]:\n",
    "            start_early_stop_check=1\n",
    "    else:\n",
    "        val_loss_min=val_loss_list[-1]\n",
    "        \n",
    "    if start_early_stop_check:\n",
    "        early_stop_temp=val_loss_list[-patience:]\n",
    "        if all(early_stop_temp[i]<early_stop_temp[i+1] for i in range (len(early_stop_temp)-1)):\n",
    "            print(\"Early stop!\")\n",
    "            break\n",
    "            \n",
    "    if epoch+1>saving_start_epoch:\n",
    "        if val_loss_list[-1]<val_loss_min:\n",
    "            if os.path.isfile(model_name):\n",
    "                os.remove(model_name)\n",
    "            val_loss_min=val_loss_list[-1]\n",
    "            model_name=saving_path+\"Custom_model_\"+model_char+\"_{:.3f}\".format(val_loss_min)\n",
    "            torch.save(model, model_name)\n",
    "            print(\"Model replaced and saved as \",model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = datasets.ImageFolder(\n",
    "        train_path_path,\n",
    "        transforms.Compose([\n",
    "        transforms.RandomRotation(degrees=45),\n",
    "        transforms.Resize(120),    \n",
    "        transforms.ColorJitter(.3,.3,.3,.3),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "            normalize,\n",
    "        ]))\n",
    "for _ in range (19):\n",
    "    aug_data = datasets.ImageFolder(\n",
    "        train_path_path,\n",
    "        transforms.Compose([\n",
    "        transforms.RandomRotation(degrees=45),\n",
    "        transforms.Resize(120),    \n",
    "        transforms.ColorJitter(.3,.3,.3,.3),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "            normalize,\n",
    "        ]))\n",
    "    dataset=torch.utils.data.ConcatDataset([dataset,aug_data])\n",
    "valset = datasets.ImageFolder(\n",
    "        test_path_path,\n",
    "        transforms.Compose([\n",
    "        transforms.RandomRotation(degrees=45),\n",
    "        transforms.Resize(120),\n",
    "        transforms.ColorJitter(.3,.3,.3,.3),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "            normalize,\n",
    "        ]))\n",
    "for _ in range (19):\n",
    "    aug_data = datasets.ImageFolder(\n",
    "        test_path_path,\n",
    "        transforms.Compose([\n",
    "        transforms.RandomRotation(degrees=45),\n",
    "        transforms.Resize(120),    \n",
    "        transforms.ColorJitter(.3,.3,.3,.3),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "            normalize,\n",
    "        ]))\n",
    "    valset=torch.utils.data.ConcatDataset([valset,aug_data])\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "        dataset, batch_size=batch_size, shuffle=True,\n",
    "        num_workers=8, pin_memory=True,drop_last=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "        valset, batch_size=batch_size, shuffle=True,\n",
    "        num_workers=8, pin_memory=True,drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=1e-4)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fine tuning\n",
    "\n",
    "total_epoch=80\n",
    "model_char=\"2.0\"\n",
    "model_name=\"\"\n",
    "patience=10\n",
    "start_early_stop_check=0\n",
    "saving_start_epoch=10\n",
    "\n",
    "for epoch in range(total_epoch):\n",
    "    trn_loss = 0.0\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        inputs, labels = data\n",
    "        if torch.cuda.is_available():\n",
    "            inputs=inputs.cuda()\n",
    "            labels=labels.cuda()\n",
    "        # grad init\n",
    "        optimizer.zero_grad()\n",
    "        # forward propagation\n",
    "        output= model(inputs)\n",
    "        # calculate loss\n",
    "        loss=criterion(output, labels)\n",
    "        # back propagation \n",
    "        loss.backward()\n",
    "        # weight update\n",
    "        optimizer.step()\n",
    "        \n",
    "        # trn_loss summary\n",
    "        trn_loss += loss.item()\n",
    "        # del (memory issue)\n",
    "        del loss\n",
    "        del output\n",
    "    with torch.no_grad():\n",
    "        val_loss = 0.0\n",
    "        cor_match = 0\n",
    "        for j, val in enumerate(test_loader):\n",
    "            val_x, val_label = val\n",
    "            if torch.cuda.is_available():\n",
    "                val_x = val_x.cuda()\n",
    "                val_label =val_label.cuda()\n",
    "            val_output = model(val_x)\n",
    "            v_loss = criterion(val_output, val_label)\n",
    "            val_loss += v_loss\n",
    "            _, predicted=torch.max(val_output,1)\n",
    "            cor_match+=np.count_nonzero(predicted.cpu().detach()==val_label.cpu().detach())\n",
    "    del val_output\n",
    "    del v_loss\n",
    "    del predicted\n",
    "    \n",
    "    scheduler.step()\n",
    "    \n",
    "    \n",
    "    \n",
    "    trn_loss_list.append(trn_loss/len(train_loader))\n",
    "    val_loss_list.append(val_loss/len(test_loader))\n",
    "    val_acc=cor_match/(len(test_loader)*batch_size)\n",
    "    val_acc_list.append(val_acc)\n",
    "    now = time.localtime()\n",
    "    print (\"%04d/%02d/%02d %02d:%02d:%02d\" % (now.tm_year, now.tm_mon, now.tm_mday, now.tm_hour, now.tm_min, now.tm_sec))\n",
    "\n",
    "    print(\"epoch: {}/{} | trn loss: {:.4f} | val loss: {:.4f} | val accuracy: {:.4f}% \\n\".format(\n",
    "                epoch+1, total_epoch, trn_loss / len(train_loader), val_loss / len(test_loader), val_acc*100\n",
    "            ))\n",
    "    \n",
    "    \n",
    "    if epoch+1>2:\n",
    "        if val_loss_list[-1]>val_loss_list[-2]:\n",
    "            start_early_stop_check=1\n",
    "    else:\n",
    "        val_loss_min=val_loss_list[-1]\n",
    "        \n",
    "    if start_early_stop_check:\n",
    "        early_stop_temp=val_loss_list[-patience:]\n",
    "        if all(early_stop_temp[i]<early_stop_temp[i+1] for i in range (len(early_stop_temp)-1)):\n",
    "            print(\"Early stop!\")\n",
    "            break\n",
    "            \n",
    "    if epoch+1>saving_start_epoch:\n",
    "        if val_loss_list[-1]<val_loss_min:\n",
    "            if os.path.isfile(model_name):\n",
    "                os.remove(model_name)\n",
    "            val_loss_min=val_loss_list[-1]\n",
    "            model_name=\"Custom_model_\"+model_char+\"_{:.3f}\".format(val_loss_min)\n",
    "            torch.save(model, model_name)\n",
    "            print(\"Model replaced and saved as \",model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,15))\n",
    "plt.ylabel(\"val_accuracy\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.plot(val_acc_list)\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# val_acc_list=np.array(val_acc_list)\n",
    "# np.savetxt(\"ver_2.0.txt\", val_acc_list, delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import pandas as pd\n",
    "# import argparse\n",
    "# import time\n",
    "# import torchvision\n",
    "# import torchvision.transforms as transforms\n",
    "# from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize = transforms.Normalize(mean=[0.507, 0.487, 0.441],\n",
    "#                                      std=[0.267, 0.256, 0.276])\n",
    "# test_transform = transforms.Compose([\n",
    "#         transforms.ToTensor(),\n",
    "#         normalize\n",
    "#     ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_dataset = torchvision.datasets.ImageFolder('./data/test', transform=test_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_loader = DataLoader(test_dataset, batch_size=batch_size, num_workers=4, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Category = []\n",
    "# for input, _ in test_loader:\n",
    "#     input = input.cuda()\n",
    "#     output = model(input)\n",
    "#     output = torch.argmax(output, dim=1)\n",
    "#     Category = Category + output.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Id = list(range(0, 8000))\n",
    "# samples = {\n",
    "#    'Id': Id,\n",
    "#    'Category': Category \n",
    "# }\n",
    "# df = pd.DataFrame(samples, columns=['Id', 'Category'])\n",
    "\n",
    "# df.to_csv('submission_2.0_2.csv', index=False)\n",
    "# print('Done!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
