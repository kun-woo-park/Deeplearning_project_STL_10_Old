{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import shutil\n",
    "import torch.distributed as dist\n",
    "import math\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from glob import glob\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from typing import Type, Any, Callable, Union, List, Optional\n",
    "from torch import Tensor\n",
    "from torch.hub import load_state_dict_from_url\n",
    "from torch.utils.data.dataloader import default_collate\n",
    "from torch.utils.data.sampler import BatchSampler\n",
    "from collections.abc import Mapping, Sequence\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path_path= f\"./data/split_train/train\"\n",
    "test_path_path= f\"./data/split_train/val\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=128\n",
    "num_gpus=4\n",
    "num_workers=64\n",
    "lr=0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize = transforms.Normalize(mean=[0.507, 0.487, 0.441],\n",
    "                                     std=[0.267, 0.256, 0.276])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = datasets.ImageFolder(\n",
    "        train_path_path,\n",
    "        transforms.Compose([\n",
    "        transforms.RandomRotation(degrees=45),\n",
    "            \n",
    "        transforms.RandomResizedCrop(70),\n",
    "        transforms.ColorJitter(.3,.3,.3,.3),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "            transforms.RandomVerticalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "            normalize,\n",
    "        ]))\n",
    "for _ in range (19):\n",
    "    aug_data = datasets.ImageFolder(\n",
    "        train_path_path,\n",
    "        transforms.Compose([\n",
    "        transforms.RandomRotation(degrees=45),\n",
    "            \n",
    "        transforms.RandomResizedCrop(70),\n",
    "        transforms.ColorJitter(.3,.3,.3,.3),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "            transforms.RandomVerticalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "            normalize,\n",
    "        ]))\n",
    "    dataset=torch.utils.data.ConcatDataset([dataset,aug_data])\n",
    "valset = datasets.ImageFolder(\n",
    "        test_path_path,\n",
    "        transforms.Compose([\n",
    "        transforms.RandomRotation(degrees=45),\n",
    "            \n",
    "        transforms.RandomResizedCrop(70),\n",
    "        transforms.ColorJitter(.3,.3,.3,.3),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "            transforms.RandomVerticalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "            normalize,\n",
    "        ]))\n",
    "for _ in range (19):\n",
    "    aug_data = datasets.ImageFolder(\n",
    "        test_path_path,\n",
    "        transforms.Compose([\n",
    "        transforms.RandomRotation(degrees=45),\n",
    "            \n",
    "        transforms.RandomResizedCrop(70),\n",
    "        transforms.ColorJitter(.3,.3,.3,.3),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "            transforms.RandomVerticalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "            normalize,\n",
    "        ]))\n",
    "    valset=torch.utils.data.ConcatDataset([valset,aug_data])\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "        dataset, batch_size=batch_size, shuffle=True,\n",
    "        num_workers=8, pin_memory=True,drop_last=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "        valset, batch_size=batch_size, shuffle=True,\n",
    "        num_workers=8, pin_memory=True,drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv3x3(in_planes, out_planes, stride=1, groups=1, dilation=1):\n",
    "    \"\"\"3x3 convolution with padding\"\"\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
    "                     padding=dilation, groups=groups, bias=False, dilation=dilation)\n",
    "\n",
    "\n",
    "def conv1x1(in_planes, out_planes, stride=1):\n",
    "    \"\"\"1x1 convolution\"\"\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Bottleneck(nn.Module):\n",
    "    # Bottleneck in torchvision places the stride for downsampling at 3x3 convolution(self.conv2)\n",
    "    # while original implementation places the stride at the first 1x1 convolution(self.conv1)\n",
    "    # according to \"Deep residual learning for image recognition\"https://arxiv.org/abs/1512.03385.\n",
    "    # This variant is also known as ResNet V1.5 and improves accuracy according to\n",
    "    # https://ngc.nvidia.com/catalog/model-scripts/nvidia:resnet_50_v1_5_for_pytorch.\n",
    "\n",
    "    expansion: int = 4\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        inplanes: int,\n",
    "        planes: int,\n",
    "        stride: int = 1,\n",
    "        downsample: Optional[nn.Module] = None,\n",
    "        groups: int = 1,\n",
    "        base_width: int = 64,\n",
    "        dilation: int = 1,\n",
    "        norm_layer: Optional[Callable[..., nn.Module]] = None\n",
    "    ) -> None:\n",
    "        super(Bottleneck, self).__init__()\n",
    "        if norm_layer is None:\n",
    "            norm_layer = nn.BatchNorm2d\n",
    "        width = int(planes * (base_width / 64.)) * groups\n",
    "        # Both self.conv2 and self.downsample layers downsample the input when stride != 1\n",
    "        self.conv1 = conv1x1(inplanes, width)\n",
    "        self.bn1 = norm_layer(width)\n",
    "        self.conv2 = conv3x3(width, width, stride, groups, dilation)\n",
    "        self.bn2 = norm_layer(width)\n",
    "        self.conv3 = conv1x1(width, planes * self.expansion)\n",
    "        self.bn3 = norm_layer(planes * self.expansion)\n",
    "        self.relu = nn.LeakyReLU(0.1)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        identity = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "\n",
    "        out += identity\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        block: Type[Union[Bottleneck]],\n",
    "        layers: List[int],\n",
    "        num_classes: int = 10,\n",
    "        zero_init_residual: bool = False,\n",
    "        groups: int = 1,\n",
    "        width_per_group: int = 64,\n",
    "        replace_stride_with_dilation: Optional[List[bool]] = None,\n",
    "        norm_layer: Optional[Callable[..., nn.Module]] = None\n",
    "    ) -> None:\n",
    "        super(ResNet, self).__init__()\n",
    "        if norm_layer is None:\n",
    "            norm_layer = nn.BatchNorm2d\n",
    "        self._norm_layer = norm_layer\n",
    "\n",
    "        self.inplanes = 64\n",
    "        self.dilation = 1\n",
    "        if replace_stride_with_dilation is None:\n",
    "            # each element in the tuple indicates if we should replace\n",
    "            # the 2x2 stride with a dilated convolution instead\n",
    "            replace_stride_with_dilation = [False, False, False]\n",
    "        if len(replace_stride_with_dilation) != 3:\n",
    "            raise ValueError(\"replace_stride_with_dilation should be None \"\n",
    "                             \"or a 3-element tuple, got {}\".format(replace_stride_with_dilation))\n",
    "        self.groups = groups\n",
    "        self.base_width = width_per_group\n",
    "        self.conv1 = nn.Conv2d(3, self.inplanes, kernel_size=4, stride=1,\n",
    "                               bias=False)\n",
    "        self.bn1 = norm_layer(self.inplanes)\n",
    "        self.relu = nn.LeakyReLU(0.1)\n",
    "        \n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.layer1 = self._make_layer(block, 30, layers[0])\n",
    "        self.layer2 = self._make_layer(block, 60, layers[1], stride=2,\n",
    "                                       dilate=replace_stride_with_dilation[0])\n",
    "        self.layer3 = self._make_layer(block, 96, layers[2], stride=2,\n",
    "                                       dilate=replace_stride_with_dilation[1])\n",
    "        \n",
    "        \n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(96 * block.expansion, num_classes)\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='leaky_relu')\n",
    "            elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "        # Zero-initialize the last BN in each residual branch,\n",
    "        # so that the residual branch starts with zeros, and each residual block behaves like an identity.\n",
    "        # This improves the model by 0.2~0.3% according to https://arxiv.org/abs/1706.02677\n",
    "        if zero_init_residual:\n",
    "            for m in self.modules():\n",
    "                if isinstance(m, Bottleneck):\n",
    "                    nn.init.constant_(m.bn3.weight, 0)  # type: ignore[arg-type]\n",
    "\n",
    "    def _make_layer(self, block: Type[Union[Bottleneck]], planes: int, blocks: int,\n",
    "                    stride: int = 1, dilate: bool = False) -> nn.Sequential:\n",
    "        norm_layer = self._norm_layer\n",
    "        downsample = None\n",
    "        previous_dilation = self.dilation\n",
    "        if dilate:\n",
    "            self.dilation *= stride\n",
    "            stride = 1\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                conv1x1(self.inplanes, planes * block.expansion, stride),\n",
    "                norm_layer(planes * block.expansion),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, stride, downsample, self.groups,\n",
    "                            self.base_width, previous_dilation, norm_layer))\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for _ in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes, groups=self.groups,\n",
    "                                base_width=self.base_width, dilation=self.dilation,\n",
    "                                norm_layer=norm_layer))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def _forward_impl(self, x: Tensor) -> Tensor:\n",
    "        # See note [TorchScript super()]\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x,1)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        return self._forward_impl(x)\n",
    "\n",
    "\n",
    "def _resnet(\n",
    "    arch: str,\n",
    "    block: Type[Union[Bottleneck]],\n",
    "    layers: List[int],\n",
    "    pretrained: bool,\n",
    "    progress: bool,\n",
    "    **kwargs: Any\n",
    ") -> ResNet:\n",
    "    model = ResNet(block, layers, **kwargs)\n",
    "    if pretrained:\n",
    "        state_dict = load_state_dict_from_url(model_urls[arch],\n",
    "                                              progress=progress)\n",
    "        model.load_state_dict(state_dict)\n",
    "    return model\n",
    "\n",
    "def _resnext(arch, block, layers, pretrained, progress, **kwargs):\n",
    "    model = ResNet(block, layers, **kwargs)\n",
    "    if pretrained:\n",
    "        state_dict = load_state_dict_from_url(model_urls[arch], progress=progress)\n",
    "        model.load_state_dict(state_dict)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Model(pretrained: bool = False, progress: bool = True, **kwargs):\n",
    "    \n",
    "    kwargs['groups'] = 1\n",
    "    kwargs['width_per_group'] = 64\n",
    "    return _resnext('resnext', Bottleneck, [4, 9, 8], pretrained, progress, **kwargs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LabelSmoothingLoss(nn.Module):\n",
    "    def __init__(self, classes, smoothing=0.1, dim=-1):\n",
    "        super(LabelSmoothingLoss, self).__init__()\n",
    "        self.confidence = 1.0 - smoothing\n",
    "        self.smoothing = smoothing\n",
    "        self.cls = classes\n",
    "        self.dim = dim\n",
    "    def forward(self, pred, target):\n",
    "        pred = pred.log_softmax(dim=self.dim)\n",
    "        with torch.no_grad():\n",
    "            true_dist = torch.zeros_like(pred)\n",
    "            true_dist.fill_(self.smoothing / (self.cls - 1))\n",
    "            true_dist.scatter_(1, target.data.unsqueeze(1), self.confidence)\n",
    "        return torch.mean(torch.sum(-true_dist * pred, dim=self.dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model()\n",
    "model = model.cuda()\n",
    "criterion = nn.CrossEntropyLoss().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for name, param in model.named_parameters():\n",
    "#     if param.requires_grad:\n",
    "#         print (name, param.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 64, 93, 93]           3,072\n",
      "       BatchNorm2d-2           [-1, 64, 93, 93]             128\n",
      "         LeakyReLU-3           [-1, 64, 93, 93]               0\n",
      "         MaxPool2d-4           [-1, 64, 46, 46]               0\n",
      "            Conv2d-5           [-1, 30, 46, 46]           1,920\n",
      "       BatchNorm2d-6           [-1, 30, 46, 46]              60\n",
      "         LeakyReLU-7           [-1, 30, 46, 46]               0\n",
      "            Conv2d-8           [-1, 30, 46, 46]           8,100\n",
      "       BatchNorm2d-9           [-1, 30, 46, 46]              60\n",
      "        LeakyReLU-10           [-1, 30, 46, 46]               0\n",
      "           Conv2d-11          [-1, 120, 46, 46]           3,600\n",
      "      BatchNorm2d-12          [-1, 120, 46, 46]             240\n",
      "           Conv2d-13          [-1, 120, 46, 46]           7,680\n",
      "      BatchNorm2d-14          [-1, 120, 46, 46]             240\n",
      "        LeakyReLU-15          [-1, 120, 46, 46]               0\n",
      "       Bottleneck-16          [-1, 120, 46, 46]               0\n",
      "           Conv2d-17           [-1, 30, 46, 46]           3,600\n",
      "      BatchNorm2d-18           [-1, 30, 46, 46]              60\n",
      "        LeakyReLU-19           [-1, 30, 46, 46]               0\n",
      "           Conv2d-20           [-1, 30, 46, 46]           8,100\n",
      "      BatchNorm2d-21           [-1, 30, 46, 46]              60\n",
      "        LeakyReLU-22           [-1, 30, 46, 46]               0\n",
      "           Conv2d-23          [-1, 120, 46, 46]           3,600\n",
      "      BatchNorm2d-24          [-1, 120, 46, 46]             240\n",
      "        LeakyReLU-25          [-1, 120, 46, 46]               0\n",
      "       Bottleneck-26          [-1, 120, 46, 46]               0\n",
      "           Conv2d-27           [-1, 30, 46, 46]           3,600\n",
      "      BatchNorm2d-28           [-1, 30, 46, 46]              60\n",
      "        LeakyReLU-29           [-1, 30, 46, 46]               0\n",
      "           Conv2d-30           [-1, 30, 46, 46]           8,100\n",
      "      BatchNorm2d-31           [-1, 30, 46, 46]              60\n",
      "        LeakyReLU-32           [-1, 30, 46, 46]               0\n",
      "           Conv2d-33          [-1, 120, 46, 46]           3,600\n",
      "      BatchNorm2d-34          [-1, 120, 46, 46]             240\n",
      "        LeakyReLU-35          [-1, 120, 46, 46]               0\n",
      "       Bottleneck-36          [-1, 120, 46, 46]               0\n",
      "           Conv2d-37           [-1, 30, 46, 46]           3,600\n",
      "      BatchNorm2d-38           [-1, 30, 46, 46]              60\n",
      "        LeakyReLU-39           [-1, 30, 46, 46]               0\n",
      "           Conv2d-40           [-1, 30, 46, 46]           8,100\n",
      "      BatchNorm2d-41           [-1, 30, 46, 46]              60\n",
      "        LeakyReLU-42           [-1, 30, 46, 46]               0\n",
      "           Conv2d-43          [-1, 120, 46, 46]           3,600\n",
      "      BatchNorm2d-44          [-1, 120, 46, 46]             240\n",
      "        LeakyReLU-45          [-1, 120, 46, 46]               0\n",
      "       Bottleneck-46          [-1, 120, 46, 46]               0\n",
      "           Conv2d-47           [-1, 60, 46, 46]           7,200\n",
      "      BatchNorm2d-48           [-1, 60, 46, 46]             120\n",
      "        LeakyReLU-49           [-1, 60, 46, 46]               0\n",
      "           Conv2d-50           [-1, 60, 23, 23]          32,400\n",
      "      BatchNorm2d-51           [-1, 60, 23, 23]             120\n",
      "        LeakyReLU-52           [-1, 60, 23, 23]               0\n",
      "           Conv2d-53          [-1, 240, 23, 23]          14,400\n",
      "      BatchNorm2d-54          [-1, 240, 23, 23]             480\n",
      "           Conv2d-55          [-1, 240, 23, 23]          28,800\n",
      "      BatchNorm2d-56          [-1, 240, 23, 23]             480\n",
      "        LeakyReLU-57          [-1, 240, 23, 23]               0\n",
      "       Bottleneck-58          [-1, 240, 23, 23]               0\n",
      "           Conv2d-59           [-1, 60, 23, 23]          14,400\n",
      "      BatchNorm2d-60           [-1, 60, 23, 23]             120\n",
      "        LeakyReLU-61           [-1, 60, 23, 23]               0\n",
      "           Conv2d-62           [-1, 60, 23, 23]          32,400\n",
      "      BatchNorm2d-63           [-1, 60, 23, 23]             120\n",
      "        LeakyReLU-64           [-1, 60, 23, 23]               0\n",
      "           Conv2d-65          [-1, 240, 23, 23]          14,400\n",
      "      BatchNorm2d-66          [-1, 240, 23, 23]             480\n",
      "        LeakyReLU-67          [-1, 240, 23, 23]               0\n",
      "       Bottleneck-68          [-1, 240, 23, 23]               0\n",
      "           Conv2d-69           [-1, 60, 23, 23]          14,400\n",
      "      BatchNorm2d-70           [-1, 60, 23, 23]             120\n",
      "        LeakyReLU-71           [-1, 60, 23, 23]               0\n",
      "           Conv2d-72           [-1, 60, 23, 23]          32,400\n",
      "      BatchNorm2d-73           [-1, 60, 23, 23]             120\n",
      "        LeakyReLU-74           [-1, 60, 23, 23]               0\n",
      "           Conv2d-75          [-1, 240, 23, 23]          14,400\n",
      "      BatchNorm2d-76          [-1, 240, 23, 23]             480\n",
      "        LeakyReLU-77          [-1, 240, 23, 23]               0\n",
      "       Bottleneck-78          [-1, 240, 23, 23]               0\n",
      "           Conv2d-79           [-1, 60, 23, 23]          14,400\n",
      "      BatchNorm2d-80           [-1, 60, 23, 23]             120\n",
      "        LeakyReLU-81           [-1, 60, 23, 23]               0\n",
      "           Conv2d-82           [-1, 60, 23, 23]          32,400\n",
      "      BatchNorm2d-83           [-1, 60, 23, 23]             120\n",
      "        LeakyReLU-84           [-1, 60, 23, 23]               0\n",
      "           Conv2d-85          [-1, 240, 23, 23]          14,400\n",
      "      BatchNorm2d-86          [-1, 240, 23, 23]             480\n",
      "        LeakyReLU-87          [-1, 240, 23, 23]               0\n",
      "       Bottleneck-88          [-1, 240, 23, 23]               0\n",
      "           Conv2d-89           [-1, 60, 23, 23]          14,400\n",
      "      BatchNorm2d-90           [-1, 60, 23, 23]             120\n",
      "        LeakyReLU-91           [-1, 60, 23, 23]               0\n",
      "           Conv2d-92           [-1, 60, 23, 23]          32,400\n",
      "      BatchNorm2d-93           [-1, 60, 23, 23]             120\n",
      "        LeakyReLU-94           [-1, 60, 23, 23]               0\n",
      "           Conv2d-95          [-1, 240, 23, 23]          14,400\n",
      "      BatchNorm2d-96          [-1, 240, 23, 23]             480\n",
      "        LeakyReLU-97          [-1, 240, 23, 23]               0\n",
      "       Bottleneck-98          [-1, 240, 23, 23]               0\n",
      "           Conv2d-99           [-1, 60, 23, 23]          14,400\n",
      "     BatchNorm2d-100           [-1, 60, 23, 23]             120\n",
      "       LeakyReLU-101           [-1, 60, 23, 23]               0\n",
      "          Conv2d-102           [-1, 60, 23, 23]          32,400\n",
      "     BatchNorm2d-103           [-1, 60, 23, 23]             120\n",
      "       LeakyReLU-104           [-1, 60, 23, 23]               0\n",
      "          Conv2d-105          [-1, 240, 23, 23]          14,400\n",
      "     BatchNorm2d-106          [-1, 240, 23, 23]             480\n",
      "       LeakyReLU-107          [-1, 240, 23, 23]               0\n",
      "      Bottleneck-108          [-1, 240, 23, 23]               0\n",
      "          Conv2d-109           [-1, 60, 23, 23]          14,400\n",
      "     BatchNorm2d-110           [-1, 60, 23, 23]             120\n",
      "       LeakyReLU-111           [-1, 60, 23, 23]               0\n",
      "          Conv2d-112           [-1, 60, 23, 23]          32,400\n",
      "     BatchNorm2d-113           [-1, 60, 23, 23]             120\n",
      "       LeakyReLU-114           [-1, 60, 23, 23]               0\n",
      "          Conv2d-115          [-1, 240, 23, 23]          14,400\n",
      "     BatchNorm2d-116          [-1, 240, 23, 23]             480\n",
      "       LeakyReLU-117          [-1, 240, 23, 23]               0\n",
      "      Bottleneck-118          [-1, 240, 23, 23]               0\n",
      "          Conv2d-119           [-1, 60, 23, 23]          14,400\n",
      "     BatchNorm2d-120           [-1, 60, 23, 23]             120\n",
      "       LeakyReLU-121           [-1, 60, 23, 23]               0\n",
      "          Conv2d-122           [-1, 60, 23, 23]          32,400\n",
      "     BatchNorm2d-123           [-1, 60, 23, 23]             120\n",
      "       LeakyReLU-124           [-1, 60, 23, 23]               0\n",
      "          Conv2d-125          [-1, 240, 23, 23]          14,400\n",
      "     BatchNorm2d-126          [-1, 240, 23, 23]             480\n",
      "       LeakyReLU-127          [-1, 240, 23, 23]               0\n",
      "      Bottleneck-128          [-1, 240, 23, 23]               0\n",
      "          Conv2d-129           [-1, 60, 23, 23]          14,400\n",
      "     BatchNorm2d-130           [-1, 60, 23, 23]             120\n",
      "       LeakyReLU-131           [-1, 60, 23, 23]               0\n",
      "          Conv2d-132           [-1, 60, 23, 23]          32,400\n",
      "     BatchNorm2d-133           [-1, 60, 23, 23]             120\n",
      "       LeakyReLU-134           [-1, 60, 23, 23]               0\n",
      "          Conv2d-135          [-1, 240, 23, 23]          14,400\n",
      "     BatchNorm2d-136          [-1, 240, 23, 23]             480\n",
      "       LeakyReLU-137          [-1, 240, 23, 23]               0\n",
      "      Bottleneck-138          [-1, 240, 23, 23]               0\n",
      "          Conv2d-139           [-1, 96, 23, 23]          23,040\n",
      "     BatchNorm2d-140           [-1, 96, 23, 23]             192\n",
      "       LeakyReLU-141           [-1, 96, 23, 23]               0\n",
      "          Conv2d-142           [-1, 96, 12, 12]          82,944\n",
      "     BatchNorm2d-143           [-1, 96, 12, 12]             192\n",
      "       LeakyReLU-144           [-1, 96, 12, 12]               0\n",
      "          Conv2d-145          [-1, 384, 12, 12]          36,864\n",
      "     BatchNorm2d-146          [-1, 384, 12, 12]             768\n",
      "          Conv2d-147          [-1, 384, 12, 12]          92,160\n",
      "     BatchNorm2d-148          [-1, 384, 12, 12]             768\n",
      "       LeakyReLU-149          [-1, 384, 12, 12]               0\n",
      "      Bottleneck-150          [-1, 384, 12, 12]               0\n",
      "          Conv2d-151           [-1, 96, 12, 12]          36,864\n",
      "     BatchNorm2d-152           [-1, 96, 12, 12]             192\n",
      "       LeakyReLU-153           [-1, 96, 12, 12]               0\n",
      "          Conv2d-154           [-1, 96, 12, 12]          82,944\n",
      "     BatchNorm2d-155           [-1, 96, 12, 12]             192\n",
      "       LeakyReLU-156           [-1, 96, 12, 12]               0\n",
      "          Conv2d-157          [-1, 384, 12, 12]          36,864\n",
      "     BatchNorm2d-158          [-1, 384, 12, 12]             768\n",
      "       LeakyReLU-159          [-1, 384, 12, 12]               0\n",
      "      Bottleneck-160          [-1, 384, 12, 12]               0\n",
      "          Conv2d-161           [-1, 96, 12, 12]          36,864\n",
      "     BatchNorm2d-162           [-1, 96, 12, 12]             192\n",
      "       LeakyReLU-163           [-1, 96, 12, 12]               0\n",
      "          Conv2d-164           [-1, 96, 12, 12]          82,944\n",
      "     BatchNorm2d-165           [-1, 96, 12, 12]             192\n",
      "       LeakyReLU-166           [-1, 96, 12, 12]               0\n",
      "          Conv2d-167          [-1, 384, 12, 12]          36,864\n",
      "     BatchNorm2d-168          [-1, 384, 12, 12]             768\n",
      "       LeakyReLU-169          [-1, 384, 12, 12]               0\n",
      "      Bottleneck-170          [-1, 384, 12, 12]               0\n",
      "          Conv2d-171           [-1, 96, 12, 12]          36,864\n",
      "     BatchNorm2d-172           [-1, 96, 12, 12]             192\n",
      "       LeakyReLU-173           [-1, 96, 12, 12]               0\n",
      "          Conv2d-174           [-1, 96, 12, 12]          82,944\n",
      "     BatchNorm2d-175           [-1, 96, 12, 12]             192\n",
      "       LeakyReLU-176           [-1, 96, 12, 12]               0\n",
      "          Conv2d-177          [-1, 384, 12, 12]          36,864\n",
      "     BatchNorm2d-178          [-1, 384, 12, 12]             768\n",
      "       LeakyReLU-179          [-1, 384, 12, 12]               0\n",
      "      Bottleneck-180          [-1, 384, 12, 12]               0\n",
      "          Conv2d-181           [-1, 96, 12, 12]          36,864\n",
      "     BatchNorm2d-182           [-1, 96, 12, 12]             192\n",
      "       LeakyReLU-183           [-1, 96, 12, 12]               0\n",
      "          Conv2d-184           [-1, 96, 12, 12]          82,944\n",
      "     BatchNorm2d-185           [-1, 96, 12, 12]             192\n",
      "       LeakyReLU-186           [-1, 96, 12, 12]               0\n",
      "          Conv2d-187          [-1, 384, 12, 12]          36,864\n",
      "     BatchNorm2d-188          [-1, 384, 12, 12]             768\n",
      "       LeakyReLU-189          [-1, 384, 12, 12]               0\n",
      "      Bottleneck-190          [-1, 384, 12, 12]               0\n",
      "          Conv2d-191           [-1, 96, 12, 12]          36,864\n",
      "     BatchNorm2d-192           [-1, 96, 12, 12]             192\n",
      "       LeakyReLU-193           [-1, 96, 12, 12]               0\n",
      "          Conv2d-194           [-1, 96, 12, 12]          82,944\n",
      "     BatchNorm2d-195           [-1, 96, 12, 12]             192\n",
      "       LeakyReLU-196           [-1, 96, 12, 12]               0\n",
      "          Conv2d-197          [-1, 384, 12, 12]          36,864\n",
      "     BatchNorm2d-198          [-1, 384, 12, 12]             768\n",
      "       LeakyReLU-199          [-1, 384, 12, 12]               0\n",
      "      Bottleneck-200          [-1, 384, 12, 12]               0\n",
      "          Conv2d-201           [-1, 96, 12, 12]          36,864\n",
      "     BatchNorm2d-202           [-1, 96, 12, 12]             192\n",
      "       LeakyReLU-203           [-1, 96, 12, 12]               0\n",
      "          Conv2d-204           [-1, 96, 12, 12]          82,944\n",
      "     BatchNorm2d-205           [-1, 96, 12, 12]             192\n",
      "       LeakyReLU-206           [-1, 96, 12, 12]               0\n",
      "          Conv2d-207          [-1, 384, 12, 12]          36,864\n",
      "     BatchNorm2d-208          [-1, 384, 12, 12]             768\n",
      "       LeakyReLU-209          [-1, 384, 12, 12]               0\n",
      "      Bottleneck-210          [-1, 384, 12, 12]               0\n",
      "          Conv2d-211           [-1, 96, 12, 12]          36,864\n",
      "     BatchNorm2d-212           [-1, 96, 12, 12]             192\n",
      "       LeakyReLU-213           [-1, 96, 12, 12]               0\n",
      "          Conv2d-214           [-1, 96, 12, 12]          82,944\n",
      "     BatchNorm2d-215           [-1, 96, 12, 12]             192\n",
      "       LeakyReLU-216           [-1, 96, 12, 12]               0\n",
      "          Conv2d-217          [-1, 384, 12, 12]          36,864\n",
      "     BatchNorm2d-218          [-1, 384, 12, 12]             768\n",
      "       LeakyReLU-219          [-1, 384, 12, 12]               0\n",
      "      Bottleneck-220          [-1, 384, 12, 12]               0\n",
      "AdaptiveAvgPool2d-221            [-1, 384, 1, 1]               0\n",
      "          Linear-222                   [-1, 10]           3,850\n",
      "================================================================\n",
      "Total params: 1,996,986\n",
      "Trainable params: 1,996,986\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.11\n",
      "Forward/backward pass size (MB): 132.52\n",
      "Params size (MB): 7.62\n",
      "Estimated Total Size (MB): 140.24\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "summary(model,(3,96,96))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=1e-4)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020/11/25 00:41:51\n",
      "epoch: 1/200 | trn loss: 1.8344 | val loss: 1.6241 | val accuracy: 39.5933% \n",
      "\n",
      "2020/11/25 00:43:26\n",
      "epoch: 2/200 | trn loss: 1.4912 | val loss: 1.4126 | val accuracy: 48.7780% \n",
      "\n",
      "2020/11/25 00:45:00\n",
      "epoch: 3/200 | trn loss: 1.2910 | val loss: 1.3192 | val accuracy: 53.3053% \n",
      "\n",
      "2020/11/25 00:46:35\n",
      "epoch: 4/200 | trn loss: 1.1636 | val loss: 1.2314 | val accuracy: 56.0897% \n",
      "\n",
      "2020/11/25 00:48:09\n",
      "epoch: 5/200 | trn loss: 1.0585 | val loss: 1.1415 | val accuracy: 59.1947% \n",
      "\n",
      "2020/11/25 00:49:44\n",
      "epoch: 6/200 | trn loss: 0.9728 | val loss: 1.1210 | val accuracy: 60.4768% \n",
      "\n",
      "2020/11/25 00:51:18\n",
      "epoch: 7/200 | trn loss: 0.9106 | val loss: 1.0969 | val accuracy: 61.8890% \n",
      "\n",
      "2020/11/25 00:52:53\n",
      "epoch: 8/200 | trn loss: 0.8500 | val loss: 1.0886 | val accuracy: 62.6853% \n",
      "\n",
      "2020/11/25 00:54:27\n",
      "epoch: 9/200 | trn loss: 0.8090 | val loss: 1.0263 | val accuracy: 64.1877% \n",
      "\n",
      "2020/11/25 00:56:01\n",
      "epoch: 10/200 | trn loss: 0.7590 | val loss: 1.0393 | val accuracy: 64.7236% \n",
      "\n",
      "2020/11/25 00:57:36\n",
      "epoch: 11/200 | trn loss: 0.7273 | val loss: 1.0262 | val accuracy: 64.9339% \n",
      "\n",
      "Model replaced and saved as  /home/jupyter-deeplearning/res_model/Custom_model_2.0_1.026\n",
      "2020/11/25 00:59:10\n",
      "epoch: 12/200 | trn loss: 0.6873 | val loss: 0.9815 | val accuracy: 66.6867% \n",
      "\n",
      "Model replaced and saved as  /home/jupyter-deeplearning/res_model/Custom_model_2.0_0.981\n",
      "2020/11/25 01:00:44\n",
      "epoch: 13/200 | trn loss: 0.6647 | val loss: 1.0206 | val accuracy: 65.9605% \n",
      "\n",
      "2020/11/25 01:02:19\n",
      "epoch: 14/200 | trn loss: 0.6358 | val loss: 1.0285 | val accuracy: 65.8854% \n",
      "\n",
      "2020/11/25 01:03:53\n",
      "epoch: 15/200 | trn loss: 0.6149 | val loss: 1.0046 | val accuracy: 66.2710% \n",
      "\n",
      "2020/11/25 01:05:27\n",
      "epoch: 16/200 | trn loss: 0.5886 | val loss: 0.9915 | val accuracy: 66.6116% \n",
      "\n",
      "2020/11/25 01:07:01\n",
      "epoch: 17/200 | trn loss: 0.5665 | val loss: 0.9833 | val accuracy: 67.5931% \n",
      "\n",
      "2020/11/25 01:08:35\n",
      "epoch: 18/200 | trn loss: 0.5493 | val loss: 0.9700 | val accuracy: 67.9137% \n",
      "\n",
      "Model replaced and saved as  /home/jupyter-deeplearning/res_model/Custom_model_2.0_0.970\n",
      "2020/11/25 01:10:10\n",
      "epoch: 19/200 | trn loss: 0.5358 | val loss: 0.9469 | val accuracy: 68.8902% \n",
      "\n",
      "Model replaced and saved as  /home/jupyter-deeplearning/res_model/Custom_model_2.0_0.947\n",
      "2020/11/25 01:11:44\n",
      "epoch: 20/200 | trn loss: 0.5094 | val loss: 1.0465 | val accuracy: 67.2276% \n",
      "\n",
      "2020/11/25 01:13:19\n",
      "epoch: 21/200 | trn loss: 0.5054 | val loss: 0.9792 | val accuracy: 68.2442% \n",
      "\n",
      "2020/11/25 01:14:53\n",
      "epoch: 22/200 | trn loss: 0.4901 | val loss: 0.9478 | val accuracy: 69.0605% \n",
      "\n",
      "2020/11/25 01:16:27\n",
      "epoch: 23/200 | trn loss: 0.4824 | val loss: 0.9774 | val accuracy: 68.6999% \n",
      "\n",
      "2020/11/25 01:18:01\n",
      "epoch: 24/200 | trn loss: 0.4680 | val loss: 0.9691 | val accuracy: 68.1741% \n",
      "\n",
      "2020/11/25 01:19:36\n",
      "epoch: 25/200 | trn loss: 0.4587 | val loss: 1.0036 | val accuracy: 68.2192% \n",
      "\n",
      "2020/11/25 01:21:10\n",
      "epoch: 26/200 | trn loss: 0.4484 | val loss: 1.0030 | val accuracy: 67.9537% \n",
      "\n",
      "2020/11/25 01:22:44\n",
      "epoch: 27/200 | trn loss: 0.4487 | val loss: 0.9956 | val accuracy: 68.9653% \n",
      "\n",
      "2020/11/25 01:24:18\n",
      "epoch: 28/200 | trn loss: 0.4334 | val loss: 0.9854 | val accuracy: 68.6198% \n",
      "\n",
      "2020/11/25 01:25:52\n",
      "epoch: 29/200 | trn loss: 0.4286 | val loss: 0.9791 | val accuracy: 69.0004% \n",
      "\n",
      "2020/11/25 01:27:27\n",
      "epoch: 30/200 | trn loss: 0.4166 | val loss: 1.0235 | val accuracy: 67.7634% \n",
      "\n",
      "2020/11/25 01:29:02\n",
      "epoch: 31/200 | trn loss: 0.3032 | val loss: 0.8704 | val accuracy: 72.8916% \n",
      "\n",
      "Model replaced and saved as  /home/jupyter-deeplearning/res_model/Custom_model_2.0_0.870\n",
      "2020/11/25 01:30:37\n",
      "epoch: 32/200 | trn loss: 0.2582 | val loss: 0.9053 | val accuracy: 73.0319% \n",
      "\n",
      "2020/11/25 01:32:11\n",
      "epoch: 33/200 | trn loss: 0.2501 | val loss: 0.9090 | val accuracy: 72.9868% \n",
      "\n",
      "2020/11/25 01:33:45\n",
      "epoch: 34/200 | trn loss: 0.2412 | val loss: 0.8994 | val accuracy: 73.6428% \n",
      "\n",
      "2020/11/25 01:35:19\n",
      "epoch: 35/200 | trn loss: 0.2350 | val loss: 0.9098 | val accuracy: 73.6929% \n",
      "\n",
      "2020/11/25 01:36:53\n",
      "epoch: 36/200 | trn loss: 0.2276 | val loss: 0.9350 | val accuracy: 73.1170% \n",
      "\n",
      "2020/11/25 01:38:28\n",
      "epoch: 37/200 | trn loss: 0.2240 | val loss: 0.9402 | val accuracy: 73.1320% \n",
      "\n",
      "2020/11/25 01:40:02\n",
      "epoch: 38/200 | trn loss: 0.2166 | val loss: 0.9242 | val accuracy: 73.6679% \n",
      "\n",
      "2020/11/25 01:41:36\n",
      "epoch: 39/200 | trn loss: 0.2136 | val loss: 0.9617 | val accuracy: 73.4776% \n",
      "\n",
      "2020/11/25 01:43:10\n",
      "epoch: 40/200 | trn loss: 0.2115 | val loss: 0.9453 | val accuracy: 73.3323% \n",
      "\n",
      "2020/11/25 01:44:44\n",
      "epoch: 41/200 | trn loss: 0.2047 | val loss: 0.9641 | val accuracy: 73.2422% \n",
      "\n",
      "2020/11/25 01:46:18\n",
      "epoch: 42/200 | trn loss: 0.2055 | val loss: 0.9567 | val accuracy: 73.2071% \n",
      "\n",
      "2020/11/25 01:47:53\n",
      "epoch: 43/200 | trn loss: 0.2025 | val loss: 0.9606 | val accuracy: 73.2171% \n",
      "\n",
      "2020/11/25 01:49:26\n",
      "epoch: 44/200 | trn loss: 0.2019 | val loss: 0.9376 | val accuracy: 74.1887% \n",
      "\n",
      "2020/11/25 01:51:02\n",
      "epoch: 45/200 | trn loss: 0.2013 | val loss: 0.9518 | val accuracy: 73.9133% \n",
      "\n",
      "2020/11/25 01:52:36\n",
      "epoch: 46/200 | trn loss: 0.1939 | val loss: 0.9617 | val accuracy: 73.3824% \n",
      "\n",
      "2020/11/25 01:54:11\n",
      "epoch: 47/200 | trn loss: 0.1939 | val loss: 0.9809 | val accuracy: 73.3423% \n",
      "\n",
      "2020/11/25 01:55:45\n",
      "epoch: 48/200 | trn loss: 0.1903 | val loss: 1.0058 | val accuracy: 72.9467% \n",
      "\n",
      "2020/11/25 01:57:19\n",
      "epoch: 49/200 | trn loss: 0.1860 | val loss: 0.9616 | val accuracy: 73.6128% \n",
      "\n",
      "2020/11/25 01:58:53\n",
      "epoch: 50/200 | trn loss: 0.1915 | val loss: 0.9688 | val accuracy: 73.4225% \n",
      "\n",
      "2020/11/25 02:00:27\n",
      "epoch: 51/200 | trn loss: 0.1863 | val loss: 0.9685 | val accuracy: 73.4024% \n",
      "\n",
      "2020/11/25 02:02:02\n",
      "epoch: 52/200 | trn loss: 0.1788 | val loss: 0.9776 | val accuracy: 73.6328% \n",
      "\n",
      "2020/11/25 02:03:36\n",
      "epoch: 53/200 | trn loss: 0.1848 | val loss: 0.9825 | val accuracy: 73.4525% \n",
      "\n",
      "2020/11/25 02:05:10\n",
      "epoch: 54/200 | trn loss: 0.1784 | val loss: 0.9768 | val accuracy: 73.3874% \n",
      "\n",
      "2020/11/25 02:06:45\n",
      "epoch: 55/200 | trn loss: 0.1816 | val loss: 0.9750 | val accuracy: 73.8081% \n",
      "\n",
      "2020/11/25 02:08:20\n",
      "epoch: 56/200 | trn loss: 0.1795 | val loss: 0.9803 | val accuracy: 73.5527% \n",
      "\n",
      "2020/11/25 02:09:54\n",
      "epoch: 57/200 | trn loss: 0.1767 | val loss: 0.9720 | val accuracy: 73.5727% \n",
      "\n",
      "2020/11/25 02:11:29\n",
      "epoch: 58/200 | trn loss: 0.1744 | val loss: 0.9870 | val accuracy: 73.2422% \n",
      "\n",
      "2020/11/25 02:13:03\n",
      "epoch: 59/200 | trn loss: 0.1773 | val loss: 0.9799 | val accuracy: 73.7129% \n",
      "\n",
      "2020/11/25 02:14:38\n",
      "epoch: 60/200 | trn loss: 0.1706 | val loss: 1.0101 | val accuracy: 73.5677% \n",
      "\n",
      "2020/11/25 02:16:12\n",
      "epoch: 61/200 | trn loss: 0.1625 | val loss: 0.9804 | val accuracy: 73.8331% \n",
      "\n",
      "2020/11/25 02:17:47\n",
      "epoch: 62/200 | trn loss: 0.1612 | val loss: 0.9780 | val accuracy: 73.8431% \n",
      "\n",
      "2020/11/25 02:19:21\n",
      "epoch: 63/200 | trn loss: 0.1601 | val loss: 0.9830 | val accuracy: 74.0184% \n",
      "\n",
      "2020/11/25 02:20:56\n",
      "epoch: 64/200 | trn loss: 0.1525 | val loss: 0.9719 | val accuracy: 74.1787% \n",
      "\n",
      "2020/11/25 02:22:30\n",
      "epoch: 65/200 | trn loss: 0.1544 | val loss: 0.9824 | val accuracy: 73.8081% \n",
      "\n",
      "2020/11/25 02:24:05\n",
      "epoch: 66/200 | trn loss: 0.1520 | val loss: 0.9753 | val accuracy: 74.1236% \n",
      "\n",
      "2020/11/25 02:25:39\n",
      "epoch: 67/200 | trn loss: 0.1525 | val loss: 0.9892 | val accuracy: 73.9483% \n",
      "\n",
      "2020/11/25 02:27:13\n",
      "epoch: 68/200 | trn loss: 0.1554 | val loss: 0.9739 | val accuracy: 74.1687% \n",
      "\n",
      "2020/11/25 02:28:48\n",
      "epoch: 69/200 | trn loss: 0.1527 | val loss: 0.9911 | val accuracy: 73.9683% \n",
      "\n",
      "2020/11/25 02:30:22\n",
      "epoch: 70/200 | trn loss: 0.1523 | val loss: 0.9950 | val accuracy: 73.6979% \n",
      "\n",
      "2020/11/25 02:31:56\n",
      "epoch: 71/200 | trn loss: 0.1491 | val loss: 0.9805 | val accuracy: 74.1286% \n",
      "\n",
      "2020/11/25 02:33:29\n",
      "epoch: 72/200 | trn loss: 0.1501 | val loss: 0.9782 | val accuracy: 73.7380% \n",
      "\n",
      "2020/11/25 02:35:04\n",
      "epoch: 73/200 | trn loss: 0.1476 | val loss: 0.9909 | val accuracy: 73.6779% \n",
      "\n",
      "2020/11/25 02:36:37\n",
      "epoch: 74/200 | trn loss: 0.1486 | val loss: 0.9782 | val accuracy: 74.4141% \n",
      "\n",
      "2020/11/25 02:38:12\n",
      "epoch: 75/200 | trn loss: 0.1486 | val loss: 0.9750 | val accuracy: 74.5192% \n",
      "\n",
      "2020/11/25 02:39:47\n",
      "epoch: 76/200 | trn loss: 0.1464 | val loss: 0.9920 | val accuracy: 73.9884% \n",
      "\n",
      "2020/11/25 02:41:20\n",
      "epoch: 77/200 | trn loss: 0.1487 | val loss: 1.0018 | val accuracy: 73.8031% \n",
      "\n",
      "2020/11/25 02:42:55\n",
      "epoch: 78/200 | trn loss: 0.1439 | val loss: 0.9968 | val accuracy: 73.9884% \n",
      "\n",
      "2020/11/25 02:44:30\n",
      "epoch: 79/200 | trn loss: 0.1453 | val loss: 0.9771 | val accuracy: 74.3590% \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020/11/25 02:46:04\n",
      "epoch: 80/200 | trn loss: 0.1469 | val loss: 0.9725 | val accuracy: 74.7847% \n",
      "\n",
      "2020/11/25 02:47:38\n",
      "epoch: 81/200 | trn loss: 0.1507 | val loss: 0.9871 | val accuracy: 74.2188% \n",
      "\n",
      "2020/11/25 02:49:12\n",
      "epoch: 82/200 | trn loss: 0.1464 | val loss: 0.9753 | val accuracy: 74.2238% \n",
      "\n",
      "2020/11/25 02:50:47\n",
      "epoch: 83/200 | trn loss: 0.1469 | val loss: 0.9754 | val accuracy: 74.6595% \n",
      "\n",
      "2020/11/25 02:52:21\n",
      "epoch: 84/200 | trn loss: 0.1435 | val loss: 0.9778 | val accuracy: 74.1687% \n",
      "\n",
      "2020/11/25 02:53:55\n",
      "epoch: 85/200 | trn loss: 0.1423 | val loss: 0.9964 | val accuracy: 73.5727% \n",
      "\n",
      "2020/11/25 02:55:30\n",
      "epoch: 86/200 | trn loss: 0.1488 | val loss: 0.9917 | val accuracy: 74.4842% \n",
      "\n",
      "2020/11/25 02:57:04\n",
      "epoch: 87/200 | trn loss: 0.1469 | val loss: 0.9777 | val accuracy: 74.3389% \n",
      "\n",
      "2020/11/25 02:58:38\n",
      "epoch: 88/200 | trn loss: 0.1486 | val loss: 0.9922 | val accuracy: 74.0986% \n",
      "\n",
      "2020/11/25 03:00:12\n",
      "epoch: 89/200 | trn loss: 0.1485 | val loss: 0.9758 | val accuracy: 74.2788% \n",
      "\n",
      "2020/11/25 03:01:47\n",
      "epoch: 90/200 | trn loss: 0.1434 | val loss: 1.0004 | val accuracy: 74.1687% \n",
      "\n",
      "2020/11/25 03:03:21\n",
      "epoch: 91/200 | trn loss: 0.1417 | val loss: 0.9857 | val accuracy: 74.1336% \n",
      "\n",
      "2020/11/25 03:04:56\n",
      "epoch: 92/200 | trn loss: 0.1416 | val loss: 0.9768 | val accuracy: 74.3890% \n",
      "\n",
      "2020/11/25 03:06:30\n",
      "epoch: 93/200 | trn loss: 0.1466 | val loss: 0.9852 | val accuracy: 74.2538% \n",
      "\n",
      "2020/11/25 03:08:03\n",
      "epoch: 94/200 | trn loss: 0.1427 | val loss: 1.0001 | val accuracy: 73.6078% \n",
      "\n",
      "2020/11/25 03:09:36\n",
      "epoch: 95/200 | trn loss: 0.1433 | val loss: 1.0047 | val accuracy: 73.9233% \n",
      "\n",
      "2020/11/25 03:11:07\n",
      "epoch: 96/200 | trn loss: 0.1450 | val loss: 0.9912 | val accuracy: 74.0485% \n",
      "\n",
      "2020/11/25 03:12:38\n",
      "epoch: 97/200 | trn loss: 0.1442 | val loss: 0.9908 | val accuracy: 74.2688% \n",
      "\n",
      "2020/11/25 03:14:08\n",
      "epoch: 98/200 | trn loss: 0.1425 | val loss: 0.9816 | val accuracy: 74.1136% \n",
      "\n",
      "2020/11/25 03:15:38\n",
      "epoch: 99/200 | trn loss: 0.1430 | val loss: 0.9850 | val accuracy: 73.8882% \n",
      "\n",
      "2020/11/25 03:17:09\n",
      "epoch: 100/200 | trn loss: 0.1434 | val loss: 1.0031 | val accuracy: 74.0485% \n",
      "\n",
      "2020/11/25 03:18:40\n",
      "epoch: 101/200 | trn loss: 0.1411 | val loss: 0.9885 | val accuracy: 74.0284% \n",
      "\n",
      "2020/11/25 03:20:11\n",
      "epoch: 102/200 | trn loss: 0.1462 | val loss: 0.9909 | val accuracy: 74.1036% \n",
      "\n",
      "2020/11/25 03:21:42\n",
      "epoch: 103/200 | trn loss: 0.1450 | val loss: 1.0077 | val accuracy: 73.6228% \n",
      "\n",
      "2020/11/25 03:23:13\n",
      "epoch: 104/200 | trn loss: 0.1430 | val loss: 0.9891 | val accuracy: 73.8682% \n",
      "\n",
      "2020/11/25 03:24:45\n",
      "epoch: 105/200 | trn loss: 0.1455 | val loss: 0.9685 | val accuracy: 74.1687% \n",
      "\n",
      "2020/11/25 03:26:17\n",
      "epoch: 106/200 | trn loss: 0.1438 | val loss: 0.9987 | val accuracy: 74.1036% \n",
      "\n",
      "2020/11/25 03:27:49\n",
      "epoch: 107/200 | trn loss: 0.1395 | val loss: 1.0063 | val accuracy: 73.6679% \n",
      "\n",
      "2020/11/25 03:29:20\n",
      "epoch: 108/200 | trn loss: 0.1413 | val loss: 0.9919 | val accuracy: 74.3840% \n",
      "\n",
      "2020/11/25 03:30:51\n",
      "epoch: 109/200 | trn loss: 0.1393 | val loss: 0.9911 | val accuracy: 74.3740% \n",
      "\n",
      "2020/11/25 03:32:23\n",
      "epoch: 110/200 | trn loss: 0.1445 | val loss: 0.9861 | val accuracy: 74.0885% \n",
      "\n",
      "2020/11/25 03:33:54\n",
      "epoch: 111/200 | trn loss: 0.1407 | val loss: 0.9972 | val accuracy: 74.2788% \n",
      "\n",
      "2020/11/25 03:35:25\n",
      "epoch: 112/200 | trn loss: 0.1408 | val loss: 0.9969 | val accuracy: 73.8682% \n",
      "\n",
      "2020/11/25 03:36:56\n",
      "epoch: 113/200 | trn loss: 0.1446 | val loss: 0.9957 | val accuracy: 73.8331% \n",
      "\n",
      "2020/11/25 03:38:28\n",
      "epoch: 114/200 | trn loss: 0.1424 | val loss: 0.9885 | val accuracy: 74.1186% \n",
      "\n",
      "2020/11/25 03:39:59\n",
      "epoch: 115/200 | trn loss: 0.1403 | val loss: 0.9728 | val accuracy: 74.1286% \n",
      "\n",
      "2020/11/25 03:41:30\n",
      "epoch: 116/200 | trn loss: 0.1435 | val loss: 0.9963 | val accuracy: 74.2839% \n",
      "\n",
      "2020/11/25 03:43:02\n",
      "epoch: 117/200 | trn loss: 0.1404 | val loss: 0.9729 | val accuracy: 74.5543% \n",
      "\n",
      "2020/11/25 03:44:33\n",
      "epoch: 118/200 | trn loss: 0.1416 | val loss: 0.9980 | val accuracy: 74.1536% \n",
      "\n",
      "2020/11/25 03:46:04\n",
      "epoch: 119/200 | trn loss: 0.1426 | val loss: 0.9958 | val accuracy: 73.6779% \n",
      "\n",
      "2020/11/25 03:47:35\n",
      "epoch: 120/200 | trn loss: 0.1425 | val loss: 0.9735 | val accuracy: 74.4141% \n",
      "\n",
      "2020/11/25 03:49:06\n",
      "epoch: 121/200 | trn loss: 0.1425 | val loss: 1.0078 | val accuracy: 74.0986% \n",
      "\n",
      "2020/11/25 03:50:38\n",
      "epoch: 122/200 | trn loss: 0.1404 | val loss: 0.9986 | val accuracy: 73.9734% \n",
      "\n",
      "2020/11/25 03:52:09\n",
      "epoch: 123/200 | trn loss: 0.1393 | val loss: 1.0128 | val accuracy: 73.6679% \n",
      "\n",
      "2020/11/25 03:53:40\n",
      "epoch: 124/200 | trn loss: 0.1426 | val loss: 1.0141 | val accuracy: 73.4675% \n",
      "\n",
      "2020/11/25 03:55:11\n",
      "epoch: 125/200 | trn loss: 0.1397 | val loss: 0.9943 | val accuracy: 74.0284% \n",
      "\n",
      "2020/11/25 03:56:42\n",
      "epoch: 126/200 | trn loss: 0.1408 | val loss: 0.9751 | val accuracy: 74.3540% \n",
      "\n",
      "2020/11/25 03:58:14\n",
      "epoch: 127/200 | trn loss: 0.1376 | val loss: 0.9750 | val accuracy: 74.4491% \n",
      "\n",
      "2020/11/25 03:59:45\n",
      "epoch: 128/200 | trn loss: 0.1420 | val loss: 0.9830 | val accuracy: 73.9784% \n",
      "\n",
      "2020/11/25 04:01:15\n",
      "epoch: 129/200 | trn loss: 0.1426 | val loss: 0.9921 | val accuracy: 74.3990% \n",
      "\n",
      "2020/11/25 04:02:47\n",
      "epoch: 130/200 | trn loss: 0.1425 | val loss: 0.9916 | val accuracy: 74.0184% \n",
      "\n",
      "2020/11/25 04:04:18\n",
      "epoch: 131/200 | trn loss: 0.1414 | val loss: 0.9841 | val accuracy: 74.0084% \n",
      "\n",
      "2020/11/25 04:05:49\n",
      "epoch: 132/200 | trn loss: 0.1408 | val loss: 0.9742 | val accuracy: 73.9383% \n",
      "\n",
      "2020/11/25 04:07:20\n",
      "epoch: 133/200 | trn loss: 0.1438 | val loss: 0.9881 | val accuracy: 74.0635% \n",
      "\n",
      "2020/11/25 04:08:52\n",
      "epoch: 134/200 | trn loss: 0.1408 | val loss: 0.9833 | val accuracy: 74.2788% \n",
      "\n",
      "2020/11/25 04:10:24\n",
      "epoch: 135/200 | trn loss: 0.1420 | val loss: 0.9942 | val accuracy: 74.0184% \n",
      "\n",
      "2020/11/25 04:11:55\n",
      "epoch: 136/200 | trn loss: 0.1397 | val loss: 0.9914 | val accuracy: 74.0485% \n",
      "\n",
      "2020/11/25 04:13:27\n",
      "epoch: 137/200 | trn loss: 0.1386 | val loss: 0.9878 | val accuracy: 74.1937% \n",
      "\n",
      "2020/11/25 04:14:59\n",
      "epoch: 138/200 | trn loss: 0.1425 | val loss: 0.9910 | val accuracy: 74.3189% \n",
      "\n",
      "2020/11/25 04:16:30\n",
      "epoch: 139/200 | trn loss: 0.1408 | val loss: 0.9863 | val accuracy: 74.1637% \n",
      "\n",
      "2020/11/25 04:18:01\n",
      "epoch: 140/200 | trn loss: 0.1419 | val loss: 0.9812 | val accuracy: 74.3189% \n",
      "\n",
      "2020/11/25 04:19:33\n",
      "epoch: 141/200 | trn loss: 0.1415 | val loss: 0.9858 | val accuracy: 74.0184% \n",
      "\n",
      "2020/11/25 04:21:05\n",
      "epoch: 142/200 | trn loss: 0.1400 | val loss: 0.9894 | val accuracy: 74.2388% \n",
      "\n",
      "2020/11/25 04:22:36\n",
      "epoch: 143/200 | trn loss: 0.1403 | val loss: 1.0080 | val accuracy: 73.8782% \n",
      "\n",
      "2020/11/25 04:24:08\n",
      "epoch: 144/200 | trn loss: 0.1467 | val loss: 0.9818 | val accuracy: 74.3339% \n",
      "\n",
      "2020/11/25 04:25:39\n",
      "epoch: 145/200 | trn loss: 0.1404 | val loss: 0.9697 | val accuracy: 74.4942% \n",
      "\n",
      "2020/11/25 04:27:10\n",
      "epoch: 146/200 | trn loss: 0.1428 | val loss: 0.9781 | val accuracy: 74.5743% \n",
      "\n",
      "2020/11/25 04:28:41\n",
      "epoch: 147/200 | trn loss: 0.1379 | val loss: 0.9967 | val accuracy: 74.3740% \n",
      "\n",
      "2020/11/25 04:30:13\n",
      "epoch: 148/200 | trn loss: 0.1419 | val loss: 0.9980 | val accuracy: 74.2087% \n",
      "\n",
      "2020/11/25 04:31:44\n",
      "epoch: 149/200 | trn loss: 0.1395 | val loss: 0.9880 | val accuracy: 74.0485% \n",
      "\n",
      "2020/11/25 04:33:15\n",
      "epoch: 150/200 | trn loss: 0.1403 | val loss: 0.9896 | val accuracy: 73.9233% \n",
      "\n",
      "2020/11/25 04:34:46\n",
      "epoch: 151/200 | trn loss: 0.1439 | val loss: 1.0060 | val accuracy: 73.9333% \n",
      "\n",
      "2020/11/25 04:36:18\n",
      "epoch: 152/200 | trn loss: 0.1377 | val loss: 1.0047 | val accuracy: 73.9734% \n",
      "\n",
      "2020/11/25 04:37:49\n",
      "epoch: 153/200 | trn loss: 0.1384 | val loss: 0.9657 | val accuracy: 74.6544% \n",
      "\n",
      "2020/11/25 04:39:21\n",
      "epoch: 154/200 | trn loss: 0.1379 | val loss: 0.9989 | val accuracy: 74.2388% \n",
      "\n",
      "2020/11/25 04:40:52\n",
      "epoch: 155/200 | trn loss: 0.1418 | val loss: 0.9885 | val accuracy: 74.1236% \n",
      "\n",
      "2020/11/25 04:42:23\n",
      "epoch: 156/200 | trn loss: 0.1421 | val loss: 0.9902 | val accuracy: 74.5142% \n",
      "\n",
      "2020/11/25 04:43:54\n",
      "epoch: 157/200 | trn loss: 0.1416 | val loss: 1.0133 | val accuracy: 73.4375% \n",
      "\n",
      "2020/11/25 04:45:26\n",
      "epoch: 158/200 | trn loss: 0.1410 | val loss: 0.9932 | val accuracy: 74.1687% \n",
      "\n",
      "2020/11/25 04:46:57\n",
      "epoch: 159/200 | trn loss: 0.1459 | val loss: 1.0023 | val accuracy: 74.2889% \n",
      "\n",
      "2020/11/25 04:48:28\n",
      "epoch: 160/200 | trn loss: 0.1421 | val loss: 0.9719 | val accuracy: 74.3289% \n",
      "\n",
      "2020/11/25 04:49:59\n",
      "epoch: 161/200 | trn loss: 0.1431 | val loss: 0.9936 | val accuracy: 74.0234% \n",
      "\n",
      "2020/11/25 04:51:30\n",
      "epoch: 162/200 | trn loss: 0.1420 | val loss: 0.9925 | val accuracy: 74.1386% \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020/11/25 04:53:03\n",
      "epoch: 163/200 | trn loss: 0.1393 | val loss: 0.9788 | val accuracy: 74.4441% \n",
      "\n",
      "2020/11/25 04:54:34\n",
      "epoch: 164/200 | trn loss: 0.1444 | val loss: 0.9715 | val accuracy: 74.6695% \n",
      "\n",
      "2020/11/25 04:56:04\n",
      "epoch: 165/200 | trn loss: 0.1430 | val loss: 0.9766 | val accuracy: 74.6494% \n",
      "\n",
      "2020/11/25 04:57:35\n",
      "epoch: 166/200 | trn loss: 0.1371 | val loss: 1.0165 | val accuracy: 73.6779% \n",
      "\n",
      "2020/11/25 04:59:07\n",
      "epoch: 167/200 | trn loss: 0.1433 | val loss: 1.0040 | val accuracy: 73.8381% \n",
      "\n",
      "2020/11/25 05:00:38\n",
      "epoch: 168/200 | trn loss: 0.1402 | val loss: 0.9983 | val accuracy: 74.0585% \n",
      "\n",
      "2020/11/25 05:02:10\n",
      "epoch: 169/200 | trn loss: 0.1405 | val loss: 0.9860 | val accuracy: 74.2588% \n",
      "\n",
      "2020/11/25 05:03:42\n",
      "epoch: 170/200 | trn loss: 0.1423 | val loss: 0.9747 | val accuracy: 74.4441% \n",
      "\n",
      "2020/11/25 05:05:13\n",
      "epoch: 171/200 | trn loss: 0.1371 | val loss: 0.9987 | val accuracy: 73.9483% \n",
      "\n",
      "2020/11/25 05:06:44\n",
      "epoch: 172/200 | trn loss: 0.1435 | val loss: 0.9860 | val accuracy: 74.6795% \n",
      "\n",
      "2020/11/25 05:08:15\n",
      "epoch: 173/200 | trn loss: 0.1412 | val loss: 0.9951 | val accuracy: 73.9032% \n",
      "\n",
      "2020/11/25 05:09:46\n",
      "epoch: 174/200 | trn loss: 0.1392 | val loss: 1.0119 | val accuracy: 74.0585% \n",
      "\n",
      "2020/11/25 05:11:18\n",
      "epoch: 175/200 | trn loss: 0.1414 | val loss: 0.9919 | val accuracy: 74.0635% \n",
      "\n",
      "2020/11/25 05:12:50\n",
      "epoch: 176/200 | trn loss: 0.1432 | val loss: 0.9639 | val accuracy: 74.3990% \n",
      "\n",
      "2020/11/25 05:14:21\n",
      "epoch: 177/200 | trn loss: 0.1394 | val loss: 0.9858 | val accuracy: 74.3990% \n",
      "\n",
      "2020/11/25 05:15:53\n",
      "epoch: 178/200 | trn loss: 0.1403 | val loss: 0.9879 | val accuracy: 74.7696% \n",
      "\n",
      "2020/11/25 05:17:24\n",
      "epoch: 179/200 | trn loss: 0.1424 | val loss: 0.9935 | val accuracy: 74.4291% \n",
      "\n",
      "2020/11/25 05:18:54\n",
      "epoch: 180/200 | trn loss: 0.1414 | val loss: 1.0080 | val accuracy: 73.6478% \n",
      "\n",
      "2020/11/25 05:20:25\n",
      "epoch: 181/200 | trn loss: 0.1437 | val loss: 0.9890 | val accuracy: 74.2989% \n",
      "\n",
      "2020/11/25 05:21:56\n",
      "epoch: 182/200 | trn loss: 0.1419 | val loss: 0.9779 | val accuracy: 74.1637% \n",
      "\n",
      "2020/11/25 05:23:28\n",
      "epoch: 183/200 | trn loss: 0.1413 | val loss: 0.9936 | val accuracy: 74.1837% \n",
      "\n",
      "2020/11/25 05:24:59\n",
      "epoch: 184/200 | trn loss: 0.1434 | val loss: 0.9865 | val accuracy: 74.1787% \n",
      "\n",
      "2020/11/25 05:26:31\n",
      "epoch: 185/200 | trn loss: 0.1411 | val loss: 1.0064 | val accuracy: 74.0284% \n",
      "\n",
      "2020/11/25 05:28:02\n",
      "epoch: 186/200 | trn loss: 0.1403 | val loss: 0.9908 | val accuracy: 74.1436% \n",
      "\n",
      "2020/11/25 05:29:33\n",
      "epoch: 187/200 | trn loss: 0.1413 | val loss: 1.0062 | val accuracy: 73.8832% \n",
      "\n",
      "2020/11/25 05:31:05\n",
      "epoch: 188/200 | trn loss: 0.1418 | val loss: 0.9849 | val accuracy: 74.8047% \n",
      "\n",
      "2020/11/25 05:32:36\n",
      "epoch: 189/200 | trn loss: 0.1415 | val loss: 0.9768 | val accuracy: 74.1987% \n",
      "\n",
      "2020/11/25 05:34:07\n",
      "epoch: 190/200 | trn loss: 0.1401 | val loss: 0.9725 | val accuracy: 74.2087% \n",
      "\n",
      "2020/11/25 05:35:38\n",
      "epoch: 191/200 | trn loss: 0.1386 | val loss: 0.9806 | val accuracy: 74.6394% \n",
      "\n",
      "2020/11/25 05:37:09\n",
      "epoch: 192/200 | trn loss: 0.1447 | val loss: 0.9910 | val accuracy: 74.3590% \n",
      "\n",
      "2020/11/25 05:38:40\n",
      "epoch: 193/200 | trn loss: 0.1401 | val loss: 0.9923 | val accuracy: 74.0935% \n",
      "\n",
      "2020/11/25 05:40:11\n",
      "epoch: 194/200 | trn loss: 0.1430 | val loss: 0.9961 | val accuracy: 74.0535% \n",
      "\n",
      "2020/11/25 05:41:43\n",
      "epoch: 195/200 | trn loss: 0.1420 | val loss: 0.9960 | val accuracy: 73.9533% \n",
      "\n",
      "2020/11/25 05:43:14\n",
      "epoch: 196/200 | trn loss: 0.1372 | val loss: 0.9912 | val accuracy: 73.9333% \n",
      "\n",
      "2020/11/25 05:44:45\n",
      "epoch: 197/200 | trn loss: 0.1410 | val loss: 0.9887 | val accuracy: 74.1687% \n",
      "\n",
      "2020/11/25 05:46:16\n",
      "epoch: 198/200 | trn loss: 0.1411 | val loss: 0.9950 | val accuracy: 73.7480% \n",
      "\n",
      "2020/11/25 05:47:47\n",
      "epoch: 199/200 | trn loss: 0.1446 | val loss: 0.9788 | val accuracy: 74.4541% \n",
      "\n",
      "2020/11/25 05:49:18\n",
      "epoch: 200/200 | trn loss: 0.1406 | val loss: 0.9841 | val accuracy: 74.2839% \n",
      "\n"
     ]
    }
   ],
   "source": [
    "saving_path=\"/home/jupyter-deeplearning/res_model/\"\n",
    "trn_loss_list = []\n",
    "val_loss_list = []\n",
    "val_acc_list = []\n",
    "total_epoch=200\n",
    "model_char=\"2.0\"\n",
    "model_name=\"\"\n",
    "patience=10\n",
    "start_early_stop_check=0\n",
    "saving_start_epoch=10\n",
    "\n",
    "for epoch in range(total_epoch):\n",
    "    trn_loss = 0.0\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        inputs, labels = data\n",
    "        if torch.cuda.is_available():\n",
    "            inputs=inputs.cuda()\n",
    "            labels=labels.cuda()\n",
    "        # grad init\n",
    "        optimizer.zero_grad()\n",
    "        # forward propagation\n",
    "        output= model(inputs)\n",
    "        # calculate loss\n",
    "        loss=criterion(output, labels)\n",
    "        # back propagation \n",
    "        loss.backward()\n",
    "        # weight update\n",
    "        optimizer.step()\n",
    "        \n",
    "        # trn_loss summary\n",
    "        trn_loss += loss.item()\n",
    "        # del (memory issue)\n",
    "        del loss\n",
    "        del output\n",
    "    with torch.no_grad():\n",
    "        val_loss = 0.0\n",
    "        cor_match = 0\n",
    "        for j, val in enumerate(test_loader):\n",
    "            val_x, val_label = val\n",
    "            if torch.cuda.is_available():\n",
    "                val_x = val_x.cuda()\n",
    "                val_label =val_label.cuda()\n",
    "            val_output = model(val_x)\n",
    "            v_loss = criterion(val_output, val_label)\n",
    "            val_loss += v_loss\n",
    "            _, predicted=torch.max(val_output,1)\n",
    "            cor_match+=np.count_nonzero(predicted.cpu().detach()==val_label.cpu().detach())\n",
    "    del val_output\n",
    "    del v_loss\n",
    "    del predicted\n",
    "    \n",
    "    scheduler.step()\n",
    "    \n",
    "    \n",
    "    \n",
    "    trn_loss_list.append(trn_loss/len(train_loader))\n",
    "    val_loss_list.append(val_loss/len(test_loader))\n",
    "    val_acc=cor_match/(len(test_loader)*batch_size)\n",
    "    val_acc_list.append(val_acc)\n",
    "    now = time.localtime()\n",
    "    print (\"%04d/%02d/%02d %02d:%02d:%02d\" % (now.tm_year, now.tm_mon, now.tm_mday, now.tm_hour, now.tm_min, now.tm_sec))\n",
    "\n",
    "    print(\"epoch: {}/{} | trn loss: {:.4f} | val loss: {:.4f} | val accuracy: {:.4f}% \\n\".format(\n",
    "                epoch+1, total_epoch, trn_loss / len(train_loader), val_loss / len(test_loader), val_acc*100\n",
    "            ))\n",
    "    \n",
    "    \n",
    "    if epoch+1>2:\n",
    "        if val_loss_list[-1]>val_loss_list[-2]:\n",
    "            start_early_stop_check=1\n",
    "    else:\n",
    "        val_loss_min=val_loss_list[-1]\n",
    "        \n",
    "    if start_early_stop_check:\n",
    "        early_stop_temp=val_loss_list[-patience:]\n",
    "        if all(early_stop_temp[i]<early_stop_temp[i+1] for i in range (len(early_stop_temp)-1)):\n",
    "            print(\"Early stop!\")\n",
    "            break\n",
    "            \n",
    "    if epoch+1>saving_start_epoch:\n",
    "        if val_loss_list[-1]<val_loss_min:\n",
    "            if os.path.isfile(model_name):\n",
    "                os.remove(model_name)\n",
    "            val_loss_min=val_loss_list[-1]\n",
    "            model_name=saving_path+\"Custom_model_\"+model_char+\"_{:.3f}\".format(val_loss_min)\n",
    "            torch.save(model, model_name)\n",
    "            print(\"Model replaced and saved as \",model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=64\n",
    "dataset = datasets.ImageFolder(\n",
    "        train_path_path,\n",
    "        transforms.Compose([\n",
    "        transforms.RandomRotation(degrees=45),\n",
    "        transforms.Resize(120),    \n",
    "        transforms.ColorJitter(.3,.3,.3,.3),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "            transforms.RandomVerticalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "            normalize,\n",
    "        ]))\n",
    "for _ in range (19):\n",
    "    aug_data = datasets.ImageFolder(\n",
    "        train_path_path,\n",
    "        transforms.Compose([\n",
    "        transforms.RandomRotation(degrees=45),\n",
    "        transforms.Resize(120),    \n",
    "        transforms.ColorJitter(.3,.3,.3,.3),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "            transforms.RandomVerticalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "            normalize,\n",
    "        ]))\n",
    "    dataset=torch.utils.data.ConcatDataset([dataset,aug_data])\n",
    "valset = datasets.ImageFolder(\n",
    "        test_path_path,\n",
    "        transforms.Compose([\n",
    "        transforms.RandomRotation(degrees=45),\n",
    "        transforms.Resize(120),\n",
    "        transforms.ColorJitter(.3,.3,.3,.3),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "            transforms.RandomVerticalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "            normalize,\n",
    "        ]))\n",
    "for _ in range (19):\n",
    "    aug_data = datasets.ImageFolder(\n",
    "        test_path_path,\n",
    "        transforms.Compose([\n",
    "        transforms.RandomRotation(degrees=45),\n",
    "        transforms.Resize(120),    \n",
    "        transforms.ColorJitter(.3,.3,.3,.3),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "            transforms.RandomVerticalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "            normalize,\n",
    "        ]))\n",
    "    valset=torch.utils.data.ConcatDataset([valset,aug_data])\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "        dataset, batch_size=batch_size, shuffle=True,\n",
    "        num_workers=8, pin_memory=True,drop_last=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "        valset, batch_size=batch_size, shuffle=True,\n",
    "        num_workers=8, pin_memory=True,drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=1e-4)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020/11/25 05:52:59\n",
      "epoch: 1/80 | trn loss: 0.1396 | val loss: 0.7628 | val accuracy: 78.2252% \n",
      "\n",
      "2020/11/25 05:56:41\n",
      "epoch: 2/80 | trn loss: 0.1178 | val loss: 0.8382 | val accuracy: 76.9832% \n",
      "\n",
      "2020/11/25 06:00:23\n",
      "epoch: 3/80 | trn loss: 0.1099 | val loss: 0.7795 | val accuracy: 78.8812% \n",
      "\n",
      "2020/11/25 06:04:04\n",
      "epoch: 4/80 | trn loss: 0.1011 | val loss: 0.7501 | val accuracy: 80.0631% \n",
      "\n",
      "2020/11/25 06:07:45\n",
      "epoch: 5/80 | trn loss: 0.0957 | val loss: 0.7833 | val accuracy: 79.3269% \n",
      "\n",
      "2020/11/25 06:11:26\n",
      "epoch: 6/80 | trn loss: 0.0932 | val loss: 0.7905 | val accuracy: 79.7025% \n",
      "\n",
      "2020/11/25 06:15:07\n",
      "epoch: 7/80 | trn loss: 0.0879 | val loss: 0.8409 | val accuracy: 78.4004% \n",
      "\n",
      "2020/11/25 06:18:49\n",
      "epoch: 8/80 | trn loss: 0.0859 | val loss: 0.7634 | val accuracy: 79.7676% \n",
      "\n",
      "2020/11/25 06:22:29\n",
      "epoch: 9/80 | trn loss: 0.0841 | val loss: 0.8216 | val accuracy: 78.6208% \n",
      "\n",
      "2020/11/25 06:26:11\n",
      "epoch: 10/80 | trn loss: 0.0788 | val loss: 0.8297 | val accuracy: 79.2418% \n",
      "\n",
      "2020/11/25 06:29:51\n",
      "epoch: 11/80 | trn loss: 0.0755 | val loss: 0.8533 | val accuracy: 79.0014% \n",
      "\n",
      "2020/11/25 06:33:32\n",
      "epoch: 12/80 | trn loss: 0.0746 | val loss: 0.8813 | val accuracy: 78.7560% \n",
      "\n",
      "2020/11/25 06:37:12\n",
      "epoch: 13/80 | trn loss: 0.0730 | val loss: 0.8263 | val accuracy: 78.8411% \n",
      "\n",
      "Model replaced and saved as  Custom_model_2.0_0.826\n",
      "2020/11/25 06:40:53\n",
      "epoch: 14/80 | trn loss: 0.0703 | val loss: 0.8472 | val accuracy: 79.2668% \n",
      "\n",
      "2020/11/25 06:44:34\n",
      "epoch: 15/80 | trn loss: 0.0682 | val loss: 0.8254 | val accuracy: 79.8427% \n",
      "\n",
      "Model replaced and saved as  Custom_model_2.0_0.825\n",
      "2020/11/25 06:48:14\n",
      "epoch: 16/80 | trn loss: 0.0720 | val loss: 0.8863 | val accuracy: 78.1951% \n",
      "\n",
      "2020/11/25 06:51:56\n",
      "epoch: 17/80 | trn loss: 0.0679 | val loss: 0.8081 | val accuracy: 80.0331% \n",
      "\n",
      "Model replaced and saved as  Custom_model_2.0_0.808\n",
      "2020/11/25 06:55:36\n",
      "epoch: 18/80 | trn loss: 0.0664 | val loss: 0.8633 | val accuracy: 78.6458% \n",
      "\n",
      "2020/11/25 06:59:16\n",
      "epoch: 19/80 | trn loss: 0.0664 | val loss: 0.9022 | val accuracy: 77.5040% \n",
      "\n",
      "2020/11/25 07:02:57\n",
      "epoch: 20/80 | trn loss: 0.0636 | val loss: 0.9846 | val accuracy: 76.6877% \n",
      "\n",
      "2020/11/25 07:06:37\n",
      "epoch: 21/80 | trn loss: 0.0139 | val loss: 0.7081 | val accuracy: 82.6322% \n",
      "\n",
      "Model replaced and saved as  Custom_model_2.0_0.708\n",
      "2020/11/25 07:10:18\n",
      "epoch: 22/80 | trn loss: 0.0047 | val loss: 0.7057 | val accuracy: 82.9677% \n",
      "\n",
      "Model replaced and saved as  Custom_model_2.0_0.706\n",
      "2020/11/25 07:13:58\n",
      "epoch: 23/80 | trn loss: 0.0039 | val loss: 0.7257 | val accuracy: 82.7925% \n",
      "\n",
      "2020/11/25 07:17:39\n",
      "epoch: 24/80 | trn loss: 0.0030 | val loss: 0.7098 | val accuracy: 83.0980% \n",
      "\n",
      "2020/11/25 07:21:19\n",
      "epoch: 25/80 | trn loss: 0.0029 | val loss: 0.7124 | val accuracy: 83.2282% \n",
      "\n",
      "2020/11/25 07:24:59\n",
      "epoch: 26/80 | trn loss: 0.0034 | val loss: 0.7449 | val accuracy: 82.8025% \n",
      "\n",
      "2020/11/25 07:28:39\n",
      "epoch: 27/80 | trn loss: 0.0027 | val loss: 0.7217 | val accuracy: 82.8225% \n",
      "\n",
      "2020/11/25 07:32:19\n",
      "epoch: 28/80 | trn loss: 0.0028 | val loss: 0.7208 | val accuracy: 82.9978% \n",
      "\n",
      "2020/11/25 07:35:59\n",
      "epoch: 29/80 | trn loss: 0.0032 | val loss: 0.7424 | val accuracy: 82.5321% \n",
      "\n",
      "2020/11/25 07:39:39\n",
      "epoch: 30/80 | trn loss: 0.0027 | val loss: 0.7065 | val accuracy: 82.8325% \n",
      "\n",
      "2020/11/25 07:43:22\n",
      "epoch: 31/80 | trn loss: 0.0022 | val loss: 0.7275 | val accuracy: 82.5771% \n",
      "\n",
      "2020/11/25 07:47:02\n",
      "epoch: 32/80 | trn loss: 0.0033 | val loss: 0.7501 | val accuracy: 82.0162% \n",
      "\n",
      "2020/11/25 07:50:42\n",
      "epoch: 33/80 | trn loss: 0.0030 | val loss: 0.7300 | val accuracy: 82.3167% \n",
      "\n",
      "2020/11/25 07:54:22\n",
      "epoch: 34/80 | trn loss: 0.0025 | val loss: 0.7509 | val accuracy: 82.3518% \n",
      "\n",
      "2020/11/25 07:58:02\n",
      "epoch: 35/80 | trn loss: 0.0030 | val loss: 0.7399 | val accuracy: 82.1615% \n",
      "\n",
      "2020/11/25 08:01:43\n",
      "epoch: 36/80 | trn loss: 0.0023 | val loss: 0.7794 | val accuracy: 82.3067% \n",
      "\n",
      "2020/11/25 08:05:23\n",
      "epoch: 37/80 | trn loss: 0.0040 | val loss: 0.7614 | val accuracy: 81.9211% \n",
      "\n",
      "2020/11/25 08:09:04\n",
      "epoch: 38/80 | trn loss: 0.0025 | val loss: 0.7489 | val accuracy: 82.4820% \n",
      "\n",
      "2020/11/25 08:12:44\n",
      "epoch: 39/80 | trn loss: 0.0032 | val loss: 0.7057 | val accuracy: 82.5721% \n",
      "\n",
      "Model replaced and saved as  Custom_model_2.0_0.706\n",
      "2020/11/25 08:16:25\n",
      "epoch: 40/80 | trn loss: 0.0027 | val loss: 0.7855 | val accuracy: 81.5054% \n",
      "\n",
      "2020/11/25 08:20:04\n",
      "epoch: 41/80 | trn loss: 0.0023 | val loss: 0.7378 | val accuracy: 82.7624% \n",
      "\n",
      "2020/11/25 08:23:45\n",
      "epoch: 42/80 | trn loss: 0.0015 | val loss: 0.7222 | val accuracy: 82.9427% \n",
      "\n",
      "2020/11/25 08:27:25\n",
      "epoch: 43/80 | trn loss: 0.0011 | val loss: 0.7134 | val accuracy: 82.8776% \n",
      "\n",
      "2020/11/25 08:31:04\n",
      "epoch: 44/80 | trn loss: 0.0012 | val loss: 0.7158 | val accuracy: 82.8876% \n",
      "\n",
      "2020/11/25 08:34:44\n",
      "epoch: 45/80 | trn loss: 0.0010 | val loss: 0.7056 | val accuracy: 83.1931% \n",
      "\n",
      "Model replaced and saved as  Custom_model_2.0_0.706\n",
      "2020/11/25 08:38:24\n",
      "epoch: 46/80 | trn loss: 0.0009 | val loss: 0.7045 | val accuracy: 82.9026% \n",
      "\n",
      "Model replaced and saved as  Custom_model_2.0_0.705\n",
      "2020/11/25 08:42:05\n",
      "epoch: 47/80 | trn loss: 0.0009 | val loss: 0.7208 | val accuracy: 82.6372% \n",
      "\n",
      "2020/11/25 08:45:46\n",
      "epoch: 48/80 | trn loss: 0.0009 | val loss: 0.6978 | val accuracy: 82.9177% \n",
      "\n",
      "Model replaced and saved as  Custom_model_2.0_0.698\n",
      "2020/11/25 08:49:27\n",
      "epoch: 49/80 | trn loss: 0.0008 | val loss: 0.6900 | val accuracy: 83.0228% \n",
      "\n",
      "Model replaced and saved as  Custom_model_2.0_0.690\n",
      "2020/11/25 08:53:09\n",
      "epoch: 50/80 | trn loss: 0.0009 | val loss: 0.6933 | val accuracy: 82.9077% \n",
      "\n",
      "2020/11/25 08:56:49\n",
      "epoch: 51/80 | trn loss: 0.0008 | val loss: 0.6917 | val accuracy: 82.9026% \n",
      "\n",
      "2020/11/25 09:00:31\n",
      "epoch: 52/80 | trn loss: 0.0009 | val loss: 0.6843 | val accuracy: 83.2382% \n",
      "\n",
      "Model replaced and saved as  Custom_model_2.0_0.684\n",
      "2020/11/25 09:04:11\n",
      "epoch: 53/80 | trn loss: 0.0008 | val loss: 0.6923 | val accuracy: 83.4886% \n",
      "\n",
      "2020/11/25 09:07:51\n",
      "epoch: 54/80 | trn loss: 0.0008 | val loss: 0.6707 | val accuracy: 83.4034% \n",
      "\n",
      "Model replaced and saved as  Custom_model_2.0_0.671\n",
      "2020/11/25 09:11:31\n",
      "epoch: 55/80 | trn loss: 0.0010 | val loss: 0.6630 | val accuracy: 83.1530% \n",
      "\n",
      "Model replaced and saved as  Custom_model_2.0_0.663\n",
      "2020/11/25 09:15:11\n",
      "epoch: 56/80 | trn loss: 0.0009 | val loss: 0.6791 | val accuracy: 83.1180% \n",
      "\n",
      "2020/11/25 09:18:51\n",
      "epoch: 57/80 | trn loss: 0.0009 | val loss: 0.6618 | val accuracy: 83.3333% \n",
      "\n",
      "Model replaced and saved as  Custom_model_2.0_0.662\n",
      "2020/11/25 09:22:31\n",
      "epoch: 58/80 | trn loss: 0.0009 | val loss: 0.6643 | val accuracy: 83.2682% \n",
      "\n",
      "2020/11/25 09:26:11\n",
      "epoch: 59/80 | trn loss: 0.0008 | val loss: 0.6618 | val accuracy: 83.3433% \n",
      "\n",
      "2020/11/25 09:29:53\n",
      "epoch: 60/80 | trn loss: 0.0009 | val loss: 0.6659 | val accuracy: 83.1530% \n",
      "\n",
      "2020/11/25 09:33:33\n",
      "epoch: 61/80 | trn loss: 0.0010 | val loss: 0.6685 | val accuracy: 83.1731% \n",
      "\n",
      "2020/11/25 09:37:14\n",
      "epoch: 62/80 | trn loss: 0.0009 | val loss: 0.6700 | val accuracy: 83.2131% \n",
      "\n",
      "2020/11/25 09:40:53\n",
      "epoch: 63/80 | trn loss: 0.0009 | val loss: 0.6678 | val accuracy: 83.1881% \n",
      "\n",
      "2020/11/25 09:44:34\n",
      "epoch: 64/80 | trn loss: 0.0009 | val loss: 0.6616 | val accuracy: 83.1581% \n",
      "\n",
      "Model replaced and saved as  Custom_model_2.0_0.662\n",
      "2020/11/25 09:48:14\n",
      "epoch: 65/80 | trn loss: 0.0009 | val loss: 0.6741 | val accuracy: 82.7574% \n",
      "\n",
      "2020/11/25 09:51:54\n",
      "epoch: 66/80 | trn loss: 0.0009 | val loss: 0.6730 | val accuracy: 82.8926% \n",
      "\n",
      "2020/11/25 09:55:33\n",
      "epoch: 67/80 | trn loss: 0.0008 | val loss: 0.6695 | val accuracy: 82.9978% \n",
      "\n",
      "2020/11/25 09:59:13\n",
      "epoch: 68/80 | trn loss: 0.0009 | val loss: 0.6626 | val accuracy: 83.3734% \n",
      "\n",
      "2020/11/25 10:02:52\n",
      "epoch: 69/80 | trn loss: 0.0009 | val loss: 0.6712 | val accuracy: 82.8526% \n",
      "\n",
      "2020/11/25 10:06:33\n",
      "epoch: 70/80 | trn loss: 0.0008 | val loss: 0.6695 | val accuracy: 83.2732% \n",
      "\n",
      "2020/11/25 10:10:12\n",
      "epoch: 71/80 | trn loss: 0.0008 | val loss: 0.6571 | val accuracy: 83.3133% \n",
      "\n",
      "Model replaced and saved as  Custom_model_2.0_0.657\n",
      "2020/11/25 10:13:52\n",
      "epoch: 72/80 | trn loss: 0.0009 | val loss: 0.6598 | val accuracy: 83.2282% \n",
      "\n",
      "2020/11/25 10:17:30\n",
      "epoch: 73/80 | trn loss: 0.0008 | val loss: 0.6713 | val accuracy: 83.0579% \n",
      "\n",
      "2020/11/25 10:21:08\n",
      "epoch: 74/80 | trn loss: 0.0008 | val loss: 0.6749 | val accuracy: 83.0879% \n",
      "\n",
      "2020/11/25 10:24:45\n",
      "epoch: 75/80 | trn loss: 0.0008 | val loss: 0.6587 | val accuracy: 83.0729% \n",
      "\n",
      "2020/11/25 10:28:24\n",
      "epoch: 76/80 | trn loss: 0.0009 | val loss: 0.6556 | val accuracy: 83.2582% \n",
      "\n",
      "Model replaced and saved as  Custom_model_2.0_0.656\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020/11/25 10:32:03\n",
      "epoch: 77/80 | trn loss: 0.0008 | val loss: 0.6637 | val accuracy: 82.9277% \n",
      "\n",
      "2020/11/25 10:35:42\n",
      "epoch: 78/80 | trn loss: 0.0008 | val loss: 0.6650 | val accuracy: 82.9427% \n",
      "\n",
      "2020/11/25 10:39:20\n",
      "epoch: 79/80 | trn loss: 0.0008 | val loss: 0.6588 | val accuracy: 83.3283% \n",
      "\n",
      "2020/11/25 10:42:59\n",
      "epoch: 80/80 | trn loss: 0.0008 | val loss: 0.6567 | val accuracy: 83.1430% \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#fine tuning\n",
    "\n",
    "total_epoch=80\n",
    "model_char=\"2.0\"\n",
    "model_name=\"\"\n",
    "patience=10\n",
    "start_early_stop_check=0\n",
    "saving_start_epoch=10\n",
    "\n",
    "for epoch in range(total_epoch):\n",
    "    trn_loss = 0.0\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        inputs, labels = data\n",
    "        if torch.cuda.is_available():\n",
    "            inputs=inputs.cuda()\n",
    "            labels=labels.cuda()\n",
    "        # grad init\n",
    "        optimizer.zero_grad()\n",
    "        # forward propagation\n",
    "        output= model(inputs)\n",
    "        # calculate loss\n",
    "        loss=criterion(output, labels)\n",
    "        # back propagation \n",
    "        loss.backward()\n",
    "        # weight update\n",
    "        optimizer.step()\n",
    "        \n",
    "        # trn_loss summary\n",
    "        trn_loss += loss.item()\n",
    "        # del (memory issue)\n",
    "        del loss\n",
    "        del output\n",
    "    with torch.no_grad():\n",
    "        val_loss = 0.0\n",
    "        cor_match = 0\n",
    "        for j, val in enumerate(test_loader):\n",
    "            val_x, val_label = val\n",
    "            if torch.cuda.is_available():\n",
    "                val_x = val_x.cuda()\n",
    "                val_label =val_label.cuda()\n",
    "            val_output = model(val_x)\n",
    "            v_loss = criterion(val_output, val_label)\n",
    "            val_loss += v_loss\n",
    "            _, predicted=torch.max(val_output,1)\n",
    "            cor_match+=np.count_nonzero(predicted.cpu().detach()==val_label.cpu().detach())\n",
    "    del val_output\n",
    "    del v_loss\n",
    "    del predicted\n",
    "    \n",
    "    scheduler.step()\n",
    "    \n",
    "    \n",
    "    \n",
    "    trn_loss_list.append(trn_loss/len(train_loader))\n",
    "    val_loss_list.append(val_loss/len(test_loader))\n",
    "    val_acc=cor_match/(len(test_loader)*batch_size)\n",
    "    val_acc_list.append(val_acc)\n",
    "    now = time.localtime()\n",
    "    print (\"%04d/%02d/%02d %02d:%02d:%02d\" % (now.tm_year, now.tm_mon, now.tm_mday, now.tm_hour, now.tm_min, now.tm_sec))\n",
    "\n",
    "    print(\"epoch: {}/{} | trn loss: {:.4f} | val loss: {:.4f} | val accuracy: {:.4f}% \\n\".format(\n",
    "                epoch+1, total_epoch, trn_loss / len(train_loader), val_loss / len(test_loader), val_acc*100\n",
    "            ))\n",
    "    \n",
    "    \n",
    "    if epoch+1>2:\n",
    "        if val_loss_list[-1]>val_loss_list[-2]:\n",
    "            start_early_stop_check=1\n",
    "    else:\n",
    "        val_loss_min=val_loss_list[-1]\n",
    "        \n",
    "    if start_early_stop_check:\n",
    "        early_stop_temp=val_loss_list[-patience:]\n",
    "        if all(early_stop_temp[i]<early_stop_temp[i+1] for i in range (len(early_stop_temp)-1)):\n",
    "            print(\"Early stop!\")\n",
    "            break\n",
    "            \n",
    "    if epoch+1>saving_start_epoch:\n",
    "        if val_loss_list[-1]<val_loss_min:\n",
    "            if os.path.isfile(model_name):\n",
    "                os.remove(model_name)\n",
    "            val_loss_min=val_loss_list[-1]\n",
    "            model_name=\"Custom_model_\"+model_char+\"_{:.3f}\".format(val_loss_min)\n",
    "            torch.save(model, model_name)\n",
    "            print(\"Model replaced and saved as \",model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x1080 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(15,15))\n",
    "plt.ylabel(\"val_accuracy\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.plot(val_acc_list)\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# val_acc_list=np.array(val_acc_list)\n",
    "# np.savetxt(\"ver_2.0.txt\", val_acc_list, delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import pandas as pd\n",
    "# import argparse\n",
    "# import time\n",
    "# import torchvision\n",
    "# import torchvision.transforms as transforms\n",
    "# from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize = transforms.Normalize(mean=[0.507, 0.487, 0.441],\n",
    "#                                      std=[0.267, 0.256, 0.276])\n",
    "# test_transform = transforms.Compose([\n",
    "#         transforms.ToTensor(),\n",
    "#         normalize\n",
    "#     ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_dataset = torchvision.datasets.ImageFolder('./data/test', transform=test_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_loader = DataLoader(test_dataset, batch_size=batch_size, num_workers=4, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Category = []\n",
    "# for input, _ in test_loader:\n",
    "#     input = input.cuda()\n",
    "#     output = model(input)\n",
    "#     output = torch.argmax(output, dim=1)\n",
    "#     Category = Category + output.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Id = list(range(0, 8000))\n",
    "# samples = {\n",
    "#    'Id': Id,\n",
    "#    'Category': Category \n",
    "# }\n",
    "# df = pd.DataFrame(samples, columns=['Id', 'Category'])\n",
    "\n",
    "# df.to_csv('submission_2.0_2.csv', index=False)\n",
    "# print('Done!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
