{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import shutil\n",
    "import torch.distributed as dist\n",
    "import math\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from glob import glob\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from typing import Type, Any, Callable, Union, List, Optional\n",
    "from torch import Tensor\n",
    "from torch.hub import load_state_dict_from_url\n",
    "from torch.utils.data.dataloader import default_collate\n",
    "from torch.utils.data.sampler import BatchSampler\n",
    "from collections.abc import Mapping, Sequence\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path_path= f\"./data/split_train/train\"\n",
    "test_path_path= f\"./data/split_train/val\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=128\n",
    "num_gpus=4\n",
    "num_workers=64\n",
    "lr=0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize = transforms.Normalize(mean=[0.507, 0.487, 0.441],\n",
    "                                     std=[0.267, 0.256, 0.276])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = datasets.ImageFolder(\n",
    "        train_path_path,\n",
    "        transforms.Compose([\n",
    "        transforms.RandomRotation(degrees=45),\n",
    "            \n",
    "        transforms.RandomResizedCrop(70),\n",
    "        transforms.ColorJitter(.3,.3,.3,.3),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "            normalize,\n",
    "        ]))\n",
    "for _ in range (19):\n",
    "    aug_data = datasets.ImageFolder(\n",
    "        train_path_path,\n",
    "        transforms.Compose([\n",
    "        transforms.RandomRotation(degrees=45),\n",
    "            \n",
    "        transforms.RandomResizedCrop(70),\n",
    "        transforms.ColorJitter(.3,.3,.3,.3),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "            normalize,\n",
    "        ]))\n",
    "    dataset=torch.utils.data.ConcatDataset([dataset,aug_data])\n",
    "valset = datasets.ImageFolder(\n",
    "        test_path_path,\n",
    "        transforms.Compose([\n",
    "        transforms.RandomRotation(degrees=45),\n",
    "            \n",
    "        transforms.RandomResizedCrop(70),\n",
    "        transforms.ColorJitter(.3,.3,.3,.3),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "            normalize,\n",
    "        ]))\n",
    "for _ in range (19):\n",
    "    aug_data = datasets.ImageFolder(\n",
    "        test_path_path,\n",
    "        transforms.Compose([\n",
    "        transforms.RandomRotation(degrees=45),\n",
    "            \n",
    "        transforms.RandomResizedCrop(70),\n",
    "        transforms.ColorJitter(.3,.3,.3,.3),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "            normalize,\n",
    "        ]))\n",
    "    valset=torch.utils.data.ConcatDataset([valset,aug_data])\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "        dataset, batch_size=batch_size, shuffle=True,\n",
    "        num_workers=8, pin_memory=True,drop_last=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "        valset, batch_size=batch_size, shuffle=True,\n",
    "        num_workers=8, pin_memory=True,drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv3x3(in_planes, out_planes, stride=1, groups=1, dilation=1):\n",
    "    \"\"\"3x3 convolution with padding\"\"\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
    "                     padding=dilation, groups=groups, bias=False, dilation=dilation)\n",
    "\n",
    "\n",
    "def conv1x1(in_planes, out_planes, stride=1):\n",
    "    \"\"\"1x1 convolution\"\"\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Bottleneck(nn.Module):\n",
    "    # Bottleneck in torchvision places the stride for downsampling at 3x3 convolution(self.conv2)\n",
    "    # while original implementation places the stride at the first 1x1 convolution(self.conv1)\n",
    "    # according to \"Deep residual learning for image recognition\"https://arxiv.org/abs/1512.03385.\n",
    "    # This variant is also known as ResNet V1.5 and improves accuracy according to\n",
    "    # https://ngc.nvidia.com/catalog/model-scripts/nvidia:resnet_50_v1_5_for_pytorch.\n",
    "\n",
    "    expansion: int = 4\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        inplanes: int,\n",
    "        planes: int,\n",
    "        stride: int = 1,\n",
    "        downsample: Optional[nn.Module] = None,\n",
    "        groups: int = 1,\n",
    "        base_width: int = 64,\n",
    "        dilation: int = 1,\n",
    "        norm_layer: Optional[Callable[..., nn.Module]] = None\n",
    "    ) -> None:\n",
    "        super(Bottleneck, self).__init__()\n",
    "        if norm_layer is None:\n",
    "            norm_layer = nn.BatchNorm2d\n",
    "        width = int(planes * (base_width / 64.)) * groups\n",
    "        # Both self.conv2 and self.downsample layers downsample the input when stride != 1\n",
    "        self.conv1 = conv1x1(inplanes, width)\n",
    "        self.bn1 = norm_layer(width)\n",
    "        self.conv2 = conv3x3(width, width, stride, groups, dilation)\n",
    "        self.bn2 = norm_layer(width)\n",
    "        self.conv3 = conv1x1(width, planes * self.expansion)\n",
    "        self.bn3 = norm_layer(planes * self.expansion)\n",
    "        self.relu = nn.LeakyReLU(0.1)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        identity = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "\n",
    "        out += identity\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        block: Type[Union[Bottleneck]],\n",
    "        layers: List[int],\n",
    "        num_classes: int = 10,\n",
    "        zero_init_residual: bool = False,\n",
    "        groups: int = 1,\n",
    "        width_per_group: int = 64,\n",
    "        replace_stride_with_dilation: Optional[List[bool]] = None,\n",
    "        norm_layer: Optional[Callable[..., nn.Module]] = None\n",
    "    ) -> None:\n",
    "        super(ResNet, self).__init__()\n",
    "        if norm_layer is None:\n",
    "            norm_layer = nn.BatchNorm2d\n",
    "        self._norm_layer = norm_layer\n",
    "\n",
    "        self.inplanes = 64\n",
    "        self.dilation = 1\n",
    "        if replace_stride_with_dilation is None:\n",
    "            # each element in the tuple indicates if we should replace\n",
    "            # the 2x2 stride with a dilated convolution instead\n",
    "            replace_stride_with_dilation = [False, False, False]\n",
    "        if len(replace_stride_with_dilation) != 3:\n",
    "            raise ValueError(\"replace_stride_with_dilation should be None \"\n",
    "                             \"or a 3-element tuple, got {}\".format(replace_stride_with_dilation))\n",
    "        self.groups = groups\n",
    "        self.base_width = width_per_group\n",
    "        self.conv1 = nn.Conv2d(3, self.inplanes, kernel_size=4, stride=1,\n",
    "                               bias=False)\n",
    "        self.bn1 = norm_layer(self.inplanes)\n",
    "        self.relu = nn.LeakyReLU(0.1)\n",
    "        \n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.layer1 = self._make_layer(block, 30, layers[0])\n",
    "        self.layer2 = self._make_layer(block, 60, layers[1], stride=2,\n",
    "                                       dilate=replace_stride_with_dilation[0])\n",
    "        self.layer3 = self._make_layer(block, 96, layers[2], stride=2,\n",
    "                                       dilate=replace_stride_with_dilation[1])\n",
    "        \n",
    "        \n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(96 * block.expansion, num_classes)\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='leaky_relu')\n",
    "            elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "        # Zero-initialize the last BN in each residual branch,\n",
    "        # so that the residual branch starts with zeros, and each residual block behaves like an identity.\n",
    "        # This improves the model by 0.2~0.3% according to https://arxiv.org/abs/1706.02677\n",
    "        if zero_init_residual:\n",
    "            for m in self.modules():\n",
    "                if isinstance(m, Bottleneck):\n",
    "                    nn.init.constant_(m.bn3.weight, 0)  # type: ignore[arg-type]\n",
    "\n",
    "    def _make_layer(self, block: Type[Union[Bottleneck]], planes: int, blocks: int,\n",
    "                    stride: int = 1, dilate: bool = False) -> nn.Sequential:\n",
    "        norm_layer = self._norm_layer\n",
    "        downsample = None\n",
    "        previous_dilation = self.dilation\n",
    "        if dilate:\n",
    "            self.dilation *= stride\n",
    "            stride = 1\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                conv1x1(self.inplanes, planes * block.expansion, stride),\n",
    "                norm_layer(planes * block.expansion),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, stride, downsample, self.groups,\n",
    "                            self.base_width, previous_dilation, norm_layer))\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for _ in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes, groups=self.groups,\n",
    "                                base_width=self.base_width, dilation=self.dilation,\n",
    "                                norm_layer=norm_layer))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def _forward_impl(self, x: Tensor) -> Tensor:\n",
    "        # See note [TorchScript super()]\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x,1)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        return self._forward_impl(x)\n",
    "\n",
    "\n",
    "def _resnet(\n",
    "    arch: str,\n",
    "    block: Type[Union[Bottleneck]],\n",
    "    layers: List[int],\n",
    "    pretrained: bool,\n",
    "    progress: bool,\n",
    "    **kwargs: Any\n",
    ") -> ResNet:\n",
    "    model = ResNet(block, layers, **kwargs)\n",
    "    if pretrained:\n",
    "        state_dict = load_state_dict_from_url(model_urls[arch],\n",
    "                                              progress=progress)\n",
    "        model.load_state_dict(state_dict)\n",
    "    return model\n",
    "\n",
    "def _resnext(arch, block, layers, pretrained, progress, **kwargs):\n",
    "    model = ResNet(block, layers, **kwargs)\n",
    "    if pretrained:\n",
    "        state_dict = load_state_dict_from_url(model_urls[arch], progress=progress)\n",
    "        model.load_state_dict(state_dict)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Model(pretrained: bool = False, progress: bool = True, **kwargs):\n",
    "    \n",
    "    kwargs['groups'] = 1\n",
    "    kwargs['width_per_group'] = 64\n",
    "    return _resnext('resnext', Bottleneck, [4, 9, 8], pretrained, progress, **kwargs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LabelSmoothingLoss(nn.Module):\n",
    "    def __init__(self, classes, smoothing=0.1, dim=-1):\n",
    "        super(LabelSmoothingLoss, self).__init__()\n",
    "        self.confidence = 1.0 - smoothing\n",
    "        self.smoothing = smoothing\n",
    "        self.cls = classes\n",
    "        self.dim = dim\n",
    "    def forward(self, pred, target):\n",
    "        pred = pred.log_softmax(dim=self.dim)\n",
    "        with torch.no_grad():\n",
    "            true_dist = torch.zeros_like(pred)\n",
    "            true_dist.fill_(self.smoothing / (self.cls - 1))\n",
    "            true_dist.scatter_(1, target.data.unsqueeze(1), self.confidence)\n",
    "        return torch.mean(torch.sum(-true_dist * pred, dim=self.dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model()\n",
    "model = model.cuda()\n",
    "criterion = nn.CrossEntropyLoss().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for name, param in model.named_parameters():\n",
    "#     if param.requires_grad:\n",
    "#         print (name, param.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 64, 93, 93]           3,072\n",
      "       BatchNorm2d-2           [-1, 64, 93, 93]             128\n",
      "         LeakyReLU-3           [-1, 64, 93, 93]               0\n",
      "         MaxPool2d-4           [-1, 64, 46, 46]               0\n",
      "            Conv2d-5           [-1, 30, 46, 46]           1,920\n",
      "       BatchNorm2d-6           [-1, 30, 46, 46]              60\n",
      "         LeakyReLU-7           [-1, 30, 46, 46]               0\n",
      "            Conv2d-8           [-1, 30, 46, 46]           8,100\n",
      "       BatchNorm2d-9           [-1, 30, 46, 46]              60\n",
      "        LeakyReLU-10           [-1, 30, 46, 46]               0\n",
      "           Conv2d-11          [-1, 120, 46, 46]           3,600\n",
      "      BatchNorm2d-12          [-1, 120, 46, 46]             240\n",
      "           Conv2d-13          [-1, 120, 46, 46]           7,680\n",
      "      BatchNorm2d-14          [-1, 120, 46, 46]             240\n",
      "        LeakyReLU-15          [-1, 120, 46, 46]               0\n",
      "       Bottleneck-16          [-1, 120, 46, 46]               0\n",
      "           Conv2d-17           [-1, 30, 46, 46]           3,600\n",
      "      BatchNorm2d-18           [-1, 30, 46, 46]              60\n",
      "        LeakyReLU-19           [-1, 30, 46, 46]               0\n",
      "           Conv2d-20           [-1, 30, 46, 46]           8,100\n",
      "      BatchNorm2d-21           [-1, 30, 46, 46]              60\n",
      "        LeakyReLU-22           [-1, 30, 46, 46]               0\n",
      "           Conv2d-23          [-1, 120, 46, 46]           3,600\n",
      "      BatchNorm2d-24          [-1, 120, 46, 46]             240\n",
      "        LeakyReLU-25          [-1, 120, 46, 46]               0\n",
      "       Bottleneck-26          [-1, 120, 46, 46]               0\n",
      "           Conv2d-27           [-1, 30, 46, 46]           3,600\n",
      "      BatchNorm2d-28           [-1, 30, 46, 46]              60\n",
      "        LeakyReLU-29           [-1, 30, 46, 46]               0\n",
      "           Conv2d-30           [-1, 30, 46, 46]           8,100\n",
      "      BatchNorm2d-31           [-1, 30, 46, 46]              60\n",
      "        LeakyReLU-32           [-1, 30, 46, 46]               0\n",
      "           Conv2d-33          [-1, 120, 46, 46]           3,600\n",
      "      BatchNorm2d-34          [-1, 120, 46, 46]             240\n",
      "        LeakyReLU-35          [-1, 120, 46, 46]               0\n",
      "       Bottleneck-36          [-1, 120, 46, 46]               0\n",
      "           Conv2d-37           [-1, 30, 46, 46]           3,600\n",
      "      BatchNorm2d-38           [-1, 30, 46, 46]              60\n",
      "        LeakyReLU-39           [-1, 30, 46, 46]               0\n",
      "           Conv2d-40           [-1, 30, 46, 46]           8,100\n",
      "      BatchNorm2d-41           [-1, 30, 46, 46]              60\n",
      "        LeakyReLU-42           [-1, 30, 46, 46]               0\n",
      "           Conv2d-43          [-1, 120, 46, 46]           3,600\n",
      "      BatchNorm2d-44          [-1, 120, 46, 46]             240\n",
      "        LeakyReLU-45          [-1, 120, 46, 46]               0\n",
      "       Bottleneck-46          [-1, 120, 46, 46]               0\n",
      "           Conv2d-47           [-1, 60, 46, 46]           7,200\n",
      "      BatchNorm2d-48           [-1, 60, 46, 46]             120\n",
      "        LeakyReLU-49           [-1, 60, 46, 46]               0\n",
      "           Conv2d-50           [-1, 60, 23, 23]          32,400\n",
      "      BatchNorm2d-51           [-1, 60, 23, 23]             120\n",
      "        LeakyReLU-52           [-1, 60, 23, 23]               0\n",
      "           Conv2d-53          [-1, 240, 23, 23]          14,400\n",
      "      BatchNorm2d-54          [-1, 240, 23, 23]             480\n",
      "           Conv2d-55          [-1, 240, 23, 23]          28,800\n",
      "      BatchNorm2d-56          [-1, 240, 23, 23]             480\n",
      "        LeakyReLU-57          [-1, 240, 23, 23]               0\n",
      "       Bottleneck-58          [-1, 240, 23, 23]               0\n",
      "           Conv2d-59           [-1, 60, 23, 23]          14,400\n",
      "      BatchNorm2d-60           [-1, 60, 23, 23]             120\n",
      "        LeakyReLU-61           [-1, 60, 23, 23]               0\n",
      "           Conv2d-62           [-1, 60, 23, 23]          32,400\n",
      "      BatchNorm2d-63           [-1, 60, 23, 23]             120\n",
      "        LeakyReLU-64           [-1, 60, 23, 23]               0\n",
      "           Conv2d-65          [-1, 240, 23, 23]          14,400\n",
      "      BatchNorm2d-66          [-1, 240, 23, 23]             480\n",
      "        LeakyReLU-67          [-1, 240, 23, 23]               0\n",
      "       Bottleneck-68          [-1, 240, 23, 23]               0\n",
      "           Conv2d-69           [-1, 60, 23, 23]          14,400\n",
      "      BatchNorm2d-70           [-1, 60, 23, 23]             120\n",
      "        LeakyReLU-71           [-1, 60, 23, 23]               0\n",
      "           Conv2d-72           [-1, 60, 23, 23]          32,400\n",
      "      BatchNorm2d-73           [-1, 60, 23, 23]             120\n",
      "        LeakyReLU-74           [-1, 60, 23, 23]               0\n",
      "           Conv2d-75          [-1, 240, 23, 23]          14,400\n",
      "      BatchNorm2d-76          [-1, 240, 23, 23]             480\n",
      "        LeakyReLU-77          [-1, 240, 23, 23]               0\n",
      "       Bottleneck-78          [-1, 240, 23, 23]               0\n",
      "           Conv2d-79           [-1, 60, 23, 23]          14,400\n",
      "      BatchNorm2d-80           [-1, 60, 23, 23]             120\n",
      "        LeakyReLU-81           [-1, 60, 23, 23]               0\n",
      "           Conv2d-82           [-1, 60, 23, 23]          32,400\n",
      "      BatchNorm2d-83           [-1, 60, 23, 23]             120\n",
      "        LeakyReLU-84           [-1, 60, 23, 23]               0\n",
      "           Conv2d-85          [-1, 240, 23, 23]          14,400\n",
      "      BatchNorm2d-86          [-1, 240, 23, 23]             480\n",
      "        LeakyReLU-87          [-1, 240, 23, 23]               0\n",
      "       Bottleneck-88          [-1, 240, 23, 23]               0\n",
      "           Conv2d-89           [-1, 60, 23, 23]          14,400\n",
      "      BatchNorm2d-90           [-1, 60, 23, 23]             120\n",
      "        LeakyReLU-91           [-1, 60, 23, 23]               0\n",
      "           Conv2d-92           [-1, 60, 23, 23]          32,400\n",
      "      BatchNorm2d-93           [-1, 60, 23, 23]             120\n",
      "        LeakyReLU-94           [-1, 60, 23, 23]               0\n",
      "           Conv2d-95          [-1, 240, 23, 23]          14,400\n",
      "      BatchNorm2d-96          [-1, 240, 23, 23]             480\n",
      "        LeakyReLU-97          [-1, 240, 23, 23]               0\n",
      "       Bottleneck-98          [-1, 240, 23, 23]               0\n",
      "           Conv2d-99           [-1, 60, 23, 23]          14,400\n",
      "     BatchNorm2d-100           [-1, 60, 23, 23]             120\n",
      "       LeakyReLU-101           [-1, 60, 23, 23]               0\n",
      "          Conv2d-102           [-1, 60, 23, 23]          32,400\n",
      "     BatchNorm2d-103           [-1, 60, 23, 23]             120\n",
      "       LeakyReLU-104           [-1, 60, 23, 23]               0\n",
      "          Conv2d-105          [-1, 240, 23, 23]          14,400\n",
      "     BatchNorm2d-106          [-1, 240, 23, 23]             480\n",
      "       LeakyReLU-107          [-1, 240, 23, 23]               0\n",
      "      Bottleneck-108          [-1, 240, 23, 23]               0\n",
      "          Conv2d-109           [-1, 60, 23, 23]          14,400\n",
      "     BatchNorm2d-110           [-1, 60, 23, 23]             120\n",
      "       LeakyReLU-111           [-1, 60, 23, 23]               0\n",
      "          Conv2d-112           [-1, 60, 23, 23]          32,400\n",
      "     BatchNorm2d-113           [-1, 60, 23, 23]             120\n",
      "       LeakyReLU-114           [-1, 60, 23, 23]               0\n",
      "          Conv2d-115          [-1, 240, 23, 23]          14,400\n",
      "     BatchNorm2d-116          [-1, 240, 23, 23]             480\n",
      "       LeakyReLU-117          [-1, 240, 23, 23]               0\n",
      "      Bottleneck-118          [-1, 240, 23, 23]               0\n",
      "          Conv2d-119           [-1, 60, 23, 23]          14,400\n",
      "     BatchNorm2d-120           [-1, 60, 23, 23]             120\n",
      "       LeakyReLU-121           [-1, 60, 23, 23]               0\n",
      "          Conv2d-122           [-1, 60, 23, 23]          32,400\n",
      "     BatchNorm2d-123           [-1, 60, 23, 23]             120\n",
      "       LeakyReLU-124           [-1, 60, 23, 23]               0\n",
      "          Conv2d-125          [-1, 240, 23, 23]          14,400\n",
      "     BatchNorm2d-126          [-1, 240, 23, 23]             480\n",
      "       LeakyReLU-127          [-1, 240, 23, 23]               0\n",
      "      Bottleneck-128          [-1, 240, 23, 23]               0\n",
      "          Conv2d-129           [-1, 60, 23, 23]          14,400\n",
      "     BatchNorm2d-130           [-1, 60, 23, 23]             120\n",
      "       LeakyReLU-131           [-1, 60, 23, 23]               0\n",
      "          Conv2d-132           [-1, 60, 23, 23]          32,400\n",
      "     BatchNorm2d-133           [-1, 60, 23, 23]             120\n",
      "       LeakyReLU-134           [-1, 60, 23, 23]               0\n",
      "          Conv2d-135          [-1, 240, 23, 23]          14,400\n",
      "     BatchNorm2d-136          [-1, 240, 23, 23]             480\n",
      "       LeakyReLU-137          [-1, 240, 23, 23]               0\n",
      "      Bottleneck-138          [-1, 240, 23, 23]               0\n",
      "          Conv2d-139           [-1, 96, 23, 23]          23,040\n",
      "     BatchNorm2d-140           [-1, 96, 23, 23]             192\n",
      "       LeakyReLU-141           [-1, 96, 23, 23]               0\n",
      "          Conv2d-142           [-1, 96, 12, 12]          82,944\n",
      "     BatchNorm2d-143           [-1, 96, 12, 12]             192\n",
      "       LeakyReLU-144           [-1, 96, 12, 12]               0\n",
      "          Conv2d-145          [-1, 384, 12, 12]          36,864\n",
      "     BatchNorm2d-146          [-1, 384, 12, 12]             768\n",
      "          Conv2d-147          [-1, 384, 12, 12]          92,160\n",
      "     BatchNorm2d-148          [-1, 384, 12, 12]             768\n",
      "       LeakyReLU-149          [-1, 384, 12, 12]               0\n",
      "      Bottleneck-150          [-1, 384, 12, 12]               0\n",
      "          Conv2d-151           [-1, 96, 12, 12]          36,864\n",
      "     BatchNorm2d-152           [-1, 96, 12, 12]             192\n",
      "       LeakyReLU-153           [-1, 96, 12, 12]               0\n",
      "          Conv2d-154           [-1, 96, 12, 12]          82,944\n",
      "     BatchNorm2d-155           [-1, 96, 12, 12]             192\n",
      "       LeakyReLU-156           [-1, 96, 12, 12]               0\n",
      "          Conv2d-157          [-1, 384, 12, 12]          36,864\n",
      "     BatchNorm2d-158          [-1, 384, 12, 12]             768\n",
      "       LeakyReLU-159          [-1, 384, 12, 12]               0\n",
      "      Bottleneck-160          [-1, 384, 12, 12]               0\n",
      "          Conv2d-161           [-1, 96, 12, 12]          36,864\n",
      "     BatchNorm2d-162           [-1, 96, 12, 12]             192\n",
      "       LeakyReLU-163           [-1, 96, 12, 12]               0\n",
      "          Conv2d-164           [-1, 96, 12, 12]          82,944\n",
      "     BatchNorm2d-165           [-1, 96, 12, 12]             192\n",
      "       LeakyReLU-166           [-1, 96, 12, 12]               0\n",
      "          Conv2d-167          [-1, 384, 12, 12]          36,864\n",
      "     BatchNorm2d-168          [-1, 384, 12, 12]             768\n",
      "       LeakyReLU-169          [-1, 384, 12, 12]               0\n",
      "      Bottleneck-170          [-1, 384, 12, 12]               0\n",
      "          Conv2d-171           [-1, 96, 12, 12]          36,864\n",
      "     BatchNorm2d-172           [-1, 96, 12, 12]             192\n",
      "       LeakyReLU-173           [-1, 96, 12, 12]               0\n",
      "          Conv2d-174           [-1, 96, 12, 12]          82,944\n",
      "     BatchNorm2d-175           [-1, 96, 12, 12]             192\n",
      "       LeakyReLU-176           [-1, 96, 12, 12]               0\n",
      "          Conv2d-177          [-1, 384, 12, 12]          36,864\n",
      "     BatchNorm2d-178          [-1, 384, 12, 12]             768\n",
      "       LeakyReLU-179          [-1, 384, 12, 12]               0\n",
      "      Bottleneck-180          [-1, 384, 12, 12]               0\n",
      "          Conv2d-181           [-1, 96, 12, 12]          36,864\n",
      "     BatchNorm2d-182           [-1, 96, 12, 12]             192\n",
      "       LeakyReLU-183           [-1, 96, 12, 12]               0\n",
      "          Conv2d-184           [-1, 96, 12, 12]          82,944\n",
      "     BatchNorm2d-185           [-1, 96, 12, 12]             192\n",
      "       LeakyReLU-186           [-1, 96, 12, 12]               0\n",
      "          Conv2d-187          [-1, 384, 12, 12]          36,864\n",
      "     BatchNorm2d-188          [-1, 384, 12, 12]             768\n",
      "       LeakyReLU-189          [-1, 384, 12, 12]               0\n",
      "      Bottleneck-190          [-1, 384, 12, 12]               0\n",
      "          Conv2d-191           [-1, 96, 12, 12]          36,864\n",
      "     BatchNorm2d-192           [-1, 96, 12, 12]             192\n",
      "       LeakyReLU-193           [-1, 96, 12, 12]               0\n",
      "          Conv2d-194           [-1, 96, 12, 12]          82,944\n",
      "     BatchNorm2d-195           [-1, 96, 12, 12]             192\n",
      "       LeakyReLU-196           [-1, 96, 12, 12]               0\n",
      "          Conv2d-197          [-1, 384, 12, 12]          36,864\n",
      "     BatchNorm2d-198          [-1, 384, 12, 12]             768\n",
      "       LeakyReLU-199          [-1, 384, 12, 12]               0\n",
      "      Bottleneck-200          [-1, 384, 12, 12]               0\n",
      "          Conv2d-201           [-1, 96, 12, 12]          36,864\n",
      "     BatchNorm2d-202           [-1, 96, 12, 12]             192\n",
      "       LeakyReLU-203           [-1, 96, 12, 12]               0\n",
      "          Conv2d-204           [-1, 96, 12, 12]          82,944\n",
      "     BatchNorm2d-205           [-1, 96, 12, 12]             192\n",
      "       LeakyReLU-206           [-1, 96, 12, 12]               0\n",
      "          Conv2d-207          [-1, 384, 12, 12]          36,864\n",
      "     BatchNorm2d-208          [-1, 384, 12, 12]             768\n",
      "       LeakyReLU-209          [-1, 384, 12, 12]               0\n",
      "      Bottleneck-210          [-1, 384, 12, 12]               0\n",
      "          Conv2d-211           [-1, 96, 12, 12]          36,864\n",
      "     BatchNorm2d-212           [-1, 96, 12, 12]             192\n",
      "       LeakyReLU-213           [-1, 96, 12, 12]               0\n",
      "          Conv2d-214           [-1, 96, 12, 12]          82,944\n",
      "     BatchNorm2d-215           [-1, 96, 12, 12]             192\n",
      "       LeakyReLU-216           [-1, 96, 12, 12]               0\n",
      "          Conv2d-217          [-1, 384, 12, 12]          36,864\n",
      "     BatchNorm2d-218          [-1, 384, 12, 12]             768\n",
      "       LeakyReLU-219          [-1, 384, 12, 12]               0\n",
      "      Bottleneck-220          [-1, 384, 12, 12]               0\n",
      "AdaptiveAvgPool2d-221            [-1, 384, 1, 1]               0\n",
      "          Linear-222                   [-1, 10]           3,850\n",
      "================================================================\n",
      "Total params: 1,996,986\n",
      "Trainable params: 1,996,986\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.11\n",
      "Forward/backward pass size (MB): 132.52\n",
      "Params size (MB): 7.62\n",
      "Estimated Total Size (MB): 140.24\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "summary(model,(3,96,96))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=1e-4)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020/11/25 00:41:51\n",
      "epoch: 1/200 | trn loss: 1.8344 | val loss: 1.6241 | val accuracy: 39.5933% \n",
      "\n",
      "2020/11/25 00:43:26\n",
      "epoch: 2/200 | trn loss: 1.4912 | val loss: 1.4126 | val accuracy: 48.7780% \n",
      "\n",
      "2020/11/25 00:45:00\n",
      "epoch: 3/200 | trn loss: 1.2910 | val loss: 1.3192 | val accuracy: 53.3053% \n",
      "\n",
      "2020/11/25 00:46:35\n",
      "epoch: 4/200 | trn loss: 1.1636 | val loss: 1.2314 | val accuracy: 56.0897% \n",
      "\n",
      "2020/11/25 00:48:09\n",
      "epoch: 5/200 | trn loss: 1.0585 | val loss: 1.1415 | val accuracy: 59.1947% \n",
      "\n",
      "2020/11/25 00:49:44\n",
      "epoch: 6/200 | trn loss: 0.9728 | val loss: 1.1210 | val accuracy: 60.4768% \n",
      "\n",
      "2020/11/25 00:51:18\n",
      "epoch: 7/200 | trn loss: 0.9106 | val loss: 1.0969 | val accuracy: 61.8890% \n",
      "\n",
      "2020/11/25 00:52:53\n",
      "epoch: 8/200 | trn loss: 0.8500 | val loss: 1.0886 | val accuracy: 62.6853% \n",
      "\n",
      "2020/11/25 00:54:27\n",
      "epoch: 9/200 | trn loss: 0.8090 | val loss: 1.0263 | val accuracy: 64.1877% \n",
      "\n",
      "2020/11/25 00:56:01\n",
      "epoch: 10/200 | trn loss: 0.7590 | val loss: 1.0393 | val accuracy: 64.7236% \n",
      "\n",
      "2020/11/25 00:57:36\n",
      "epoch: 11/200 | trn loss: 0.7273 | val loss: 1.0262 | val accuracy: 64.9339% \n",
      "\n",
      "Model replaced and saved as  /home/jupyter-deeplearning/res_model/Custom_model_2.0_1.026\n",
      "2020/11/25 00:59:10\n",
      "epoch: 12/200 | trn loss: 0.6873 | val loss: 0.9815 | val accuracy: 66.6867% \n",
      "\n",
      "Model replaced and saved as  /home/jupyter-deeplearning/res_model/Custom_model_2.0_0.981\n",
      "2020/11/25 01:00:44\n",
      "epoch: 13/200 | trn loss: 0.6647 | val loss: 1.0206 | val accuracy: 65.9605% \n",
      "\n",
      "2020/11/25 01:02:19\n",
      "epoch: 14/200 | trn loss: 0.6358 | val loss: 1.0285 | val accuracy: 65.8854% \n",
      "\n",
      "2020/11/25 01:03:53\n",
      "epoch: 15/200 | trn loss: 0.6149 | val loss: 1.0046 | val accuracy: 66.2710% \n",
      "\n",
      "2020/11/25 01:05:27\n",
      "epoch: 16/200 | trn loss: 0.5886 | val loss: 0.9915 | val accuracy: 66.6116% \n",
      "\n",
      "2020/11/25 01:07:01\n",
      "epoch: 17/200 | trn loss: 0.5665 | val loss: 0.9833 | val accuracy: 67.5931% \n",
      "\n",
      "2020/11/25 01:08:35\n",
      "epoch: 18/200 | trn loss: 0.5493 | val loss: 0.9700 | val accuracy: 67.9137% \n",
      "\n",
      "Model replaced and saved as  /home/jupyter-deeplearning/res_model/Custom_model_2.0_0.970\n",
      "2020/11/25 01:10:10\n",
      "epoch: 19/200 | trn loss: 0.5358 | val loss: 0.9469 | val accuracy: 68.8902% \n",
      "\n",
      "Model replaced and saved as  /home/jupyter-deeplearning/res_model/Custom_model_2.0_0.947\n",
      "2020/11/25 01:11:44\n",
      "epoch: 20/200 | trn loss: 0.5094 | val loss: 1.0465 | val accuracy: 67.2276% \n",
      "\n",
      "2020/11/25 01:13:19\n",
      "epoch: 21/200 | trn loss: 0.5054 | val loss: 0.9792 | val accuracy: 68.2442% \n",
      "\n",
      "2020/11/25 01:14:53\n",
      "epoch: 22/200 | trn loss: 0.4901 | val loss: 0.9478 | val accuracy: 69.0605% \n",
      "\n",
      "2020/11/25 01:16:27\n",
      "epoch: 23/200 | trn loss: 0.4824 | val loss: 0.9774 | val accuracy: 68.6999% \n",
      "\n",
      "2020/11/25 01:18:01\n",
      "epoch: 24/200 | trn loss: 0.4680 | val loss: 0.9691 | val accuracy: 68.1741% \n",
      "\n",
      "2020/11/25 01:19:36\n",
      "epoch: 25/200 | trn loss: 0.4587 | val loss: 1.0036 | val accuracy: 68.2192% \n",
      "\n",
      "2020/11/25 01:21:10\n",
      "epoch: 26/200 | trn loss: 0.4484 | val loss: 1.0030 | val accuracy: 67.9537% \n",
      "\n",
      "2020/11/25 01:22:44\n",
      "epoch: 27/200 | trn loss: 0.4487 | val loss: 0.9956 | val accuracy: 68.9653% \n",
      "\n",
      "2020/11/25 01:24:18\n",
      "epoch: 28/200 | trn loss: 0.4334 | val loss: 0.9854 | val accuracy: 68.6198% \n",
      "\n",
      "2020/11/25 01:25:52\n",
      "epoch: 29/200 | trn loss: 0.4286 | val loss: 0.9791 | val accuracy: 69.0004% \n",
      "\n",
      "2020/11/25 01:27:27\n",
      "epoch: 30/200 | trn loss: 0.4166 | val loss: 1.0235 | val accuracy: 67.7634% \n",
      "\n",
      "2020/11/25 01:29:02\n",
      "epoch: 31/200 | trn loss: 0.3032 | val loss: 0.8704 | val accuracy: 72.8916% \n",
      "\n",
      "Model replaced and saved as  /home/jupyter-deeplearning/res_model/Custom_model_2.0_0.870\n",
      "2020/11/25 01:30:37\n",
      "epoch: 32/200 | trn loss: 0.2582 | val loss: 0.9053 | val accuracy: 73.0319% \n",
      "\n",
      "2020/11/25 01:32:11\n",
      "epoch: 33/200 | trn loss: 0.2501 | val loss: 0.9090 | val accuracy: 72.9868% \n",
      "\n",
      "2020/11/25 01:33:45\n",
      "epoch: 34/200 | trn loss: 0.2412 | val loss: 0.8994 | val accuracy: 73.6428% \n",
      "\n",
      "2020/11/25 01:35:19\n",
      "epoch: 35/200 | trn loss: 0.2350 | val loss: 0.9098 | val accuracy: 73.6929% \n",
      "\n",
      "2020/11/25 01:36:53\n",
      "epoch: 36/200 | trn loss: 0.2276 | val loss: 0.9350 | val accuracy: 73.1170% \n",
      "\n",
      "2020/11/25 01:38:28\n",
      "epoch: 37/200 | trn loss: 0.2240 | val loss: 0.9402 | val accuracy: 73.1320% \n",
      "\n",
      "2020/11/25 01:40:02\n",
      "epoch: 38/200 | trn loss: 0.2166 | val loss: 0.9242 | val accuracy: 73.6679% \n",
      "\n",
      "2020/11/25 01:41:36\n",
      "epoch: 39/200 | trn loss: 0.2136 | val loss: 0.9617 | val accuracy: 73.4776% \n",
      "\n",
      "2020/11/25 01:43:10\n",
      "epoch: 40/200 | trn loss: 0.2115 | val loss: 0.9453 | val accuracy: 73.3323% \n",
      "\n",
      "2020/11/25 01:44:44\n",
      "epoch: 41/200 | trn loss: 0.2047 | val loss: 0.9641 | val accuracy: 73.2422% \n",
      "\n",
      "2020/11/25 01:46:18\n",
      "epoch: 42/200 | trn loss: 0.2055 | val loss: 0.9567 | val accuracy: 73.2071% \n",
      "\n",
      "2020/11/25 01:47:53\n",
      "epoch: 43/200 | trn loss: 0.2025 | val loss: 0.9606 | val accuracy: 73.2171% \n",
      "\n",
      "2020/11/25 01:49:26\n",
      "epoch: 44/200 | trn loss: 0.2019 | val loss: 0.9376 | val accuracy: 74.1887% \n",
      "\n",
      "2020/11/25 01:51:02\n",
      "epoch: 45/200 | trn loss: 0.2013 | val loss: 0.9518 | val accuracy: 73.9133% \n",
      "\n",
      "2020/11/25 01:52:36\n",
      "epoch: 46/200 | trn loss: 0.1939 | val loss: 0.9617 | val accuracy: 73.3824% \n",
      "\n",
      "2020/11/25 01:54:11\n",
      "epoch: 47/200 | trn loss: 0.1939 | val loss: 0.9809 | val accuracy: 73.3423% \n",
      "\n",
      "2020/11/25 01:55:45\n",
      "epoch: 48/200 | trn loss: 0.1903 | val loss: 1.0058 | val accuracy: 72.9467% \n",
      "\n",
      "2020/11/25 01:57:19\n",
      "epoch: 49/200 | trn loss: 0.1860 | val loss: 0.9616 | val accuracy: 73.6128% \n",
      "\n",
      "2020/11/25 01:58:53\n",
      "epoch: 50/200 | trn loss: 0.1915 | val loss: 0.9688 | val accuracy: 73.4225% \n",
      "\n",
      "2020/11/25 02:00:27\n",
      "epoch: 51/200 | trn loss: 0.1863 | val loss: 0.9685 | val accuracy: 73.4024% \n",
      "\n",
      "2020/11/25 02:02:02\n",
      "epoch: 52/200 | trn loss: 0.1788 | val loss: 0.9776 | val accuracy: 73.6328% \n",
      "\n",
      "2020/11/25 02:03:36\n",
      "epoch: 53/200 | trn loss: 0.1848 | val loss: 0.9825 | val accuracy: 73.4525% \n",
      "\n",
      "2020/11/25 02:05:10\n",
      "epoch: 54/200 | trn loss: 0.1784 | val loss: 0.9768 | val accuracy: 73.3874% \n",
      "\n",
      "2020/11/25 02:06:45\n",
      "epoch: 55/200 | trn loss: 0.1816 | val loss: 0.9750 | val accuracy: 73.8081% \n",
      "\n",
      "2020/11/25 02:08:20\n",
      "epoch: 56/200 | trn loss: 0.1795 | val loss: 0.9803 | val accuracy: 73.5527% \n",
      "\n",
      "2020/11/25 02:09:54\n",
      "epoch: 57/200 | trn loss: 0.1767 | val loss: 0.9720 | val accuracy: 73.5727% \n",
      "\n",
      "2020/11/25 02:11:29\n",
      "epoch: 58/200 | trn loss: 0.1744 | val loss: 0.9870 | val accuracy: 73.2422% \n",
      "\n",
      "2020/11/25 02:13:03\n",
      "epoch: 59/200 | trn loss: 0.1773 | val loss: 0.9799 | val accuracy: 73.7129% \n",
      "\n",
      "2020/11/25 02:14:38\n",
      "epoch: 60/200 | trn loss: 0.1706 | val loss: 1.0101 | val accuracy: 73.5677% \n",
      "\n",
      "2020/11/25 02:16:12\n",
      "epoch: 61/200 | trn loss: 0.1625 | val loss: 0.9804 | val accuracy: 73.8331% \n",
      "\n",
      "2020/11/25 02:17:47\n",
      "epoch: 62/200 | trn loss: 0.1612 | val loss: 0.9780 | val accuracy: 73.8431% \n",
      "\n",
      "2020/11/25 02:19:21\n",
      "epoch: 63/200 | trn loss: 0.1601 | val loss: 0.9830 | val accuracy: 74.0184% \n",
      "\n",
      "2020/11/25 02:20:56\n",
      "epoch: 64/200 | trn loss: 0.1525 | val loss: 0.9719 | val accuracy: 74.1787% \n",
      "\n",
      "2020/11/25 02:22:30\n",
      "epoch: 65/200 | trn loss: 0.1544 | val loss: 0.9824 | val accuracy: 73.8081% \n",
      "\n",
      "2020/11/25 02:24:05\n",
      "epoch: 66/200 | trn loss: 0.1520 | val loss: 0.9753 | val accuracy: 74.1236% \n",
      "\n",
      "2020/11/25 02:25:39\n",
      "epoch: 67/200 | trn loss: 0.1525 | val loss: 0.9892 | val accuracy: 73.9483% \n",
      "\n",
      "2020/11/25 02:27:13\n",
      "epoch: 68/200 | trn loss: 0.1554 | val loss: 0.9739 | val accuracy: 74.1687% \n",
      "\n",
      "2020/11/25 02:28:48\n",
      "epoch: 69/200 | trn loss: 0.1527 | val loss: 0.9911 | val accuracy: 73.9683% \n",
      "\n",
      "2020/11/25 02:30:22\n",
      "epoch: 70/200 | trn loss: 0.1523 | val loss: 0.9950 | val accuracy: 73.6979% \n",
      "\n",
      "2020/11/25 02:31:56\n",
      "epoch: 71/200 | trn loss: 0.1491 | val loss: 0.9805 | val accuracy: 74.1286% \n",
      "\n",
      "2020/11/25 02:33:29\n",
      "epoch: 72/200 | trn loss: 0.1501 | val loss: 0.9782 | val accuracy: 73.7380% \n",
      "\n",
      "2020/11/25 02:35:04\n",
      "epoch: 73/200 | trn loss: 0.1476 | val loss: 0.9909 | val accuracy: 73.6779% \n",
      "\n",
      "2020/11/25 02:36:37\n",
      "epoch: 74/200 | trn loss: 0.1486 | val loss: 0.9782 | val accuracy: 74.4141% \n",
      "\n",
      "2020/11/25 02:38:12\n",
      "epoch: 75/200 | trn loss: 0.1486 | val loss: 0.9750 | val accuracy: 74.5192% \n",
      "\n",
      "2020/11/25 02:39:47\n",
      "epoch: 76/200 | trn loss: 0.1464 | val loss: 0.9920 | val accuracy: 73.9884% \n",
      "\n",
      "2020/11/25 02:41:20\n",
      "epoch: 77/200 | trn loss: 0.1487 | val loss: 1.0018 | val accuracy: 73.8031% \n",
      "\n",
      "2020/11/25 02:42:55\n",
      "epoch: 78/200 | trn loss: 0.1439 | val loss: 0.9968 | val accuracy: 73.9884% \n",
      "\n",
      "2020/11/25 02:44:30\n",
      "epoch: 79/200 | trn loss: 0.1453 | val loss: 0.9771 | val accuracy: 74.3590% \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020/11/25 02:46:04\n",
      "epoch: 80/200 | trn loss: 0.1469 | val loss: 0.9725 | val accuracy: 74.7847% \n",
      "\n",
      "2020/11/25 02:47:38\n",
      "epoch: 81/200 | trn loss: 0.1507 | val loss: 0.9871 | val accuracy: 74.2188% \n",
      "\n",
      "2020/11/25 02:49:12\n",
      "epoch: 82/200 | trn loss: 0.1464 | val loss: 0.9753 | val accuracy: 74.2238% \n",
      "\n",
      "2020/11/25 02:50:47\n",
      "epoch: 83/200 | trn loss: 0.1469 | val loss: 0.9754 | val accuracy: 74.6595% \n",
      "\n",
      "2020/11/25 02:52:21\n",
      "epoch: 84/200 | trn loss: 0.1435 | val loss: 0.9778 | val accuracy: 74.1687% \n",
      "\n",
      "2020/11/25 02:53:55\n",
      "epoch: 85/200 | trn loss: 0.1423 | val loss: 0.9964 | val accuracy: 73.5727% \n",
      "\n",
      "2020/11/25 02:55:30\n",
      "epoch: 86/200 | trn loss: 0.1488 | val loss: 0.9917 | val accuracy: 74.4842% \n",
      "\n",
      "2020/11/25 02:57:04\n",
      "epoch: 87/200 | trn loss: 0.1469 | val loss: 0.9777 | val accuracy: 74.3389% \n",
      "\n",
      "2020/11/25 02:58:38\n",
      "epoch: 88/200 | trn loss: 0.1486 | val loss: 0.9922 | val accuracy: 74.0986% \n",
      "\n",
      "2020/11/25 03:00:12\n",
      "epoch: 89/200 | trn loss: 0.1485 | val loss: 0.9758 | val accuracy: 74.2788% \n",
      "\n",
      "2020/11/25 03:01:47\n",
      "epoch: 90/200 | trn loss: 0.1434 | val loss: 1.0004 | val accuracy: 74.1687% \n",
      "\n",
      "2020/11/25 03:03:21\n",
      "epoch: 91/200 | trn loss: 0.1417 | val loss: 0.9857 | val accuracy: 74.1336% \n",
      "\n",
      "2020/11/25 03:04:56\n",
      "epoch: 92/200 | trn loss: 0.1416 | val loss: 0.9768 | val accuracy: 74.3890% \n",
      "\n",
      "2020/11/25 03:06:30\n",
      "epoch: 93/200 | trn loss: 0.1466 | val loss: 0.9852 | val accuracy: 74.2538% \n",
      "\n"
     ]
    }
   ],
   "source": [
    "saving_path=\"/home/jupyter-deeplearning/res_model/\"\n",
    "trn_loss_list = []\n",
    "val_loss_list = []\n",
    "val_acc_list = []\n",
    "total_epoch=200\n",
    "model_char=\"2.0\"\n",
    "model_name=\"\"\n",
    "patience=10\n",
    "start_early_stop_check=0\n",
    "saving_start_epoch=10\n",
    "\n",
    "for epoch in range(total_epoch):\n",
    "    trn_loss = 0.0\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        inputs, labels = data\n",
    "        if torch.cuda.is_available():\n",
    "            inputs=inputs.cuda()\n",
    "            labels=labels.cuda()\n",
    "        # grad init\n",
    "        optimizer.zero_grad()\n",
    "        # forward propagation\n",
    "        output= model(inputs)\n",
    "        # calculate loss\n",
    "        loss=criterion(output, labels)\n",
    "        # back propagation \n",
    "        loss.backward()\n",
    "        # weight update\n",
    "        optimizer.step()\n",
    "        \n",
    "        # trn_loss summary\n",
    "        trn_loss += loss.item()\n",
    "        # del (memory issue)\n",
    "        del loss\n",
    "        del output\n",
    "    with torch.no_grad():\n",
    "        val_loss = 0.0\n",
    "        cor_match = 0\n",
    "        for j, val in enumerate(test_loader):\n",
    "            val_x, val_label = val\n",
    "            if torch.cuda.is_available():\n",
    "                val_x = val_x.cuda()\n",
    "                val_label =val_label.cuda()\n",
    "            val_output = model(val_x)\n",
    "            v_loss = criterion(val_output, val_label)\n",
    "            val_loss += v_loss\n",
    "            _, predicted=torch.max(val_output,1)\n",
    "            cor_match+=np.count_nonzero(predicted.cpu().detach()==val_label.cpu().detach())\n",
    "    del val_output\n",
    "    del v_loss\n",
    "    del predicted\n",
    "    \n",
    "    scheduler.step()\n",
    "    \n",
    "    \n",
    "    \n",
    "    trn_loss_list.append(trn_loss/len(train_loader))\n",
    "    val_loss_list.append(val_loss/len(test_loader))\n",
    "    val_acc=cor_match/(len(test_loader)*batch_size)\n",
    "    val_acc_list.append(val_acc)\n",
    "    now = time.localtime()\n",
    "    print (\"%04d/%02d/%02d %02d:%02d:%02d\" % (now.tm_year, now.tm_mon, now.tm_mday, now.tm_hour, now.tm_min, now.tm_sec))\n",
    "\n",
    "    print(\"epoch: {}/{} | trn loss: {:.4f} | val loss: {:.4f} | val accuracy: {:.4f}% \\n\".format(\n",
    "                epoch+1, total_epoch, trn_loss / len(train_loader), val_loss / len(test_loader), val_acc*100\n",
    "            ))\n",
    "    \n",
    "    \n",
    "    if epoch+1>2:\n",
    "        if val_loss_list[-1]>val_loss_list[-2]:\n",
    "            start_early_stop_check=1\n",
    "    else:\n",
    "        val_loss_min=val_loss_list[-1]\n",
    "        \n",
    "    if start_early_stop_check:\n",
    "        early_stop_temp=val_loss_list[-patience:]\n",
    "        if all(early_stop_temp[i]<early_stop_temp[i+1] for i in range (len(early_stop_temp)-1)):\n",
    "            print(\"Early stop!\")\n",
    "            break\n",
    "            \n",
    "    if epoch+1>saving_start_epoch:\n",
    "        if val_loss_list[-1]<val_loss_min:\n",
    "            if os.path.isfile(model_name):\n",
    "                os.remove(model_name)\n",
    "            val_loss_min=val_loss_list[-1]\n",
    "            model_name=saving_path+\"Custom_model_\"+model_char+\"_{:.3f}\".format(val_loss_min)\n",
    "            torch.save(model, model_name)\n",
    "            print(\"Model replaced and saved as \",model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=64\n",
    "dataset = datasets.ImageFolder(\n",
    "        train_path_path,\n",
    "        transforms.Compose([\n",
    "        transforms.RandomRotation(degrees=45),\n",
    "        transforms.Resize(120),    \n",
    "        transforms.ColorJitter(.3,.3,.3,.3),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "            normalize,\n",
    "        ]))\n",
    "for _ in range (19):\n",
    "    aug_data = datasets.ImageFolder(\n",
    "        train_path_path,\n",
    "        transforms.Compose([\n",
    "        transforms.RandomRotation(degrees=45),\n",
    "        transforms.Resize(120),    \n",
    "        transforms.ColorJitter(.3,.3,.3,.3),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "            normalize,\n",
    "        ]))\n",
    "    dataset=torch.utils.data.ConcatDataset([dataset,aug_data])\n",
    "valset = datasets.ImageFolder(\n",
    "        test_path_path,\n",
    "        transforms.Compose([\n",
    "        transforms.RandomRotation(degrees=45),\n",
    "        transforms.Resize(120),\n",
    "        transforms.ColorJitter(.3,.3,.3,.3),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "            normalize,\n",
    "        ]))\n",
    "for _ in range (19):\n",
    "    aug_data = datasets.ImageFolder(\n",
    "        test_path_path,\n",
    "        transforms.Compose([\n",
    "        transforms.RandomRotation(degrees=45),\n",
    "        transforms.Resize(120),    \n",
    "        transforms.ColorJitter(.3,.3,.3,.3),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "            normalize,\n",
    "        ]))\n",
    "    valset=torch.utils.data.ConcatDataset([valset,aug_data])\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "        dataset, batch_size=batch_size, shuffle=True,\n",
    "        num_workers=8, pin_memory=True,drop_last=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "        valset, batch_size=batch_size, shuffle=True,\n",
    "        num_workers=8, pin_memory=True,drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=1e-4)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fine tuning\n",
    "\n",
    "total_epoch=80\n",
    "model_char=\"2.0\"\n",
    "model_name=\"\"\n",
    "patience=10\n",
    "start_early_stop_check=0\n",
    "saving_start_epoch=10\n",
    "\n",
    "for epoch in range(total_epoch):\n",
    "    trn_loss = 0.0\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        inputs, labels = data\n",
    "        if torch.cuda.is_available():\n",
    "            inputs=inputs.cuda()\n",
    "            labels=labels.cuda()\n",
    "        # grad init\n",
    "        optimizer.zero_grad()\n",
    "        # forward propagation\n",
    "        output= model(inputs)\n",
    "        # calculate loss\n",
    "        loss=criterion(output, labels)\n",
    "        # back propagation \n",
    "        loss.backward()\n",
    "        # weight update\n",
    "        optimizer.step()\n",
    "        \n",
    "        # trn_loss summary\n",
    "        trn_loss += loss.item()\n",
    "        # del (memory issue)\n",
    "        del loss\n",
    "        del output\n",
    "    with torch.no_grad():\n",
    "        val_loss = 0.0\n",
    "        cor_match = 0\n",
    "        for j, val in enumerate(test_loader):\n",
    "            val_x, val_label = val\n",
    "            if torch.cuda.is_available():\n",
    "                val_x = val_x.cuda()\n",
    "                val_label =val_label.cuda()\n",
    "            val_output = model(val_x)\n",
    "            v_loss = criterion(val_output, val_label)\n",
    "            val_loss += v_loss\n",
    "            _, predicted=torch.max(val_output,1)\n",
    "            cor_match+=np.count_nonzero(predicted.cpu().detach()==val_label.cpu().detach())\n",
    "    del val_output\n",
    "    del v_loss\n",
    "    del predicted\n",
    "    \n",
    "    scheduler.step()\n",
    "    \n",
    "    \n",
    "    \n",
    "    trn_loss_list.append(trn_loss/len(train_loader))\n",
    "    val_loss_list.append(val_loss/len(test_loader))\n",
    "    val_acc=cor_match/(len(test_loader)*batch_size)\n",
    "    val_acc_list.append(val_acc)\n",
    "    now = time.localtime()\n",
    "    print (\"%04d/%02d/%02d %02d:%02d:%02d\" % (now.tm_year, now.tm_mon, now.tm_mday, now.tm_hour, now.tm_min, now.tm_sec))\n",
    "\n",
    "    print(\"epoch: {}/{} | trn loss: {:.4f} | val loss: {:.4f} | val accuracy: {:.4f}% \\n\".format(\n",
    "                epoch+1, total_epoch, trn_loss / len(train_loader), val_loss / len(test_loader), val_acc*100\n",
    "            ))\n",
    "    \n",
    "    \n",
    "    if epoch+1>2:\n",
    "        if val_loss_list[-1]>val_loss_list[-2]:\n",
    "            start_early_stop_check=1\n",
    "    else:\n",
    "        val_loss_min=val_loss_list[-1]\n",
    "        \n",
    "    if start_early_stop_check:\n",
    "        early_stop_temp=val_loss_list[-patience:]\n",
    "        if all(early_stop_temp[i]<early_stop_temp[i+1] for i in range (len(early_stop_temp)-1)):\n",
    "            print(\"Early stop!\")\n",
    "            break\n",
    "            \n",
    "    if epoch+1>saving_start_epoch:\n",
    "        if val_loss_list[-1]<val_loss_min:\n",
    "            if os.path.isfile(model_name):\n",
    "                os.remove(model_name)\n",
    "            val_loss_min=val_loss_list[-1]\n",
    "            model_name=\"Custom_model_\"+model_char+\"_{:.3f}\".format(val_loss_min)\n",
    "            torch.save(model, model_name)\n",
    "            print(\"Model replaced and saved as \",model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,15))\n",
    "plt.ylabel(\"val_accuracy\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.plot(val_acc_list)\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# val_acc_list=np.array(val_acc_list)\n",
    "# np.savetxt(\"ver_2.0.txt\", val_acc_list, delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import pandas as pd\n",
    "# import argparse\n",
    "# import time\n",
    "# import torchvision\n",
    "# import torchvision.transforms as transforms\n",
    "# from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize = transforms.Normalize(mean=[0.507, 0.487, 0.441],\n",
    "#                                      std=[0.267, 0.256, 0.276])\n",
    "# test_transform = transforms.Compose([\n",
    "#         transforms.ToTensor(),\n",
    "#         normalize\n",
    "#     ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_dataset = torchvision.datasets.ImageFolder('./data/test', transform=test_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_loader = DataLoader(test_dataset, batch_size=batch_size, num_workers=4, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Category = []\n",
    "# for input, _ in test_loader:\n",
    "#     input = input.cuda()\n",
    "#     output = model(input)\n",
    "#     output = torch.argmax(output, dim=1)\n",
    "#     Category = Category + output.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Id = list(range(0, 8000))\n",
    "# samples = {\n",
    "#    'Id': Id,\n",
    "#    'Category': Category \n",
    "# }\n",
    "# df = pd.DataFrame(samples, columns=['Id', 'Category'])\n",
    "\n",
    "# df.to_csv('submission_2.0_2.csv', index=False)\n",
    "# print('Done!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
