{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import shutil\n",
    "import torch.distributed as dist\n",
    "import math\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from glob import glob\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from typing import Type, Any, Callable, Union, List, Optional\n",
    "from torch import Tensor\n",
    "from torch.hub import load_state_dict_from_url\n",
    "from torch.utils.data.dataloader import default_collate\n",
    "from torch.utils.data.sampler import BatchSampler\n",
    "from collections.abc import Mapping, Sequence\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path_path= f\"{os.getcwd()}/data/split_train/train\"\n",
    "test_path_path= f\"{os.getcwd()}/data/split_train/val\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=128\n",
    "num_gpus=4\n",
    "num_workers=8\n",
    "lr=0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize = transforms.Normalize(mean=[0.507, 0.487, 0.441],\n",
    "                                     std=[0.267, 0.256, 0.276])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = datasets.ImageFolder(\n",
    "        train_path_path,\n",
    "        transforms.Compose([\n",
    "        transforms.RandomRotation(degrees=45),\n",
    "            \n",
    "        transforms.RandomResizedCrop(80),\n",
    "        transforms.ColorJitter(.3,.3,.3,.3),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "            normalize,\n",
    "        ]))\n",
    "for _ in range (19):\n",
    "    aug_data = datasets.ImageFolder(\n",
    "        train_path_path,\n",
    "        transforms.Compose([\n",
    "        transforms.RandomRotation(degrees=45),\n",
    "            \n",
    "        transforms.RandomResizedCrop(80),\n",
    "        transforms.ColorJitter(.3,.3,.3,.3),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "            normalize,\n",
    "        ]))\n",
    "    dataset=torch.utils.data.ConcatDataset([dataset,aug_data])\n",
    "valset = datasets.ImageFolder(\n",
    "        test_path_path,\n",
    "        transforms.Compose([\n",
    "        transforms.RandomRotation(degrees=45),\n",
    "            \n",
    "        transforms.RandomResizedCrop(80),\n",
    "        transforms.ColorJitter(.3,.3,.3,.3),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "            normalize,\n",
    "        ]))\n",
    "for _ in range (19):\n",
    "    aug_data = datasets.ImageFolder(\n",
    "        test_path_path,\n",
    "        transforms.Compose([\n",
    "        transforms.RandomRotation(degrees=45),\n",
    "            \n",
    "        transforms.RandomResizedCrop(80),\n",
    "        transforms.ColorJitter(.3,.3,.3,.3),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "            normalize,\n",
    "        ]))\n",
    "    valset=torch.utils.data.ConcatDataset([valset,aug_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80000\n",
      "20000\n"
     ]
    }
   ],
   "source": [
    "print(len(dataset))\n",
    "print(len(valset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "        dataset, batch_size=batch_size, shuffle=True,\n",
    "        num_workers=8, pin_memory=True,drop_last=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "        valset, batch_size=batch_size, shuffle=True,\n",
    "        num_workers=8, pin_memory=True,drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.layer_1 = nn.Conv2d(in_channels=3,out_channels=64,kernel_size=5,\n",
    "                                 stride=2,padding=3)\n",
    "        self.act_1 = nn.LeakyReLU(0.1)\n",
    "        self.conv2_bn1 = nn.BatchNorm2d(64)\n",
    "        self.max_1=nn.MaxPool2d(2,2)\n",
    "        \n",
    "        self.layer_2 = nn.Conv2d(in_channels=64,out_channels=128,kernel_size=3,\n",
    "                                 stride=1,padding=2)\n",
    "        self.act_2 = nn.LeakyReLU(0.1)\n",
    "        self.conv2_bn2 = nn.BatchNorm2d(128)\n",
    "        \n",
    "        self.layer_3 = nn.Conv2d(in_channels=128,out_channels=128,kernel_size=3,\n",
    "                                 stride=1,padding=2)\n",
    "        self.act_3 = nn.LeakyReLU(0.1)\n",
    "        self.conv2_bn3 = nn.BatchNorm2d(128)\n",
    "        \n",
    "        self.layer_4 = nn.Conv2d(in_channels=128,out_channels=128,kernel_size=1,\n",
    "                                 stride=1)\n",
    "        self.act_4 = nn.LeakyReLU(0.1)\n",
    "        self.conv2_bn4 = nn.BatchNorm2d(128)\n",
    "        \n",
    "        self.max_1=nn.MaxPool2d(2,2)\n",
    "        \n",
    "        self.layer_5 = nn.Conv2d(in_channels=128,out_channels=256,kernel_size=3,\n",
    "                                 stride=1,padding=2)\n",
    "        self.act_5 = nn.LeakyReLU(0.1)\n",
    "        self.conv2_bn5 = nn.BatchNorm2d(256)\n",
    "        \n",
    "        self.layer_6 = nn.Conv2d(in_channels=256,out_channels=256,kernel_size=3,\n",
    "                                 stride=1,padding=2)\n",
    "        self.act_6 = nn.LeakyReLU(0.1)\n",
    "        self.conv2_bn6 = nn.BatchNorm2d(256)\n",
    "        \n",
    "        self.layer_7 = nn.Conv2d(in_channels=256,out_channels=256,kernel_size=1,\n",
    "                                 stride=1)\n",
    "        self.act_7 = nn.LeakyReLU(0.1)\n",
    "        self.conv2_bn7 = nn.BatchNorm2d(256)\n",
    "        \n",
    "        self.max_2=nn.MaxPool2d(2,2)\n",
    "        \n",
    "        self.layer_8 = nn.Conv2d(in_channels=256,out_channels=512,kernel_size=3,\n",
    "                                 stride=1,padding=2)\n",
    "        self.act_8 = nn.LeakyReLU(0.1)\n",
    "        self.conv2_bn8 = nn.BatchNorm2d(512)\n",
    "        \n",
    "        \n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        \n",
    "        self.fc_layer_1 = nn.Linear(512,10)\n",
    "        self.act_9 = nn.LeakyReLU(0.1)\n",
    "        \n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "        \n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.layer_1(x)\n",
    "        out = self.act_1(out)\n",
    "        for module in list(self.modules())[2:-2]:\n",
    "            out = module(out)\n",
    "        out = torch.flatten(out,1)\n",
    "        for module in list(self.modules())[-2:]:\n",
    "            out = module(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model()\n",
    "model = model.cuda()\n",
    "criterion = nn.CrossEntropyLoss().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for name, param in model.named_parameters():\n",
    "#     if param.requires_grad:\n",
    "#         print (name, param.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 64, 41, 41]           4,864\n",
      "         LeakyReLU-2           [-1, 64, 41, 41]               0\n",
      "         LeakyReLU-3           [-1, 64, 41, 41]               0\n",
      "       BatchNorm2d-4           [-1, 64, 41, 41]             128\n",
      "         MaxPool2d-5           [-1, 64, 20, 20]               0\n",
      "            Conv2d-6          [-1, 128, 22, 22]          73,856\n",
      "         LeakyReLU-7          [-1, 128, 22, 22]               0\n",
      "       BatchNorm2d-8          [-1, 128, 22, 22]             256\n",
      "            Conv2d-9          [-1, 128, 24, 24]         147,584\n",
      "        LeakyReLU-10          [-1, 128, 24, 24]               0\n",
      "      BatchNorm2d-11          [-1, 128, 24, 24]             256\n",
      "           Conv2d-12          [-1, 128, 24, 24]          16,512\n",
      "        LeakyReLU-13          [-1, 128, 24, 24]               0\n",
      "      BatchNorm2d-14          [-1, 128, 24, 24]             256\n",
      "           Conv2d-15          [-1, 256, 26, 26]         295,168\n",
      "        LeakyReLU-16          [-1, 256, 26, 26]               0\n",
      "      BatchNorm2d-17          [-1, 256, 26, 26]             512\n",
      "           Conv2d-18          [-1, 256, 28, 28]         590,080\n",
      "        LeakyReLU-19          [-1, 256, 28, 28]               0\n",
      "      BatchNorm2d-20          [-1, 256, 28, 28]             512\n",
      "           Conv2d-21          [-1, 256, 28, 28]          65,792\n",
      "        LeakyReLU-22          [-1, 256, 28, 28]               0\n",
      "      BatchNorm2d-23          [-1, 256, 28, 28]             512\n",
      "        MaxPool2d-24          [-1, 256, 14, 14]               0\n",
      "           Conv2d-25          [-1, 512, 16, 16]       1,180,160\n",
      "        LeakyReLU-26          [-1, 512, 16, 16]               0\n",
      "      BatchNorm2d-27          [-1, 512, 16, 16]           1,024\n",
      "AdaptiveAvgPool2d-28            [-1, 512, 1, 1]               0\n",
      "           Linear-29                   [-1, 10]           5,130\n",
      "        LeakyReLU-30                   [-1, 10]               0\n",
      "================================================================\n",
      "Total params: 2,382,602\n",
      "Trainable params: 2,382,602\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.07\n",
      "Forward/backward pass size (MB): 24.81\n",
      "Params size (MB): 9.09\n",
      "Estimated Total Size (MB): 33.97\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "summary(model,(3,80,80))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=1e-4)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jupyter-deeplearning/res_model\n"
     ]
    }
   ],
   "source": [
    "%cd /home/jupyter-deeplearning/res_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020/11/14 15:04:40\n",
      "epoch: 1/500 | trn loss: 1.7949 | val loss: 1.6301 | val accuracy: 40.2594% \n",
      "\n",
      "2020/11/14 15:05:27\n",
      "epoch: 2/500 | trn loss: 1.5112 | val loss: 1.4392 | val accuracy: 47.6462% \n",
      "\n",
      "2020/11/14 15:06:14\n",
      "epoch: 3/500 | trn loss: 1.3488 | val loss: 1.3575 | val accuracy: 51.8780% \n",
      "\n",
      "2020/11/14 15:07:00\n",
      "epoch: 4/500 | trn loss: 1.2231 | val loss: 1.2592 | val accuracy: 55.3135% \n",
      "\n",
      "2020/11/14 15:07:47\n",
      "epoch: 5/500 | trn loss: 1.1200 | val loss: 1.2021 | val accuracy: 57.0863% \n",
      "\n",
      "2020/11/14 15:08:33\n",
      "epoch: 6/500 | trn loss: 1.0381 | val loss: 1.1916 | val accuracy: 58.2732% \n",
      "\n",
      "2020/11/14 15:09:20\n",
      "epoch: 7/500 | trn loss: 0.9654 | val loss: 1.1458 | val accuracy: 59.8508% \n",
      "\n",
      "2020/11/14 15:10:06\n",
      "epoch: 8/500 | trn loss: 0.8949 | val loss: 1.1524 | val accuracy: 59.7656% \n",
      "\n",
      "2020/11/14 15:10:52\n",
      "epoch: 9/500 | trn loss: 0.8451 | val loss: 1.1484 | val accuracy: 60.4367% \n",
      "\n",
      "2020/11/14 15:11:38\n",
      "epoch: 10/500 | trn loss: 0.7954 | val loss: 1.1140 | val accuracy: 61.4133% \n",
      "\n",
      "2020/11/14 15:12:24\n",
      "epoch: 11/500 | trn loss: 0.7588 | val loss: 1.1174 | val accuracy: 61.2230% \n",
      "\n",
      "Model replaced and saved as  Custom_model_2.0_1.117\n",
      "2020/11/14 15:13:10\n",
      "epoch: 12/500 | trn loss: 0.7200 | val loss: 1.1083 | val accuracy: 62.3498% \n",
      "\n",
      "Model replaced and saved as  Custom_model_2.0_1.108\n",
      "2020/11/14 15:13:56\n",
      "epoch: 13/500 | trn loss: 0.6900 | val loss: 1.0991 | val accuracy: 62.8456% \n",
      "\n",
      "Model replaced and saved as  Custom_model_2.0_1.099\n",
      "2020/11/14 15:14:43\n",
      "epoch: 14/500 | trn loss: 0.6655 | val loss: 1.1062 | val accuracy: 62.6903% \n",
      "\n",
      "2020/11/14 15:15:29\n",
      "epoch: 15/500 | trn loss: 0.6470 | val loss: 1.0941 | val accuracy: 62.9908% \n",
      "\n",
      "Model replaced and saved as  Custom_model_2.0_1.094\n",
      "2020/11/14 15:16:15\n",
      "epoch: 16/500 | trn loss: 0.6199 | val loss: 1.0861 | val accuracy: 63.9974% \n",
      "\n",
      "Model replaced and saved as  Custom_model_2.0_1.086\n",
      "2020/11/14 15:17:02\n",
      "epoch: 17/500 | trn loss: 0.5970 | val loss: 1.0890 | val accuracy: 63.6018% \n",
      "\n",
      "2020/11/14 15:17:48\n",
      "epoch: 18/500 | trn loss: 0.5863 | val loss: 1.1273 | val accuracy: 62.6603% \n",
      "\n",
      "2020/11/14 15:18:34\n",
      "epoch: 19/500 | trn loss: 0.5731 | val loss: 1.0715 | val accuracy: 63.9373% \n",
      "\n",
      "Model replaced and saved as  Custom_model_2.0_1.072\n",
      "2020/11/14 15:19:21\n",
      "epoch: 20/500 | trn loss: 0.5611 | val loss: 1.0978 | val accuracy: 64.7536% \n",
      "\n",
      "2020/11/14 15:20:07\n",
      "epoch: 21/500 | trn loss: 0.5483 | val loss: 1.1053 | val accuracy: 63.9573% \n",
      "\n",
      "2020/11/14 15:20:54\n",
      "epoch: 22/500 | trn loss: 0.5384 | val loss: 1.1283 | val accuracy: 63.2412% \n",
      "\n",
      "2020/11/14 15:21:40\n",
      "epoch: 23/500 | trn loss: 0.5204 | val loss: 1.0734 | val accuracy: 65.0942% \n",
      "\n",
      "2020/11/14 15:22:27\n",
      "epoch: 24/500 | trn loss: 0.5231 | val loss: 1.1180 | val accuracy: 64.1176% \n",
      "\n",
      "2020/11/14 15:23:14\n",
      "epoch: 25/500 | trn loss: 0.5097 | val loss: 1.0846 | val accuracy: 64.9589% \n",
      "\n",
      "2020/11/14 15:24:01\n",
      "epoch: 26/500 | trn loss: 0.4996 | val loss: 1.1447 | val accuracy: 64.0325% \n",
      "\n",
      "2020/11/14 15:24:47\n",
      "epoch: 27/500 | trn loss: 0.4960 | val loss: 1.0847 | val accuracy: 65.1793% \n",
      "\n",
      "2020/11/14 15:25:33\n",
      "epoch: 28/500 | trn loss: 0.4939 | val loss: 1.1020 | val accuracy: 64.8287% \n",
      "\n",
      "2020/11/14 15:26:20\n",
      "epoch: 29/500 | trn loss: 0.4843 | val loss: 1.0993 | val accuracy: 64.8087% \n",
      "\n",
      "2020/11/14 15:27:06\n",
      "epoch: 30/500 | trn loss: 0.4739 | val loss: 1.1643 | val accuracy: 63.3514% \n",
      "\n",
      "2020/11/14 15:27:53\n",
      "epoch: 31/500 | trn loss: 0.4671 | val loss: 1.0997 | val accuracy: 65.1643% \n",
      "\n",
      "2020/11/14 15:28:39\n",
      "epoch: 32/500 | trn loss: 0.4641 | val loss: 1.0911 | val accuracy: 64.9690% \n",
      "\n",
      "2020/11/14 15:29:26\n",
      "epoch: 33/500 | trn loss: 0.4630 | val loss: 1.1166 | val accuracy: 64.5333% \n",
      "\n",
      "2020/11/14 15:30:12\n",
      "epoch: 34/500 | trn loss: 0.4570 | val loss: 1.1855 | val accuracy: 63.1811% \n",
      "\n",
      "2020/11/14 15:30:59\n",
      "epoch: 35/500 | trn loss: 0.4519 | val loss: 1.0882 | val accuracy: 64.9289% \n",
      "\n",
      "2020/11/14 15:31:46\n",
      "epoch: 36/500 | trn loss: 0.4511 | val loss: 1.1062 | val accuracy: 65.3646% \n",
      "\n",
      "2020/11/14 15:32:33\n",
      "epoch: 37/500 | trn loss: 0.4406 | val loss: 1.0839 | val accuracy: 65.5549% \n",
      "\n",
      "2020/11/14 15:33:19\n",
      "epoch: 38/500 | trn loss: 0.4295 | val loss: 1.0981 | val accuracy: 65.5950% \n",
      "\n",
      "2020/11/14 15:34:06\n",
      "epoch: 39/500 | trn loss: 0.4321 | val loss: 1.1205 | val accuracy: 64.7987% \n",
      "\n",
      "2020/11/14 15:34:52\n",
      "epoch: 40/500 | trn loss: 0.4336 | val loss: 1.0889 | val accuracy: 65.5899% \n",
      "\n",
      "2020/11/14 15:35:38\n",
      "epoch: 41/500 | trn loss: 0.4308 | val loss: 1.1231 | val accuracy: 65.4497% \n",
      "\n",
      "2020/11/14 15:36:25\n",
      "epoch: 42/500 | trn loss: 0.4272 | val loss: 1.0790 | val accuracy: 65.7602% \n",
      "\n",
      "2020/11/14 15:37:11\n",
      "epoch: 43/500 | trn loss: 0.4213 | val loss: 1.1246 | val accuracy: 65.1743% \n",
      "\n",
      "2020/11/14 15:37:58\n",
      "epoch: 44/500 | trn loss: 0.4182 | val loss: 1.1016 | val accuracy: 65.7402% \n",
      "\n",
      "2020/11/14 15:38:44\n",
      "epoch: 45/500 | trn loss: 0.4193 | val loss: 1.0868 | val accuracy: 65.5048% \n",
      "\n",
      "2020/11/14 15:39:31\n",
      "epoch: 46/500 | trn loss: 0.4179 | val loss: 1.1006 | val accuracy: 65.8203% \n",
      "\n",
      "2020/11/14 15:40:18\n",
      "epoch: 47/500 | trn loss: 0.4109 | val loss: 1.1116 | val accuracy: 64.9539% \n",
      "\n",
      "2020/11/14 15:41:04\n",
      "epoch: 48/500 | trn loss: 0.4125 | val loss: 1.0692 | val accuracy: 66.3512% \n",
      "\n",
      "Model replaced and saved as  Custom_model_2.0_1.069\n",
      "2020/11/14 15:41:50\n",
      "epoch: 49/500 | trn loss: 0.4097 | val loss: 1.1014 | val accuracy: 65.7903% \n",
      "\n",
      "2020/11/14 15:42:37\n",
      "epoch: 50/500 | trn loss: 0.4023 | val loss: 1.1537 | val accuracy: 64.6184% \n",
      "\n",
      "2020/11/14 15:43:23\n",
      "epoch: 51/500 | trn loss: 0.2979 | val loss: 0.9924 | val accuracy: 69.2157% \n",
      "\n",
      "Model replaced and saved as  Custom_model_2.0_0.992\n",
      "2020/11/14 15:44:10\n",
      "epoch: 52/500 | trn loss: 0.2619 | val loss: 0.9755 | val accuracy: 69.3159% \n",
      "\n",
      "Model replaced and saved as  Custom_model_2.0_0.976\n",
      "2020/11/14 15:44:56\n",
      "epoch: 53/500 | trn loss: 0.2552 | val loss: 0.9665 | val accuracy: 70.1723% \n",
      "\n",
      "Model replaced and saved as  Custom_model_2.0_0.966\n",
      "2020/11/14 15:45:42\n",
      "epoch: 54/500 | trn loss: 0.2484 | val loss: 1.0024 | val accuracy: 69.1006% \n",
      "\n",
      "2020/11/14 15:46:29\n",
      "epoch: 55/500 | trn loss: 0.2439 | val loss: 0.9924 | val accuracy: 69.6565% \n",
      "\n",
      "2020/11/14 15:47:16\n",
      "epoch: 56/500 | trn loss: 0.2356 | val loss: 0.9924 | val accuracy: 69.2909% \n",
      "\n",
      "2020/11/14 15:48:02\n",
      "epoch: 57/500 | trn loss: 0.2334 | val loss: 0.9983 | val accuracy: 69.5663% \n",
      "\n",
      "2020/11/14 15:48:49\n",
      "epoch: 58/500 | trn loss: 0.2298 | val loss: 1.0148 | val accuracy: 69.4311% \n",
      "\n",
      "2020/11/14 15:49:35\n",
      "epoch: 59/500 | trn loss: 0.2257 | val loss: 1.0147 | val accuracy: 69.2408% \n",
      "\n",
      "2020/11/14 15:50:22\n",
      "epoch: 60/500 | trn loss: 0.2255 | val loss: 0.9966 | val accuracy: 70.0921% \n",
      "\n",
      "2020/11/14 15:51:08\n",
      "epoch: 61/500 | trn loss: 0.2208 | val loss: 1.0215 | val accuracy: 69.3610% \n",
      "\n",
      "2020/11/14 15:51:55\n",
      "epoch: 62/500 | trn loss: 0.2218 | val loss: 1.0096 | val accuracy: 69.4962% \n",
      "\n",
      "2020/11/14 15:52:41\n",
      "epoch: 63/500 | trn loss: 0.2188 | val loss: 1.0240 | val accuracy: 69.4862% \n",
      "\n",
      "2020/11/14 15:53:27\n",
      "epoch: 64/500 | trn loss: 0.2129 | val loss: 1.0320 | val accuracy: 69.3610% \n",
      "\n",
      "2020/11/14 15:54:14\n",
      "epoch: 65/500 | trn loss: 0.2118 | val loss: 1.0365 | val accuracy: 69.2708% \n",
      "\n",
      "2020/11/14 15:55:00\n",
      "epoch: 66/500 | trn loss: 0.2098 | val loss: 1.0304 | val accuracy: 68.9854% \n",
      "\n",
      "2020/11/14 15:55:46\n",
      "epoch: 67/500 | trn loss: 0.2086 | val loss: 1.0397 | val accuracy: 69.2808% \n",
      "\n",
      "2020/11/14 15:56:33\n",
      "epoch: 68/500 | trn loss: 0.2086 | val loss: 1.0367 | val accuracy: 69.4511% \n",
      "\n",
      "2020/11/14 15:57:19\n",
      "epoch: 69/500 | trn loss: 0.2022 | val loss: 1.0642 | val accuracy: 68.6649% \n",
      "\n",
      "2020/11/14 15:58:06\n",
      "epoch: 70/500 | trn loss: 0.2046 | val loss: 1.0374 | val accuracy: 69.6164% \n",
      "\n",
      "2020/11/14 15:58:53\n",
      "epoch: 71/500 | trn loss: 0.1984 | val loss: 1.0470 | val accuracy: 69.5663% \n",
      "\n",
      "2020/11/14 15:59:39\n",
      "epoch: 72/500 | trn loss: 0.2045 | val loss: 1.0417 | val accuracy: 69.7366% \n",
      "\n",
      "2020/11/14 16:00:26\n",
      "epoch: 73/500 | trn loss: 0.2003 | val loss: 1.0434 | val accuracy: 69.4411% \n",
      "\n",
      "2020/11/14 16:01:13\n",
      "epoch: 74/500 | trn loss: 0.2002 | val loss: 1.0324 | val accuracy: 69.5713% \n",
      "\n",
      "2020/11/14 16:01:59\n",
      "epoch: 75/500 | trn loss: 0.2024 | val loss: 1.0312 | val accuracy: 69.5913% \n",
      "\n",
      "2020/11/14 16:02:45\n",
      "epoch: 76/500 | trn loss: 0.1947 | val loss: 1.0329 | val accuracy: 69.6364% \n",
      "\n",
      "2020/11/14 16:03:32\n",
      "epoch: 77/500 | trn loss: 0.1975 | val loss: 1.0598 | val accuracy: 69.2508% \n",
      "\n",
      "2020/11/14 16:04:19\n",
      "epoch: 78/500 | trn loss: 0.1978 | val loss: 1.0705 | val accuracy: 68.8452% \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020/11/14 16:05:05\n",
      "epoch: 79/500 | trn loss: 0.1946 | val loss: 1.0545 | val accuracy: 69.3760% \n",
      "\n",
      "2020/11/14 16:05:52\n",
      "epoch: 80/500 | trn loss: 0.1931 | val loss: 1.0589 | val accuracy: 69.2859% \n",
      "\n",
      "2020/11/14 16:06:38\n",
      "epoch: 81/500 | trn loss: 0.1953 | val loss: 1.0542 | val accuracy: 68.9353% \n",
      "\n",
      "2020/11/14 16:07:24\n",
      "epoch: 82/500 | trn loss: 0.1897 | val loss: 1.0612 | val accuracy: 68.9904% \n",
      "\n",
      "2020/11/14 16:08:11\n",
      "epoch: 83/500 | trn loss: 0.1931 | val loss: 1.0629 | val accuracy: 69.1206% \n",
      "\n",
      "2020/11/14 16:08:58\n",
      "epoch: 84/500 | trn loss: 0.1925 | val loss: 1.0748 | val accuracy: 69.0905% \n",
      "\n",
      "2020/11/14 16:09:44\n",
      "epoch: 85/500 | trn loss: 0.1931 | val loss: 1.0302 | val accuracy: 69.6264% \n",
      "\n",
      "2020/11/14 16:10:30\n",
      "epoch: 86/500 | trn loss: 0.1900 | val loss: 1.0528 | val accuracy: 69.2157% \n",
      "\n",
      "2020/11/14 16:11:16\n",
      "epoch: 87/500 | trn loss: 0.1889 | val loss: 1.0695 | val accuracy: 69.4611% \n",
      "\n",
      "2020/11/14 16:12:02\n",
      "epoch: 88/500 | trn loss: 0.1905 | val loss: 1.0408 | val accuracy: 69.6565% \n",
      "\n",
      "2020/11/14 16:12:49\n",
      "epoch: 89/500 | trn loss: 0.1846 | val loss: 1.0401 | val accuracy: 69.8618% \n",
      "\n",
      "2020/11/14 16:13:35\n",
      "epoch: 90/500 | trn loss: 0.1835 | val loss: 1.0789 | val accuracy: 68.9103% \n",
      "\n",
      "2020/11/14 16:14:21\n",
      "epoch: 91/500 | trn loss: 0.1796 | val loss: 1.0734 | val accuracy: 68.9403% \n",
      "\n",
      "2020/11/14 16:15:07\n",
      "epoch: 92/500 | trn loss: 0.1857 | val loss: 1.0530 | val accuracy: 70.1222% \n",
      "\n",
      "2020/11/14 16:15:53\n",
      "epoch: 93/500 | trn loss: 0.1815 | val loss: 1.0866 | val accuracy: 69.1206% \n",
      "\n",
      "2020/11/14 16:16:39\n",
      "epoch: 94/500 | trn loss: 0.1796 | val loss: 1.0673 | val accuracy: 69.4261% \n",
      "\n",
      "2020/11/14 16:17:26\n",
      "epoch: 95/500 | trn loss: 0.1791 | val loss: 1.0786 | val accuracy: 69.1857% \n",
      "\n",
      "2020/11/14 16:18:12\n",
      "epoch: 96/500 | trn loss: 0.1787 | val loss: 1.0696 | val accuracy: 69.6214% \n",
      "\n",
      "2020/11/14 16:18:57\n",
      "epoch: 97/500 | trn loss: 0.1820 | val loss: 1.0778 | val accuracy: 69.0855% \n",
      "\n",
      "2020/11/14 16:19:44\n",
      "epoch: 98/500 | trn loss: 0.1767 | val loss: 1.0831 | val accuracy: 69.3209% \n",
      "\n",
      "2020/11/14 16:20:30\n",
      "epoch: 99/500 | trn loss: 0.1796 | val loss: 1.0672 | val accuracy: 69.3710% \n",
      "\n",
      "2020/11/14 16:21:15\n",
      "epoch: 100/500 | trn loss: 0.1763 | val loss: 1.0802 | val accuracy: 69.1206% \n",
      "\n",
      "2020/11/14 16:22:01\n",
      "epoch: 101/500 | trn loss: 0.1709 | val loss: 1.0355 | val accuracy: 69.7316% \n",
      "\n",
      "2020/11/14 16:22:47\n",
      "epoch: 102/500 | trn loss: 0.1676 | val loss: 1.0375 | val accuracy: 69.8668% \n",
      "\n",
      "2020/11/14 16:23:33\n",
      "epoch: 103/500 | trn loss: 0.1608 | val loss: 1.0449 | val accuracy: 70.0721% \n",
      "\n",
      "2020/11/14 16:24:19\n",
      "epoch: 104/500 | trn loss: 0.1630 | val loss: 1.0420 | val accuracy: 69.5713% \n",
      "\n",
      "2020/11/14 16:25:06\n",
      "epoch: 105/500 | trn loss: 0.1621 | val loss: 1.0444 | val accuracy: 70.0521% \n",
      "\n",
      "2020/11/14 16:25:52\n",
      "epoch: 106/500 | trn loss: 0.1594 | val loss: 1.0306 | val accuracy: 70.2875% \n",
      "\n",
      "2020/11/14 16:26:38\n",
      "epoch: 107/500 | trn loss: 0.1568 | val loss: 1.0544 | val accuracy: 70.0821% \n",
      "\n",
      "2020/11/14 16:27:24\n",
      "epoch: 108/500 | trn loss: 0.1603 | val loss: 1.0380 | val accuracy: 70.1522% \n",
      "\n",
      "2020/11/14 16:28:11\n",
      "epoch: 109/500 | trn loss: 0.1617 | val loss: 1.0510 | val accuracy: 70.3175% \n",
      "\n",
      "2020/11/14 16:28:57\n",
      "epoch: 110/500 | trn loss: 0.1584 | val loss: 1.0458 | val accuracy: 69.9870% \n",
      "\n",
      "2020/11/14 16:29:43\n",
      "epoch: 111/500 | trn loss: 0.1580 | val loss: 1.0374 | val accuracy: 70.1372% \n",
      "\n",
      "2020/11/14 16:30:29\n",
      "epoch: 112/500 | trn loss: 0.1583 | val loss: 1.0335 | val accuracy: 70.2023% \n",
      "\n",
      "2020/11/14 16:31:15\n",
      "epoch: 113/500 | trn loss: 0.1566 | val loss: 1.0398 | val accuracy: 70.1573% \n",
      "\n",
      "2020/11/14 16:32:02\n",
      "epoch: 114/500 | trn loss: 0.1554 | val loss: 1.0367 | val accuracy: 70.4227% \n",
      "\n",
      "2020/11/14 16:32:48\n",
      "epoch: 115/500 | trn loss: 0.1553 | val loss: 1.0452 | val accuracy: 70.2574% \n",
      "\n",
      "2020/11/14 16:33:35\n",
      "epoch: 116/500 | trn loss: 0.1558 | val loss: 1.0480 | val accuracy: 69.8468% \n",
      "\n",
      "2020/11/14 16:34:21\n",
      "epoch: 117/500 | trn loss: 0.1563 | val loss: 1.0534 | val accuracy: 69.7165% \n",
      "\n",
      "2020/11/14 16:35:08\n",
      "epoch: 118/500 | trn loss: 0.1537 | val loss: 1.0383 | val accuracy: 70.0070% \n",
      "\n",
      "2020/11/14 16:35:54\n",
      "epoch: 119/500 | trn loss: 0.1564 | val loss: 1.0465 | val accuracy: 69.9369% \n",
      "\n",
      "2020/11/14 16:36:41\n",
      "epoch: 120/500 | trn loss: 0.1579 | val loss: 1.0634 | val accuracy: 69.4912% \n",
      "\n",
      "2020/11/14 16:37:28\n",
      "epoch: 121/500 | trn loss: 0.1533 | val loss: 1.0440 | val accuracy: 70.1773% \n",
      "\n",
      "2020/11/14 16:38:14\n",
      "epoch: 122/500 | trn loss: 0.1534 | val loss: 1.0505 | val accuracy: 70.4277% \n",
      "\n",
      "2020/11/14 16:39:01\n",
      "epoch: 123/500 | trn loss: 0.1526 | val loss: 1.0545 | val accuracy: 69.7366% \n",
      "\n",
      "2020/11/14 16:39:47\n",
      "epoch: 124/500 | trn loss: 0.1541 | val loss: 1.0471 | val accuracy: 70.1873% \n",
      "\n",
      "2020/11/14 16:40:34\n",
      "epoch: 125/500 | trn loss: 0.1525 | val loss: 1.0580 | val accuracy: 70.0120% \n",
      "\n",
      "2020/11/14 16:41:20\n",
      "epoch: 126/500 | trn loss: 0.1540 | val loss: 1.0347 | val accuracy: 70.3075% \n",
      "\n",
      "2020/11/14 16:42:06\n",
      "epoch: 127/500 | trn loss: 0.1545 | val loss: 1.0444 | val accuracy: 70.2073% \n",
      "\n",
      "2020/11/14 16:42:53\n",
      "epoch: 128/500 | trn loss: 0.1532 | val loss: 1.0595 | val accuracy: 70.3626% \n",
      "\n",
      "2020/11/14 16:43:39\n",
      "epoch: 129/500 | trn loss: 0.1531 | val loss: 1.0546 | val accuracy: 69.7917% \n",
      "\n",
      "2020/11/14 16:44:26\n",
      "epoch: 130/500 | trn loss: 0.1561 | val loss: 1.0621 | val accuracy: 69.7917% \n",
      "\n",
      "2020/11/14 16:45:13\n",
      "epoch: 131/500 | trn loss: 0.1537 | val loss: 1.0621 | val accuracy: 70.0471% \n",
      "\n",
      "2020/11/14 16:45:59\n",
      "epoch: 132/500 | trn loss: 0.1514 | val loss: 1.0604 | val accuracy: 69.8868% \n",
      "\n",
      "2020/11/14 16:46:45\n",
      "epoch: 133/500 | trn loss: 0.1526 | val loss: 1.0509 | val accuracy: 70.3275% \n",
      "\n",
      "2020/11/14 16:47:32\n",
      "epoch: 134/500 | trn loss: 0.1512 | val loss: 1.0483 | val accuracy: 70.4026% \n",
      "\n",
      "2020/11/14 16:48:18\n",
      "epoch: 135/500 | trn loss: 0.1544 | val loss: 1.0469 | val accuracy: 70.0170% \n",
      "\n",
      "2020/11/14 16:49:04\n",
      "epoch: 136/500 | trn loss: 0.1501 | val loss: 1.0491 | val accuracy: 69.8868% \n",
      "\n",
      "2020/11/14 16:49:51\n",
      "epoch: 137/500 | trn loss: 0.1524 | val loss: 1.0700 | val accuracy: 69.8468% \n",
      "\n",
      "2020/11/14 16:50:37\n",
      "epoch: 138/500 | trn loss: 0.1501 | val loss: 1.0410 | val accuracy: 70.1723% \n",
      "\n",
      "2020/11/14 16:51:24\n",
      "epoch: 139/500 | trn loss: 0.1537 | val loss: 1.0515 | val accuracy: 69.8468% \n",
      "\n",
      "2020/11/14 16:52:10\n",
      "epoch: 140/500 | trn loss: 0.1545 | val loss: 1.0581 | val accuracy: 69.8768% \n",
      "\n"
     ]
    }
   ],
   "source": [
    "trn_loss_list = []\n",
    "val_loss_list = []\n",
    "val_acc_list = []\n",
    "total_epoch=500\n",
    "model_char=\"2.0\"\n",
    "model_name=\"\"\n",
    "patience=10\n",
    "start_early_stop_check=0\n",
    "saving_start_epoch=10\n",
    "\n",
    "for epoch in range(total_epoch):\n",
    "    trn_loss = 0.0\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        inputs, labels = data\n",
    "        if torch.cuda.is_available():\n",
    "            inputs=inputs.cuda()\n",
    "            labels=labels.cuda()\n",
    "        # grad init\n",
    "        optimizer.zero_grad()\n",
    "        # forward propagation\n",
    "        output= model(inputs)\n",
    "        # calculate loss\n",
    "        loss=criterion(output, labels)\n",
    "        # back propagation \n",
    "        loss.backward()\n",
    "        # weight update\n",
    "        optimizer.step()\n",
    "        \n",
    "        # trn_loss summary\n",
    "        trn_loss += loss.item()\n",
    "        # del (memory issue)\n",
    "        del loss\n",
    "        del output\n",
    "    with torch.no_grad():\n",
    "        val_loss = 0.0\n",
    "        cor_match = 0\n",
    "        for j, val in enumerate(test_loader):\n",
    "            val_x, val_label = val\n",
    "            if torch.cuda.is_available():\n",
    "                val_x = val_x.cuda()\n",
    "                val_label =val_label.cuda()\n",
    "            val_output = model(val_x)\n",
    "            v_loss = criterion(val_output, val_label)\n",
    "            val_loss += v_loss\n",
    "            _, predicted=torch.max(val_output,1)\n",
    "            cor_match+=np.count_nonzero(predicted.cpu().detach()==val_label.cpu().detach())\n",
    "    del val_output\n",
    "    del v_loss\n",
    "    del predicted\n",
    "    \n",
    "    scheduler.step()\n",
    "    \n",
    "    \n",
    "    \n",
    "    trn_loss_list.append(trn_loss/len(train_loader))\n",
    "    val_loss_list.append(val_loss/len(test_loader))\n",
    "    val_acc=cor_match/(len(test_loader)*batch_size)\n",
    "    val_acc_list.append(val_acc)\n",
    "    now = time.localtime()\n",
    "    print (\"%04d/%02d/%02d %02d:%02d:%02d\" % (now.tm_year, now.tm_mon, now.tm_mday, now.tm_hour, now.tm_min, now.tm_sec))\n",
    "\n",
    "    print(\"epoch: {}/{} | trn loss: {:.4f} | val loss: {:.4f} | val accuracy: {:.4f}% \\n\".format(\n",
    "                epoch+1, total_epoch, trn_loss / len(train_loader), val_loss / len(test_loader), val_acc*100\n",
    "            ))\n",
    "    \n",
    "    \n",
    "    if epoch+1>2:\n",
    "        if val_loss_list[-1]>val_loss_list[-2]:\n",
    "            start_early_stop_check=1\n",
    "    else:\n",
    "        val_loss_min=val_loss_list[-1]\n",
    "        \n",
    "    if start_early_stop_check:\n",
    "        early_stop_temp=val_loss_list[-patience:]\n",
    "        if all(early_stop_temp[i]<early_stop_temp[i+1] for i in range (len(early_stop_temp)-1)):\n",
    "            print(\"Early stop!\")\n",
    "            break\n",
    "            \n",
    "    if epoch+1>saving_start_epoch:\n",
    "        if val_loss_list[-1]<val_loss_min:\n",
    "            if os.path.isfile(model_name):\n",
    "                os.remove(model_name)\n",
    "            val_loss_min=val_loss_list[-1]\n",
    "            model_name=\"Custom_model_\"+model_char+\"_{:.3f}\".format(val_loss_min)\n",
    "            torch.save(model, model_name)\n",
    "            print(\"Model replaced and saved as \",model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,15))\n",
    "plt.ylabel(\"val_accuracy\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.plot(val_acc_list)\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_acc_list=np.array(val_acc_list)\n",
    "np.savetxt(\"ver_2.0.txt\", val_acc_list, delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import argparse\n",
    "import time\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /home/jupyter-deeplearning/Organize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize = transforms.Normalize(mean=[0.507, 0.487, 0.441],\n",
    "                                     std=[0.267, 0.256, 0.276])\n",
    "test_transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        normalize\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = torchvision.datasets.ImageFolder('./data/test', transform=test_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, num_workers=4, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Category = []\n",
    "for input, _ in test_loader:\n",
    "    input = input.cuda()\n",
    "    output = model(input)\n",
    "    output = torch.argmax(output, dim=1)\n",
    "    Category = Category + output.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Id = list(range(0, 8000))\n",
    "samples = {\n",
    "   'Id': Id,\n",
    "   'Category': Category \n",
    "}\n",
    "df = pd.DataFrame(samples, columns=['Id', 'Category'])\n",
    "\n",
    "df.to_csv('submission_2.0_2.csv', index=False)\n",
    "print('Done!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
